<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>DY的个人博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-01-16T02:17:34.972Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>湛蓝星空</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Tensorflow中的模型训练技巧</title>
    <link href="http://yoursite.com/2020/01/15/Tensorflow%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/"/>
    <id>http://yoursite.com/2020/01/15/Tensorflow中的模型训练技巧/</id>
    <published>2020-01-15T07:07:04.000Z</published>
    <updated>2020-01-16T02:17:34.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="优化卷积核"><a href="#优化卷积核" class="headerlink" title="优化卷积核"></a>优化卷积核</h2><p>在实际的卷积训练中，为了加快速度，常常把卷积层裁开。比如一个3x3的过滤器，可以裁成3x1和1x3两个过滤器，分别对原有输入做卷积操作，这样可以大大提升运算速度</p><p>原理：在浮点运算中乘法消耗的资源较多，我们的目的就是尽量减小乘法运算</p><p>比如：对一个5x2的原始图片进行一次3x3的同卷积，相当于生成的5x2像素中每一个都要经历3x3次乘法，一共90次。同样一张图片，如果先进行一次3x1的同卷积需要30次运算，再进行一次1x3的同卷积还是30次，一共60次。</p><p>看下面例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv2=tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)</span><br></pre></td></tr></table></figure><p>修改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">W_conv21 = weight_variable([<span class="number">5</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">64</span>])</span><br><span class="line">b_conv21 = bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv21 = tf.nn.relu(conv2d(h_pool1, W_conv21) + b_conv21)</span><br><span class="line">W_conv2 = weight_variable([<span class="number">1</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv2=tf.nn.relu(conv2d(h_conv21,W_conv2)+b_conv2)</span><br></pre></td></tr></table></figure><h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><p>批量归一化，简称BN算法。一般用在全连接层或卷积神经网络。它的作用是要最大限度地保证每次的正向传播输出在同一分布上， 这样反向计算时参照的数据样本分布就会与正向计算时的数据分布一样了。 保证了分布统一， 对权重的调整才会更有意义。  </p><p>批量归一化的做法很简单，即将每一层运算出来的数据都归一化成均值为0、方差为1的标准高斯分布。这样就会在保留样本分布特征的同时，又消除了层与层之间的分布差异</p><p>Tensorflow中自带的BN函数定义：</p><p>tf.nn.batch_normalization(x,mean,variance,offset,scale,variance_epsion,name=None)，参数说明如下：</p><p>x：代表输入</p><p>mean：代表样本的均值</p><p>variance：代表方差</p><p>offset：代表偏移，即相加一个转化值，后面我们会用激活函数来转换，所以直接使用0</p><p>scale：代表缩放，即乘以一个转化值。一般用1</p><p>variance_epsilon：为了避免分布为0的情况，给分母加一个极小值</p><p>要想使用上面这个BN函数，必须由另一个函数配合使用——tf.nn.moments，由他来计算均值和方差，然后就可以使用BN。tf.nn.moments定义如下：</p><p>tf.nn.moments(x,axes,name=None,keep_dims=False)</p><p>axes主要是指定哪个轴来求均值与方差</p><p>有了上面的两个函数还不够，为了有更好的效果，我们希望使用平滑指数衰减的方法来优化每次的均值与方差，于是就用到了tf.train.ExponentialMovingAverage函数。它的左右是上一次的值对本次的值有个衰减后的影响，从而使每次的值连起来后会相对平滑一些。展开后可以用下列等式表示：</p><p>shadow_variable = decay * shadow_variable + (1- decay) * variable，各参数说明如下：</p><p>decay：代表衰减指数，直接指定的。比如0.9</p><p>variable：代表本批次样本中的值</p><p>等式右边的shadow_variable：代表上次总样本的值</p><p>等式左边的shadow_variable：代表计算出来的本次总样本的值</p><p>上面的函数需要联合使用，于是在Tensorflow中的layers模块又实现了一次BN函数，相当于把上面几个函数结合在一起。使用时，首先将头文件引入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.contrib.layers.python.layers <span class="keyword">import</span> barch_norm</span><br></pre></td></tr></table></figure><p>batch_norm(inputs,decay=0.999,center=True,scale=False,epsilon=0.001,activation_fn=None,param_initializers=None,param_regularizers=None,updates_collections=ops.GraphKeys.UPDATE_OPS,is_training=True,reuse=None,variables_collections=None,outputs_collections=None,trainable=True,batch_weights=None,fused=False,data_format=DATA_FORMAT_NHWC,zero_debias_moving_mean=False,scope=None,renorm=False,renorm_clipping=None,renorm_decay=0.9)，参数看得眼都花了，参数说明如下：</p><p>inputs：代表输入</p><p>decay：代表移动平均值的衰败速度，是使用了一种叫做平滑指数衰减的方法更新均值方差，一般设为0.9；值太小会导致均值和方差更新太快，而值太大又会导致几乎没有衰减，容易出现过拟合。</p><p>scale：是否进行变化（通过乘一个gamma值进行缩放），一般设为False。</p><p>epsilon：是为了避免分母为0的情况，给分母加一个极小值，默认即可。</p><p>is_training：当它为True，代表是训练过程，这时会不断更新样本集的均值与方差。测试时，设为False，就会使用测试样本集的均值与方差</p><p>updatas_collections：默认为tf.GraphKeys.UPDARE_OPS，在训练时提供一种内置的均值方差更新机制，即通过图中的tf.GraphKeys.UPDATE_OPS变量来更新。但它是在每次当前批次训练完成后才更新均值和方差，这样导致当前数据总是使用前一次的均值和方差，没有得到最新的更新。所以都会将其设为None，让均值和方差即时更新。</p><p>reuse：支持共享变量，与下面的scope参数联合使用</p><p>scope：指定变量的作用域variable_scope</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;优化卷积核&quot;&gt;&lt;a href=&quot;#优化卷积核&quot; class=&quot;headerlink&quot; title=&quot;优化卷积核&quot;&gt;&lt;/a&gt;优化卷积核&lt;/h2&gt;&lt;p&gt;在实际的卷积训练中，为了加快速度，常常把卷积层裁开。比如一个3x3的过滤器，可以裁成3x1和1x3两个过滤器，分别对
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>梯度</title>
    <link href="http://yoursite.com/2020/01/15/%E6%A2%AF%E5%BA%A6/"/>
    <id>http://yoursite.com/2020/01/15/梯度/</id>
    <published>2020-01-15T01:15:11.000Z</published>
    <updated>2020-01-16T02:06:24.435Z</updated>
    
    <content type="html"><![CDATA[<p>在反向传播过程中，神经网络需要对每一个loss对应的学习参数求偏导，算出的这个值叫做梯度，用来乘以学习率然后更新学习参数使用的</p><h2 id="求单变量偏导"><a href="#求单变量偏导" class="headerlink" title="求单变量偏导"></a>求单变量偏导</h2><p>它是通过tf.gradients函数来实现的。<br>tf.gradients(ys,xs,grad_ys=None,name=’gradients’,colocate_gradients_with_ops=False,gate_gradients=False,  aggregation_method=None,stop_gradients=None)</p><p>第一个参数为求导公式的结果，第二个参数为指定公式中的哪个变量来求偏导。实现第一个参数对第二个参数求导。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1=tf.Variable([[<span class="number">1</span>,<span class="number">2</span>]],dtype=tf.float32)</span><br><span class="line">w2=tf.Variable([[<span class="number">3</span>,<span class="number">4</span>]],dtype=tf.float32)</span><br><span class="line">y=tf.matmul(w1,tf.convert_to_tensor([[<span class="number">9</span>],[<span class="number">10</span>]],dtype=tf.float32))</span><br><span class="line">grads=tf.gradients(y,[w1])</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  print(<span class="string">"梯度为："</span>,sess.run(grads))</span><br><span class="line"></span><br><span class="line"> <span class="comment">#梯度为： [array([[ 9., 10.]], dtype=float32)]</span></span><br></pre></td></tr></table></figure><p>上面例子中，由于y是由w1与[[9],[10]]相乘而来，所以导数就是[[9],[10]]，也就是斜率</p><h2 id="求多变量偏导"><a href="#求多变量偏导" class="headerlink" title="求多变量偏导"></a>求多变量偏导</h2><p>这就需要用到tf.gradients的第三个参数，grad_ys。grad_ys也是一个list，其长度等于len(ys)。这个参数的意义在于对第一个参数中的每个元素的求导加权重</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="comment">#随机生成一个形状为2的变量</span></span><br><span class="line">w1 = tf.get_variable(<span class="string">'w1'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w2 = tf.get_variable(<span class="string">'w2'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">w3 = tf.get_variable(<span class="string">'w3'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w4 = tf.get_variable(<span class="string">'w4'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">y1 = w1 + w2+ w3</span><br><span class="line">y2 = w3 + w4</span><br><span class="line"><span class="comment">#不考虑参数grad_ys</span></span><br><span class="line">gradients= tf.gradients([y1, y2], [w1, w2, w3, w4])</span><br><span class="line"><span class="comment">#考虑参数grad_ys</span></span><br><span class="line">gradients1 = tf.gradients([y1, y2], [w1, w2, w3, w4], grad_ys=[tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>]),</span><br><span class="line">                                                          tf.convert_to_tensor([<span class="number">3.</span>,<span class="number">4.</span>])])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(w1))</span><br><span class="line">    print(sess.run(gradients1))</span><br><span class="line">    print(sess.run(gradients))</span><br></pre></td></tr></table></figure><h2 id="梯度停止"><a href="#梯度停止" class="headerlink" title="梯度停止"></a>梯度停止</h2><p>对于反向传播过程中某种特殊情况需要停止梯度运算时，在tensorflow中提供了一个tf.stop_gradient函数，被它定义过的节点将没有梯度运算功能</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">w1 = tf.get_variable(<span class="string">'w1'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w2 = tf.get_variable(<span class="string">'w2'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">w3 = tf.get_variable(<span class="string">'w3'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w4 = tf.get_variable(<span class="string">'w4'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">y1 = w1 + w2+ w3</span><br><span class="line">y2 = w3 + w4</span><br><span class="line"></span><br><span class="line">a = w1+w2</span><br><span class="line">a_stoped = tf.stop_gradient(a)</span><br><span class="line">y3= a_stoped+w3</span><br><span class="line"></span><br><span class="line">gradients = tf.gradients([y1, y2], [w1, w2, w3, w4], grad_ys=[tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>]),</span><br><span class="line">                                                          tf.convert_to_tensor([<span class="number">3.</span>,<span class="number">4.</span>])])                                                      </span><br><span class="line">gradients2 = tf.gradients(y3, [w1, w2, w3], grad_ys=tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>]))                                                          </span><br><span class="line">print(gradients2) </span><br><span class="line"> </span><br><span class="line">gradients3 = tf.gradients(y3, [w3], grad_ys=tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>])) </span><br><span class="line">                                                       </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(gradients))</span><br><span class="line">    <span class="comment">#print(sess.run(gradients2))#报错，因为w1和w2梯度停止了</span></span><br><span class="line">    print(sess.run(gradients3))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在反向传播过程中，神经网络需要对每一个loss对应的学习参数求偏导，算出的这个值叫做梯度，用来乘以学习率然后更新学习参数使用的&lt;/p&gt;
&lt;h2 id=&quot;求单变量偏导&quot;&gt;&lt;a href=&quot;#求单变量偏导&quot; class=&quot;headerlink&quot; title=&quot;求单变量偏导&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>反卷积和反池化</title>
    <link href="http://yoursite.com/2020/01/11/%E5%8F%8D%E5%8D%B7%E7%A7%AF%E5%92%8C%E5%8F%8D%E6%B1%A0%E5%8C%96/"/>
    <id>http://yoursite.com/2020/01/11/反卷积和反池化/</id>
    <published>2020-01-11T09:13:49.000Z</published>
    <updated>2020-01-15T07:02:58.500Z</updated>
    
    <content type="html"><![CDATA[<h2 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h2><p>反卷积是指通过测量输出已知输入重构未知输入的过程。在神经网络中，反卷积过程并不具备学习的能力，仅仅是用于可视化一个已经训练好的卷积网络模型，没有学习训练的过程。如下图：即为VGG16反卷积神经网络的结构，展示了一个卷积网络与反卷积网络结合的过程。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111184504.png" alt=""></p><p>反卷积就是将中间的数据，按照前面卷积、池化等过程，完全相反地做一遍，从而得到类似原始输入的数据。</p><h3 id="反卷积原理"><a href="#反卷积原理" class="headerlink" title="反卷积原理"></a>反卷积原理</h3><p>反卷积可以理解为卷积操作的逆操作。<strong>千万不要将反卷积操作可以复原卷积操作的输入值，</strong>反卷积并没有这个功能，它仅仅是将卷积变换过程中的步骤反向变换一次。通过将卷积核转置，与卷积后的结果再做一遍卷积，所以反卷积还有个名字叫做转置卷积。</p><p>反卷积操作：</p><p>（1） 首先是将卷积核反转（ 并不是转置，而是上下左右方向进行递序操作）。也就是对卷积核做180<sup>o</sup>翻转。<br>（2） 再将卷积结果作为输入， 做补0的扩充操作， 即往每一个元素后面补0。 这一步是根据步长来的， 对每一个元素沿着步长的方向补（ 步长-1） 个0。 例如， 步长为1就不用补0了。<br>（3） 在扩充后的输入基础上再对整体补0。以原始输入的shape作为输出， 按照前面介绍的卷积padding规则， 计算pading的补0位置及个数， 得到的补0位置要上下和左右各自颠倒一下。<br>（4） 将补0后的卷积结果作为真正的输入，反转后的卷积核为filter， 进行步长为1的卷积操作。  </p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111193249.png" alt=""></p><p>需要注意的是，通过反卷积并不能还原卷积之前的矩阵，只能从大小上进行还原，反卷积的本质还是卷积，只是在进行卷积之前，会进行一个自动的padding补0，从而使得输出的矩阵与指定输出矩阵的shape相同。框架本身，会根据我们自己设定的反卷积值来计算输入矩阵的尺寸，如果shape不符合，会出现报错。</p><h3 id="反卷积函数"><a href="#反卷积函数" class="headerlink" title="反卷积函数"></a>反卷积函数</h3><p>在Tensorflow中，反卷积是通过函数tf.nn.conv2d_transpose来实现的。</p><p>conv2d_transpose(value,filter,output_shape,strides,padding=”SAME”,data_format=”NHWC”,name=None)：</p><p>value：代表卷积操作之后的张量，需要进行反卷积的矩阵</p><p>filter：代表卷积核，参数格式[height,width,output_channels,in_channels]</p><p>output_shape：设置反卷积输出矩阵的shape</p><p>strides：反卷积步长</p><p>padding：补0方式，SAME和VALID方式</p><p>data_format：string类型的量，’NHWC’和’NCHW’其中之一，这是tensorflow新版本中新加的参数，它说明了value参数的数据格式。’NHWC’指tensorflow标准的数据格式[batch, height, width, in_channels]，‘NCHW’指Theano的数据格式,[batch, in_channels，height, width]，默认值是’NHWC’。</p><p>name：操作名称</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"></span><br><span class="line">img = tf.Variable(tf.constant(<span class="number">1.0</span>,shape = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>])) </span><br><span class="line"></span><br><span class="line">filter =  tf.Variable(tf.constant([<span class="number">1.0</span>,<span class="number">0</span>,<span class="number">-1</span>,<span class="number">-2</span>],shape = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">conv = tf.nn.conv2d(img, filter, strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>)  </span><br><span class="line">cons = tf.nn.conv2d(img, filter, strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">print(conv.shape)</span><br><span class="line">print(cons.shape)</span><br><span class="line"> </span><br><span class="line">contv= tf.nn.conv2d_transpose(conv, filter, [<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>],strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>)</span><br><span class="line">conts = tf.nn.conv2d_transpose(cons, filter, [<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>],strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:  </span><br><span class="line">    sess.run(tf.global_variables_initializer() )  </span><br><span class="line">    print(<span class="string">"img"</span>,sess.run(img))</span><br><span class="line">    print(<span class="string">"conv:\n"</span>,sess.run([conv,filter])) </span><br><span class="line">    print(<span class="string">"cons:\n"</span>,sess.run([cons]))    </span><br><span class="line">    print(<span class="string">"contv:\n"</span>,sess.run([contv])) </span><br><span class="line">    print(<span class="string">"conts:\n"</span>,sess.run([conts]))</span><br></pre></td></tr></table></figure><h3 id="反卷积应用场景"><a href="#反卷积应用场景" class="headerlink" title="反卷积应用场景"></a>反卷积应用场景</h3><p>由于反卷积的特性，可以用于信道均衡、图像恢复等问题。而在神经网络的研究中， 反卷积更多的是充当可视化的作用。 对于一个复杂的深度卷积网络，通过每层若干个卷积核的变换， 我们无法知道每个卷积核关注的是什么， 变换后的特征是什么样子。 通过反卷积的还原， 可以对这些问题有个清晰的可视化， 以各层得到的特征图作为输入， 进行反卷积， 得到反卷积结果， 用以验证显示各层提取到的特征图。  </p><h2 id="反池化"><a href="#反池化" class="headerlink" title="反池化"></a>反池化</h2><p>反池化属于池化的逆操作，是无法通过池化的结果还原出全部的原始数据。因为池化的过程就是只保留主要信息，舍去部分信息。如想从池化后的这些主要信息恢复出全部信息，则存在信息缺失，这时只能通过补位来实现最大程度的信息完整</p><h3 id="反池化原理"><a href="#反池化原理" class="headerlink" title="反池化原理"></a>反池化原理</h3><p>池化有两种最大池化和平均池化，反池化与其对应。</p><p>反平均池化比较简单。首先还原成原来的大小，然后将池化结果中的每个值都填入其对应于原始数据区域中的相应未知即可。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200112123007.png" alt=""></p><p>反最大池画要求在池化过程中记录最大激活值的坐标位置，然后在反池化时，只把池化过程中最大激活值所在位置坐标的值激活，其它的值置为0。这个过程只是一种近似，因为在池化过程中，除了最大值所在的位置，其它的值是不为0的</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200112123548.png" alt=""></p><h3 id="反池化操作"><a href="#反池化操作" class="headerlink" title="反池化操作"></a>反池化操作</h3><p>Tensorflow中没有反池化操作的函数。对于最大池化，也不支持输出最大激活值的位置，但是同样有个池化的反向传播函数tf.nn.max_pool_with_argmax。该函数可以输出位置，需要我们自己封装一个反池化函数。</p><p>首先重新定义最大池化函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_with_argmax</span><span class="params">(net, stride)</span>:</span></span><br><span class="line">    _, mask = tf.nn.max_pool_with_argmax( net,ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    mask = tf.stop_gradient(mask)</span><br><span class="line">    net = tf.nn.max_pool(net, ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) </span><br><span class="line">    <span class="keyword">return</span> net, mask</span><br></pre></td></tr></table></figure><p>在上面代码里，先调用tf.nn.max_pool_with_argmax函数获得每个最大值的位置mask，再将反向传播的mask梯度停止，接着再用tf.nn.max_pool函数计算最大池化操作，然后将mask和池化结果一起返回。</p><p><strong>注意</strong>：tf.nn.max_pool_with_argmax的方法只支持GPU操作，不能在cpu机器上使用。</p><p>接下来定义一个数组，并使用最大池化函数对其进行池化操作，比较一下tensorflow自带的tf.nn.max_pool函数是否一样，看看输出的mask</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">img=tf.constant([  </span><br><span class="line">        [[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>]],  </span><br><span class="line">        [[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>]],  </span><br><span class="line">        [[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>]],  </span><br><span class="line">        [[<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>], [<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>]]</span><br><span class="line">    ]) </span><br><span class="line">img=tf.reshape(img,[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line">pooling=tf.nn.max_pool(img,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">encode,mask=max_pool_with_argmax(img,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"image:"</span>,sess.run(img))</span><br><span class="line">  print(<span class="string">"pooling:"</span>,sess.run(pooling))</span><br><span class="line">  print(<span class="string">"encode"</span>,sess.run([encode,mask]))</span><br></pre></td></tr></table></figure><p>从输出结果可以看到，定义的最大池化与原来的版本输出是一样的。mask的值是将整个数据flat(扁平化)后的索引，但却保持与池化结果一致的shape。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpool</span><span class="params">(net, mask, stride)</span>:</span></span><br><span class="line"></span><br><span class="line">    ksize = [<span class="number">1</span>, stride, stride, <span class="number">1</span>]</span><br><span class="line">    input_shape = net.get_shape().as_list()</span><br><span class="line">    <span class="comment">#计算new shape</span></span><br><span class="line">    output_shape = (input_shape[<span class="number">0</span>], input_shape[<span class="number">1</span>] * ksize[<span class="number">1</span>], input_shape[<span class="number">2</span>] * ksize[<span class="number">2</span>], input_shape[<span class="number">3</span>])</span><br><span class="line">    <span class="comment">#计算索引</span></span><br><span class="line">    one_like_mask = tf.ones_like(mask)</span><br><span class="line">    batch_range = tf.reshape(tf.range(output_shape[<span class="number">0</span>], dtype=tf.int64), shape=[input_shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    b = one_like_mask * batch_range</span><br><span class="line">    y = mask // (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>])</span><br><span class="line">    x = mask % (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>]) // output_shape[<span class="number">3</span>]</span><br><span class="line">    feature_range = tf.range(output_shape[<span class="number">3</span>], dtype=tf.int64)</span><br><span class="line">    f = one_like_mask * feature_range</span><br><span class="line">    <span class="comment">#转置索引</span></span><br><span class="line">    updates_size = tf.size(net)</span><br><span class="line">    indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [<span class="number">4</span>, updates_size]))</span><br><span class="line">    values = tf.reshape(net, [updates_size])</span><br><span class="line">    ret = tf.scatter_nd(indices, values, output_shape)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure><p>上面代码的思路是找到mask对应的索引，将max的值填到指定地方。接着直接调用上面代码的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img2=unpool(encode,mask,<span class="number">2</span>)</span><br><span class="line"> <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">   result=sess.run(img2)  </span><br><span class="line">   <span class="keyword">print</span> (<span class="string">"reslut:\n"</span>,result)</span><br></pre></td></tr></table></figure><p>反最大池化整体代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_with_argmax</span><span class="params">(net, stride)</span>:</span></span><br><span class="line">    _, mask = tf.nn.max_pool_with_argmax( net,ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    mask = tf.stop_gradient(mask)</span><br><span class="line">    net = tf.nn.max_pool(net, ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) </span><br><span class="line">    <span class="keyword">return</span> net, mask</span><br><span class="line">img=tf.constant([  </span><br><span class="line">        [[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>]],  </span><br><span class="line">        [[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>]],  </span><br><span class="line">        [[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>]],  </span><br><span class="line">        [[<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>], [<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>]]</span><br><span class="line">    ]) </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpool</span><span class="params">(net, mask, stride)</span>:</span></span><br><span class="line"></span><br><span class="line">    ksize = [<span class="number">1</span>, stride, stride, <span class="number">1</span>]</span><br><span class="line">    input_shape = net.get_shape().as_list()</span><br><span class="line">    <span class="comment">#计算new shape</span></span><br><span class="line">    output_shape = (input_shape[<span class="number">0</span>], input_shape[<span class="number">1</span>] * ksize[<span class="number">1</span>], input_shape[<span class="number">2</span>] * ksize[<span class="number">2</span>], input_shape[<span class="number">3</span>])</span><br><span class="line">    <span class="comment">#计算索引</span></span><br><span class="line">    one_like_mask = tf.ones_like(mask)</span><br><span class="line">    batch_range = tf.reshape(tf.range(output_shape[<span class="number">0</span>], dtype=tf.int64), shape=[input_shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    b = one_like_mask * batch_range</span><br><span class="line">    y = mask // (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>])</span><br><span class="line">    x = mask % (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>]) // output_shape[<span class="number">3</span>]</span><br><span class="line">    feature_range = tf.range(output_shape[<span class="number">3</span>], dtype=tf.int64)</span><br><span class="line">    f = one_like_mask * feature_range</span><br><span class="line">    <span class="comment">#转置索引</span></span><br><span class="line">    updates_size = tf.size(net)</span><br><span class="line">    indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [<span class="number">4</span>, updates_size]))</span><br><span class="line">    values = tf.reshape(net, [updates_size])</span><br><span class="line">    ret = tf.scatter_nd(indices, values, output_shape)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line">img=tf.reshape(img,[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line">pooling=tf.nn.max_pool(img,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">encode,mask=max_pool_with_argmax(img,<span class="number">2</span>)</span><br><span class="line">img2=unpool(encode,mask,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"image:"</span>,sess.run(img))</span><br><span class="line">  print(<span class="string">"pooling:"</span>,sess.run(pooling))</span><br><span class="line">  print(<span class="string">"encode"</span>,sess.run([encode,mask]))</span><br><span class="line"></span><br><span class="line">  result,mask2=sess.run([encode, mask])  </span><br><span class="line">  <span class="keyword">print</span> (<span class="string">"encode:\n"</span>,result,mask2)</span><br><span class="line">  result=sess.run(img2)  </span><br><span class="line">  <span class="keyword">print</span> (<span class="string">"reslut:\n"</span>,result)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;反卷积&quot;&gt;&lt;a href=&quot;#反卷积&quot; class=&quot;headerlink&quot; title=&quot;反卷积&quot;&gt;&lt;/a&gt;反卷积&lt;/h2&gt;&lt;p&gt;反卷积是指通过测量输出已知输入重构未知输入的过程。在神经网络中，反卷积过程并不具备学习的能力，仅仅是用于可视化一个已经训练好的卷积网
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow中的队列</title>
    <link href="http://yoursite.com/2020/01/10/Tensorflow%E4%B8%AD%E7%9A%84%E9%98%9F%E5%88%97/"/>
    <id>http://yoursite.com/2020/01/10/Tensorflow中的队列/</id>
    <published>2020-01-10T10:43:32.000Z</published>
    <updated>2020-02-03T02:35:08.121Z</updated>
    
    <content type="html"><![CDATA[<p>Tensorflow提供了一个队列机制，通过多线程将读取数据与计算数据分开，因为在处理海量数据集的训练时，无法把数据集一次全部载入内存中，需要以便从硬盘中读取，一边训练计算。</p><h2 id="队列（queue）"><a href="#队列（queue）" class="headerlink" title="队列（queue）"></a>队列（queue）</h2><h3 id="启动线程"><a href="#启动线程" class="headerlink" title="启动线程"></a>启动线程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.start_queue_runners()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111144227.png" alt=""></p><p>那什么时候程序会进入挂起状态呢？</p><p>源于上面第四行代码，意思是我们要从队列中拿出指定批次的数据，但是队列里没有数据，所以程序会进入挂起状态</p><h3 id="在session内部的退出机制"><a href="#在session内部的退出机制" class="headerlink" title="在session内部的退出机制"></a>在session内部的退出机制</h3><p>如果把session部分改为with语法：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111141238.png" alt=""></p><p>再次运行程序后，程序虽然能够正常运行，但是结束后会报错。原因是with语法的session是自动关闭的，  当运行结束后session自动关闭的同时会把里面所有的操作都关掉， 而此时的队列还在等待另一个进程往里写数据， 所以就会报错。   </p><p>解决方法：使用sess=tf.InteractiveSession()实现，或者像第一张图片一样创建</p><p><strong>tf.InteractiveSession()和tf.Session()的区别：</strong></p><p>使用InteractiveSession()来创建会话，我们要先构建Session()然后定义操作。如果使用Session来创建会话，我们需要在会话之前定义好全部的操作然后再构建会话。</p><p>上面的代码在单例程序中没什么问题， 资源会随着程序关闭而整体销毁。 但如果在复杂的代码中， 需要某个线程自动关闭， 而不是依赖进程的结束而销毁， 这种情况下需要使用tf.train.Coordinator函数来创建一个协调器， 以信号量的方式来协调线程间的关系， 完成线程间的同步。  </p><h2 id="协调器"><a href="#协调器" class="headerlink" title="协调器"></a>协调器</h2><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL19.png" alt=""></p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL20.png" alt=""></p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL@1.png" alt=""></p><p>下面这个例子是先建立一个100大小的队列，主线程使用计数器不停的加1，队列线程把主线程里的计数器放到队列中，当队列为空时，主线程会在sess.run(queue.dequeue())语句位置挂起。当队列线程写入队列中时，主线程的计数器同步开始工作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#创建一个长度为100的队列</span></span><br><span class="line">queue=tf.FIFOQueue(<span class="number">100</span>,<span class="string">"float"</span>)</span><br><span class="line">c=tf.Variable(<span class="number">0.0</span>)   <span class="comment">#计数器</span></span><br><span class="line"><span class="comment">#c+1.0</span></span><br><span class="line">op=tf.assign_add(c,tf.constant(<span class="number">1.0</span>))</span><br><span class="line"><span class="comment">#将计数器的结果加入队列</span></span><br><span class="line">enqueue_op=queue.enqueue(c)</span><br><span class="line"><span class="comment">#创建一个队列管理器queueRunner,用上面这两个操作向queue中添加元素。</span></span><br><span class="line">qr=tf.train.QueueRunner(queue,enqueue_ops=[op,enqueue_op])</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  coord=tf.train.Coordinator()</span><br><span class="line">  <span class="comment">#启动入队进程</span></span><br><span class="line">  enqueue_threads=qr.create_threads(sess,coord=coord,start=<span class="literal">True</span>)</span><br><span class="line">  <span class="comment">#主线程</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>):</span><br><span class="line">    print(sess.run(queue.dequeue()))</span><br><span class="line">  <span class="comment">#通知其它线程关闭，其它所有线程关闭后，这一函数才返回</span></span><br><span class="line">  coord.request_stop()</span><br></pre></td></tr></table></figure><p>还可以使用coord.join(enqueue_threads)指定等待某个进程结束</p><p>为session中的队列加上协调器，只需要将上例的coord放到启动队列中。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111163544.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Tensorflow提供了一个队列机制，通过多线程将读取数据与计算数据分开，因为在处理海量数据集的训练时，无法把数据集一次全部载入内存中，需要以便从硬盘中读取，一边训练计算。&lt;/p&gt;
&lt;h2 id=&quot;队列（queue）&quot;&gt;&lt;a href=&quot;#队列（queue）&quot; class
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/Tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>CNN的相关函数</title>
    <link href="http://yoursite.com/2019/11/29/CNN%E7%9A%84%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2019/11/29/CNN的相关函数/</id>
    <published>2019-11-29T12:22:09.000Z</published>
    <updated>2020-01-10T07:25:13.122Z</updated>
    
    <content type="html"><![CDATA[<h2 id="卷积函数"><a href="#卷积函数" class="headerlink" title="卷积函数"></a>卷积函数</h2><p>tf.nn.conv2d(input,filter,strides,padding,use_cudnn_on_gpu=None,name=None)</p><p>除去用以指定该操作名字的name参数，与方法有关的共有5个参数。如下:</p><p>input： 指需要做卷积的输入图像， 它要求是一个Tensor， 具有[batch， in_height， in_width，in_channels]这样的形状（shape） ， 具体含义是“训练时一个batch的图片数量， 图片高度， 图片宽度， 图像通道数” ， 注意这是一个四维的<br>Tensor， 要求类型为float32和float64其中之一。</p><p>filter： 相当于CNN中的卷积核， 它要求是一个Tensor， 具有[filter_height， filter_width，in_channels， out_channels]这样的shape， 具体含义是“卷积核的高度， 滤波器的宽度， 图像通道数， 滤波器个数” ， 要求类型与参数input相同。有一个地方需要注意， 第三维in_channels， 就是参数input的第四维。</p><p>strides： 卷积时在图像每一维的步长， 这是一个一维的向量， 长度为4。</p><p>padding： 定义元素边框与元素内容之间的空间。 string类型的量， 只能是SAME和VALID其中之一， 这个值决定了不同的卷积方式， padding的值为’VALID’时， 表示边缘不填充， 当其为’SAME’时， 表示填充到滤波器可以到达图像边缘。</p><p>use_cudnn_on_gpu： bool类型， 是否使用cudnn加速， 默认为true。  </p><h2 id="池化函数"><a href="#池化函数" class="headerlink" title="池化函数"></a>池化函数</h2><p>tf.nn.max_pool(input,ksize,strides,padding,name=None)</p><p>tf.nn.avg_pool(input,ksize,strides,padding,name=None)</p><p>上面这两个函数中的四个参数和卷积参数类似，如下：</p><p>input：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch,height,width,channels]这样的shape。</p><p>ksize：池化窗口的大小，取一个四维向量，一般是[1,height,width,1]，我们不想在batch和channels上做池化，所以这两个维度设为1</p><p>strides：步长，一般也是[1,strides,strides,1]</p><p>padding：和卷积一样，VALID是不进行padding操作，SAME是padding操作</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;卷积函数&quot;&gt;&lt;a href=&quot;#卷积函数&quot; class=&quot;headerlink&quot; title=&quot;卷积函数&quot;&gt;&lt;/a&gt;卷积函数&lt;/h2&gt;&lt;p&gt;tf.nn.conv2d(input,filter,strides,padding,use_cudnn_on_gpu=Non
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow中如何预防过拟合</title>
    <link href="http://yoursite.com/2019/11/26/tensorflow%E4%B8%AD%E5%A6%82%E4%BD%95%E9%A2%84%E9%98%B2%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    <id>http://yoursite.com/2019/11/26/tensorflow中如何预防过拟合/</id>
    <published>2019-11-26T14:26:29.000Z</published>
    <updated>2020-01-15T07:12:13.452Z</updated>
    
    <content type="html"><![CDATA[<h2 id="方法概述"><a href="#方法概述" class="headerlink" title="方法概述"></a>方法概述</h2><p>避免过拟合的方法有很多，常用的方法有early stopping、数据集扩增、正则化、dropout。下面就概述一下，具体请参照 <a href="[https://brickexperts.github.io/2019/10/11/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95(2">优化算法(1)</a>/#more](<a href="https://brickexperts.github.io/2019/10/11/优化算法(2)/#more" target="_blank" rel="noopener">https://brickexperts.github.io/2019/10/11/优化算法(2)/#more</a>)</p><p>early stoping：在发生过拟合之前提前结束。理论上是可以的，但是这个点不好把握。</p><p>数据集扩增：就是让模型见到更多的情况，可以最大化地满足全样本，但实际应用中对于未来事件的预测不理想。</p><p>正则化：通过映入范数，增强模型的泛化能力。包括L1、L2.</p><p>dropout：是网络模型中的一种方法。每次训练时舍去一些节点来增强泛化能力。</p><p>下面我们来具体看看如何实现后两种方法。</p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>所谓的正则化， 其实就是在神经网络计算损失值的过程中， 在损失后面再加一项。 这样损失值所代表的输出与标准结果间的误差就会受到干扰， 导致学习参数w和b无法按照目标方向来调整， 实现模型无法与样本完全拟合的结果， 从而达到防止过拟合的效果  </p><p>这个干扰项一定要有下面这样的特性：</p><p>1、当欠拟合时，希望它对模型误差的影响越小越好，以便让模型快速拟合实际</p><p>2、当过拟合时，希望他对模型误差的影响越大越好，以便让模型不要产生过拟合的情况。</p><p>由上面两个特性，引入两个范数：L1和L2</p><p>L1：所有学习参数w的绝对值的和。</p><p>L2：所有学习参数w的平方和然后求平方根</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191127210328.png" alt=""></p><p>上图中的第一个式子是L1范式，另一个就是L2范式。loss为等式左边的结果，less(0)代表真实的loss值，less(0)后面的那一项就代表正则化，&lambda;为一个可以调整的参数，用来控制正则化对loss的影响。对于L2，将其乘以1/2是为了反向传播时对其求导可以将数据规整。</p><h2 id="tensorflow中的正则化"><a href="#tensorflow中的正则化" class="headerlink" title="tensorflow中的正则化"></a>tensorflow中的正则化</h2><p>L2的正则化函数为:</p><p>tf.nn.l2_loss(t,name=None)</p><p>L1的正则化函数在tensorflow是没有自己组装的，可以自己写：</p><p>tf.reduce_sum(tf.abs(w))</p><h2 id="通过正则化改善过拟合"><a href="#通过正则化改善过拟合" class="headerlink" title="通过正则化改善过拟合"></a>通过正则化改善过拟合</h2><p>使用正则化非常简单，只需要在计算损失值时加上loss的正则化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reg=<span class="number">0.01</span></span><br><span class="line">loss=tf.reduce_mean((y_pred-y)**<span class="number">2</span>)+tf.nn.l2_loss(weights[<span class="string">'h1'</span>])*reg+tf.nn.l2_loss(weight[<span class="string">'h2'</span>])*reg</span><br></pre></td></tr></table></figure><h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><p>还有一种防止过拟合的方法是dropout。这个方法的做法是：在训练过程中，每次随机选择一部分节点不要去“学习”</p><p>因为从样本数据的分析来看，数据本身是不可能很纯净的，也就是任何一个模型不能100%把数据完全分开，在某一类中一定会有一些异常数据，过拟合的问题恰恰是把这些异常数据当初规律来学习了。我们希望把异常数据过滤掉，只关心有用的规律数据。</p><p>异常数据的特点是，它与主流样本中的规律都不同，但是量非常少，相当于在一个样本中出现的概率比主流数据出现的概率低很多。我们可以利用这一点，通过在每次模型中忽略一些节点的数据学习，将小概率的异常数据获得学习的机会降低，这样这些异常数据对模型的影响就会更小了。</p><p><strong>注意</strong>：由于dropout让一部分节点不去“学习”，所以在增加模型的泛化能力的同时，会使学习速度降低，使模型不太容易学成。所以在使用的过程中需要合理地调节到底丢弃多少节点，并不是丢弃的节点越多越好。</p><h2 id="tensorflow中的dropout"><a href="#tensorflow中的dropout" class="headerlink" title="tensorflow中的dropout"></a>tensorflow中的dropout</h2><p>tf.nn.dropout(x,keep_prob,noise_shape=None,seed=None,name=None)</p><p>x： 输入的模型节点。<br>keep_prob： 保持率。 如果为1， 则代表全部进行学习； 如果为0.8， 则代表丢弃20%的节点， 只让80%的节点参与学习。<br>noise_shape： 代表指定x中， 哪些维度可以使用dropout技术。 为None时， 表示所有维度都使用dropout技术。 也可以将某个维度标志为1， 来代表该维度使用dropout技术。 例如： x的形状为[n， len， w， ch]， 使用noise_shape为[n， 1， 1，ch]， 这表明会对x中的第二维度len和第三维度w进行dropout。<br>seed： 随机选取节点的过程中随机数的种子值。</p><h2 id="全连接网络的深浅关系"><a href="#全连接网络的深浅关系" class="headerlink" title="全连接网络的深浅关系"></a>全连接网络的深浅关系</h2><p>在实际中，如果想使用浅层神经网络拟合复杂非线性函数，就需要靠增加的神经元个数来实现。神经元过多意味着需要训练的参数过多，这会增加网络的学习难度，并影响网络的泛化能力。因此，在增加网络结构时，一般倾向于使用更多的模型，来减少网络中所需要神经元的数量，使网络有更好的泛化能力。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;方法概述&quot;&gt;&lt;a href=&quot;#方法概述&quot; class=&quot;headerlink&quot; title=&quot;方法概述&quot;&gt;&lt;/a&gt;方法概述&lt;/h2&gt;&lt;p&gt;避免过拟合的方法有很多，常用的方法有early stopping、数据集扩增、正则化、dropout。下面就概述一下，具体请
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>numpy(2)</title>
    <link href="http://yoursite.com/2019/11/24/numpy(2)/"/>
    <id>http://yoursite.com/2019/11/24/numpy(2)/</id>
    <published>2019-11-24T06:58:11.000Z</published>
    <updated>2019-11-24T11:31:45.253Z</updated>
    
    <content type="html"><![CDATA[<h2 id="np-concatenate"><a href="#np-concatenate" class="headerlink" title="np.concatenate"></a>np.concatenate</h2><p>数组拼接函数，concatenate((a1,a2,……),axis=0)</p><p>参数a1，a2……为要拼接的数组，axis为在哪个维度上进行拼接。默认为0</p><p>>&gt;&gt;import numpy as np<br>>&gt;&gt;a=np.array([[1,2],[3,4]])<br>>&gt;&gt;b=np.array([[5,6]])</p><p>>&gt;&gt;np.concatenate((a,b),axis=0)<br>array([[1, 2],<br>       [3, 4],<br>       [5, 6]])</p><p>>&gt;&gt;np.concatenate((a,b.T),axis=1)<br>array([[1, 2, 5],<br>       [3, 4, 6]])</p><h2 id="np-eye"><a href="#np-eye" class="headerlink" title="np.eye"></a>np.eye</h2><p>生成对角矩阵</p><p>numpy.eye(N,M=None, k=0, dtype=<type 'float'>)</p><p>第一个参数：输出方阵（行数=列数）的规模，即行数或列数</p><p>第三个参数：默认情况下输出的是对角线全“1”，其余全“0”的方阵，如果k为正整数，则在右上方第k条对角线全“1”其余全“0”，k为负整数则在左下方第k条对角线全“1”其余全“0”。</p><p>>&gt;&gt;import numpy as np<br>>&gt;&gt;np.eye(1,3,dtype=int)<br>array([[1, 0, 0]])<br>>&gt;&gt;np.eye(2,3,dtype=int)<br>array([[1, 0, 0],<br>       [0, 1, 0]])<br>>&gt;&gt;np.eye(2,2,dtype=int)<br>array([[1, 0],<br>       [0, 1]])<br>>&gt;&gt;np.eye(4,4,dtype=int)<br>array([[1, 0, 0, 0],<br>       [0, 1, 0, 0],<br>       [0, 0, 1, 0],<br>       [0, 0, 0, 1]])</p><p>>&gt;&gt;np.eye(4,4,k=2,dtype=int)<br>array([[0, 0, 1, 0],<br>       [0, 0, 0, 1],<br>       [0, 0, 0, 0],<br>       [0, 0, 0, 0]])</p><h2 id="np-random-multivariate-normal"><a href="#np-random-multivariate-normal" class="headerlink" title="np.random.multivariate_normal"></a>np.random.multivariate_normal</h2><p>multivariate_normal(mean,cov,size=None,check_valid=None,tol=None)：用于根据实际情况生成一个多元正态分布矩阵</p><p>其中mean和cov为必要的传参而size，check_valid以及tol为可选参数。</p><p>mean：mean是多维分布的均值维度为1；</p><p>cov：协方差矩阵，注意：协方差矩阵必须是对称的且需为半正定矩阵；</p><p>size：指定生成的正态分布矩阵的维度（例：若size=(1, 1, 2)，则输出的矩阵的shape即形状为 1X1X2XN（N为mean的长度））。</p><p>check_valid：这个参数用于决定当cov即协方差矩阵不是半正定矩阵时程序的处理方式，它一共有三个值：warn，raise以及ignore。当使用warn作为传入的参数时，如果cov不是半正定的程序会输出警告但仍旧会得到结果；当使用raise作为传入的参数时，如果cov不是半正定的程序会报错且不会计算出结果；当使用ignore时忽略这个问题即无论cov是否为半正定的都会计算出结果。3种情况的console打印结果如下：</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;np-concatenate&quot;&gt;&lt;a href=&quot;#np-concatenate&quot; class=&quot;headerlink&quot; title=&quot;np.concatenate&quot;&gt;&lt;/a&gt;np.concatenate&lt;/h2&gt;&lt;p&gt;数组拼接函数，concatenate((a1
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
      <category term="数学计算" scheme="http://yoursite.com/categories/python/%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="numpy" scheme="http://yoursite.com/categories/python/%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97/numpy/"/>
    
    
      <category term="python的数学计算模块" scheme="http://yoursite.com/tags/python%E7%9A%84%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9D%97/"/>
    
  </entry>
  
  <entry>
    <title>Maxout网络</title>
    <link href="http://yoursite.com/2019/11/23/Maxout%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2019/11/23/Maxout网络/</id>
    <published>2019-11-23T08:18:18.000Z</published>
    <updated>2019-11-23T11:12:54.214Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Maxout介绍"><a href="#Maxout介绍" class="headerlink" title="Maxout介绍"></a>Maxout介绍</h2><p>Maxout网络可以理解为单个神经元的扩展，主要是扩展单个神经元里面的激活函数。Maxout是将激活函数变成一个网络选择器，原理就是将多个神经元并列地放在一起，从它们的输出结果中找到最大的那个，代表对特征响应最敏感，然后取这个神经元的结束参与后面的运算。</p><p>下图是单个神经元和Maxout网络的区别：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/6.jpg" alt=""></p><p>Maxout的公式可以理解为：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191123163141.png" alt=""></p><p>这个的做法就是相当于同时使用多个神经元放在一起， 哪个有效果就用哪个。 所以这样的网络会有更好的拟合效果。  </p><h2 id="Maxout网络实现MNIST分类"><a href="#Maxout网络实现MNIST分类" class="headerlink" title="Maxout网络实现MNIST分类"></a>Maxout网络实现MNIST分类</h2><p>Maxout网络的构建方法：通过reduce_max函数对多个神经元的输出来计算Max值，将Max值当作输入按照神经元正反传播方向进行计算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'输入数据:'</span>,mnist.train.images)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'输入数据打shape:'</span>,mnist.train.images.shape)</span><br><span class="line"><span class="keyword">import</span> pylab </span><br><span class="line">im = mnist.train.images[<span class="number">1</span>]</span><br><span class="line">im = im.reshape(<span class="number">-1</span>,<span class="number">28</span>)</span><br><span class="line">pylab.imshow(im)</span><br><span class="line">pylab.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">'输入数据打shape:'</span>,mnist.test.images.shape)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'输入数据打shape:'</span>,mnist.validation.images.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment">#导入tensorflow库</span></span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="comment"># tf Graph Input</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment"># mnist data维度 28*28=784</span></span><br><span class="line">y = tf.placeholder(tf.int32, [<span class="literal">None</span>]) <span class="comment"># 0-9 数字=&gt; 10 classes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set model weights</span></span><br><span class="line">W = tf.Variable(tf.random_normal([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line">z= tf.matmul(x, W) + b</span><br><span class="line">cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=z))</span><br><span class="line">maxout=tf.reduce_max(z,axis=<span class="number">1</span>,keep_dims=<span class="literal">True</span>)</span><br><span class="line">W2=tf.Variable(tf.truncated_normal([<span class="number">1</span>,<span class="number">10</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b2=tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">pred=tf.nn.softmax(tf.matmul(maxout,W2)+b2)</span><br><span class="line">learning_rate = <span class="number">0.04</span></span><br><span class="line"><span class="comment"># 使用梯度下降优化器</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line">training_epochs = <span class="number">200</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动session</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())<span class="comment"># Initializing OP</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 启动循环开始训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0.</span></span><br><span class="line">        total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        <span class="comment"># 遍历全部数据集</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            <span class="comment"># Run optimization op (backprop) and cost op (to get loss value)</span></span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs,</span><br><span class="line">                                                          y: batch_ys&#125;)</span><br><span class="line">            <span class="comment"># Compute average loss</span></span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">        <span class="comment"># 显示训练中的详细信息</span></span><br><span class="line">        <span class="keyword">if</span> (epoch+<span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch+<span class="number">1</span>), <span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</span><br><span class="line"></span><br><span class="line">    print( <span class="string">" Finished!"</span>)</span><br></pre></td></tr></table></figure><p>Maxout的拟合功能很强大，但是也会有节点过多，参数过多，训练过慢的缺点。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Maxout介绍&quot;&gt;&lt;a href=&quot;#Maxout介绍&quot; class=&quot;headerlink&quot; title=&quot;Maxout介绍&quot;&gt;&lt;/a&gt;Maxout介绍&lt;/h2&gt;&lt;p&gt;Maxout网络可以理解为单个神经元的扩展，主要是扩展单个神经元里面的激活函数。Maxout
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow的学习率退化和随机初始化</title>
    <link href="http://yoursite.com/2019/11/23/Tensorflow%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%87%E9%80%80%E5%8C%96%E5%92%8C%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
    <id>http://yoursite.com/2019/11/23/Tensorflow的学习率退化和随机初始化/</id>
    <published>2019-11-23T03:47:08.000Z</published>
    <updated>2019-11-23T08:15:12.753Z</updated>
    
    <content type="html"><![CDATA[<h2 id="退化学习率"><a href="#退化学习率" class="headerlink" title="退化学习率"></a>退化学习率</h2><p>设置学习率的大小，是在精度和速度之间找到一个平衡。如果学习率的值比较大，则训练速度快，但结果的精度不够。如果学习率的值比较小，精度虽然提升了，但训练会花太多时间。</p><p>退化学习率又叫学习率衰减， 它的本意是希望在训练过程中对于学习率大和小的优点都能够为我们所用， 也就是当训练刚开始时使用大的学习率加快速度， 训练到一定程度后使用小的学习率来提高精度， 这时可以使用学习率衰减的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exponential_decay</span><span class="params">(learning_rate,global_step,decay_rate,staircase=False,name=None)</span></span></span><br></pre></td></tr></table></figure><p>学习率的衰减速度是由global_step和decay_steps来决定的。计算公式如下：</p><p>decayed_learning_rate=learning_rate*decay_rate^(global_step/decay_step)。staircase值默认为False。当为True，将没有衰减功能，只是使用上面的公式初始化一个学习率的值而已。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learning_rate=tf.train.exponential_decay(starter_learning_rate,global_step,<span class="number">10000</span>,<span class="number">0.96</span>)</span><br></pre></td></tr></table></figure><p>这种方式定义的学习率就是退化学习率， 它的意思是当前迭代到global_step步， 学习率每一步都按照每10万步缩小到0.96%的速度衰退。  </p><p>通过增大批次处理样本的数量也可以起到退化学习率的效果。但是这种方法要求训练时的最小批次要与实际应用中的最小批次一致。一旦满足该条件，建议优先选择增大批次数量的方法。因为这样会省去一些开发量和训练中的计算量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">global_step=tf.Variable(<span class="number">0</span>,trainable=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#初始学习率为0.1</span></span><br><span class="line">initial_learning_rate=<span class="number">0.1</span></span><br><span class="line"><span class="comment">#每十次衰减0.9</span></span><br><span class="line">learning_rate=tf.train.exponential_decay(initial_learning_rate,global_step=global_step,</span><br><span class="line">                                        decay_steps=<span class="number">10</span>,</span><br><span class="line">                                        decay_rate=<span class="number">0.9</span>)</span><br><span class="line">opt=tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line"><span class="comment">#相当于global_step+1</span></span><br><span class="line">add_global=global_step.assign_add(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  print(sess.run(learning_rate))</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    g,rate=sess.run([add_global,learning_rate])</span><br><span class="line">    print(g,rate)</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：  这是一种常用的训练策略， 在训练神经网络时， 通常在训练刚开始时使用较大的learning rate， 随着训练的进行， 会慢慢减小learning rate。 在使用时， 一定要把当前迭代次数global_step传进去， 否则不会有退化的功能。  </p><h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><p>在定义学习参数时，可以通过get_variable和Variable两个方式。在使用get_variable时，tf.get_variable(name,shape,initializer)，当然还有其它参数，可以自己上网找一下。参数initializer就是初始化参数。可以去下表中列出的相关函数</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191123153950.png" alt=""></p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191123154010.png" alt=""></p><h3 id="初始化为常量"><a href="#初始化为常量" class="headerlink" title="初始化为常量"></a>初始化为常量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">value = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">init = tf.constant_initializer(value)</span><br><span class="line">x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">8</span>], initializer=init)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line">  <span class="comment">#sess.run(tf.global_variables_initializer())</span></span><br><span class="line"><span class="comment">#print(sess.run(x))</span></span><br><span class="line"><span class="comment">#输出:</span></span><br><span class="line"><span class="comment">#[ 0.  1.  2.  3.  4.  5.  6.  7.]</span></span><br></pre></td></tr></table></figure><h3 id="初始化为正态分布"><a href="#初始化为正态分布" class="headerlink" title="初始化为正态分布"></a>初始化为正态分布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">init_random = tf.random_normal_initializer(mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, seed=<span class="literal">None</span>, dtype=tf.float32)</span><br><span class="line">init_truncated = tf.truncated_normal_initializer(mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, seed=<span class="literal">None</span>, dtype=tf.float32)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">10</span>], initializer=init_random)</span><br><span class="line">  y = tf.get_variable(<span class="string">'y'</span>, shape=[<span class="number">10</span>], initializer=init_truncated)</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  y.initializer.run()</span><br><span class="line"> </span><br><span class="line">  print(x.eval())</span><br><span class="line">  print(y.eval())</span><br></pre></td></tr></table></figure><h3 id="初始化为均匀分布"><a href="#初始化为均匀分布" class="headerlink" title="初始化为均匀分布"></a>初始化为均匀分布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line">init_uniform = tf.random_uniform_initializer(minval=<span class="number">0</span>, maxval=<span class="number">10</span>, seed=<span class="literal">None</span>, dtype=tf.float32</span><br><span class="line">x = tf.get_variable(<span class="string">'x'</span>, shape=[<span class="number">10</span>], initializer=init_uniform)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  x.initializer.run()</span><br><span class="line">  print(x.eval())</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="comment"># [ 6.93343639  9.41196823  5.54009819  1.38017178  1.78720832  5.38881063</span></span><br><span class="line"><span class="comment">#   3.39674473  8.12443542  0.62157512  8.36026382]</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;退化学习率&quot;&gt;&lt;a href=&quot;#退化学习率&quot; class=&quot;headerlink&quot; title=&quot;退化学习率&quot;&gt;&lt;/a&gt;退化学习率&lt;/h2&gt;&lt;p&gt;设置学习率的大小，是在精度和速度之间找到一个平衡。如果学习率的值比较大，则训练速度快，但结果的精度不够。如果学习率的
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow中的损失函数和梯度下降</title>
    <link href="http://yoursite.com/2019/11/22/Tensorflow%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <id>http://yoursite.com/2019/11/22/Tensorflow中的损失函数和梯度下降/</id>
    <published>2019-11-22T12:52:58.000Z</published>
    <updated>2019-11-23T03:34:10.889Z</updated>
    
    <content type="html"><![CDATA[<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="均值平方差"><a href="#均值平方差" class="headerlink" title="均值平方差"></a>均值平方差</h3><p>均值平方差(Mean Squared Error，MSE)，也称”均方误差”，在神经网络中主要是表达预测值与真实值之间的差异，在数理统计中，均方误差是指参数估计值与参数真值之差平方的期望值。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122210450.png" alt=""></p><p>均方误差的值越小，表明模型越好。类似的损失算法还有均方误差RMSE(将MSE开平方)，平均绝对值误差MAD(对一个真实值与预测值相减的绝对值取平均值)。</p><p><strong>注意</strong>：在神经网络计算时，预测值要与真实值控制在同样的数据分布内，假设将预测值经过Sigmoid激活函数得到取值范围在0~1之间，那么真实值也归一化成0~1之间。</p><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><p>交叉熵(crossentropy)也是loss算法的一种，一般用于分类问题，表达的意思为预测输入样本属于某一类的概率。其中y代表真实值分类(0或1)，a代表预测值。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122211858.png" alt=""></p><p>交叉熵也只值越小，代表预测结果越准。</p><p><strong>注意</strong>：这里用于计算的a也是通过分布同一化处理的（或者是经过Sigmoid函数激活的），取值范围0~1。</p><h3 id="损失算法的选取"><a href="#损失算法的选取" class="headerlink" title="损失算法的选取"></a>损失算法的选取</h3><p>损失函数的选取取决于输入标签数据的类型： 如果输入的是实数、 无界的值， 损失函数使用平方差； 如果输入标签是位矢量（分类标志） ， 使用交叉熵会更适合。  </p><h3 id="Tensorflow的loss函数"><a href="#Tensorflow的loss函数" class="headerlink" title="Tensorflow的loss函数"></a>Tensorflow的loss函数</h3><h4 id="均值平方差-1"><a href="#均值平方差-1" class="headerlink" title="均值平方差"></a>均值平方差</h4><p>在Tensorflow没有单独的MSE函数，不过由于公式比较简单，往往都是自己写函数。也有多种写法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MSE=tf.reduce_mean(tf.pow(tf.sub(logits,outputs),<span class="number">2.0</span>))</span><br><span class="line">MSE=tf.reduce_mean(tf.square(tf.sub(logits,outputs)))</span><br><span class="line">MSE=tf.reduce_mean(tf.square(logits-outputs))</span><br></pre></td></tr></table></figure><p>logits代表标签值，outputs代表预测值。同样也可以组合其它类似loss，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rmse=tf.sqrt(tf.reduce_mean(tf.pow(tf.sub(logits,outputs),<span class="number">2.0</span>)))</span><br><span class="line">mad=tf.reduce_mean(tf.complex_abs(logits,outputs))</span><br></pre></td></tr></table></figure><h4 id="交叉熵-1"><a href="#交叉熵-1" class="headerlink" title="交叉熵"></a>交叉熵</h4><p>在tensorflow中常见的交叉熵函数有：Sigmoid交叉熵、softmax交叉熵、Sparse交叉熵、加权Sigmoid交叉熵</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122215154.png" alt=""></p><p>当然，我们也可以像MSE那样使用自己组合的公式计算交叉熵。对于softmax后的结果logits我们可以对其使用公式-tf.reduce_sum(labels*tf.log(logis),1)，就等同于softmax_cross_entropy_with_logits得到结果。（注意有个负号）</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="softmax交叉熵"><a href="#softmax交叉熵" class="headerlink" title="softmax交叉熵"></a>softmax交叉熵</h4><p>标签是one-hot编码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">labels=[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],]</span><br><span class="line">logits=[[<span class="number">2</span>,<span class="number">0.5</span>,<span class="number">6</span>],[<span class="number">0.1</span>,<span class="number">0</span>,<span class="number">3</span>]]</span><br><span class="line"><span class="comment">#进行第一次softmax</span></span><br><span class="line">logits_scaled=tf.nn.softmax(logits)</span><br><span class="line"><span class="comment">#进行第二次softmax</span></span><br><span class="line">logits_scaled2=tf.nn.softmax(logits_scaled)</span><br><span class="line"><span class="comment">#用第一次的softmax进行交叉熵计算</span></span><br><span class="line">result1=tf.nn.softmax_cross_entropy_with_logits(labels=labels,logits=logits)</span><br><span class="line"><span class="comment">#用第二次的softmax进行交叉熵计算</span></span><br><span class="line">result2=tf.nn.softmax_cross_entropy_with_logits(labels=labels,logits=logits_scaled)</span><br><span class="line"><span class="comment">#用自建公式实验</span></span><br><span class="line">result3=-tf.reduce_sum(labels*tf.log(logits_scaled),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  print(<span class="string">"logits_scaled："</span>,sess.run(logits_scaled))</span><br><span class="line">  print(<span class="string">"logits_scaled2"</span>,sess.run(logits_scaled2))</span><br><span class="line">  print(<span class="string">"result1："</span>,sess.run(result1))</span><br><span class="line">  print(<span class="string">"result2："</span>,sess.run(result2))</span><br><span class="line">  print(<span class="string">"result3："</span>,sess.run(result3))</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191123095531.png" alt=""></p><p>从结果看，logits里面的值原本加和都是大于1的，但是经过softmax之后，总和变成了1。logits中的第一个是跟标签分类相符的，第二个与标签分类不符，所以第一个的交叉熵比较小，是0.02215518。第二个交叉熵比较大，是3.09967351。</p><p><strong>总结</strong>：</p><blockquote><p>比较scaled和scaled2可以看到： 经过第二次的softmax后， 分布概率会有变化， 而scaled才是我们真实转化的softmax值。 比较rel1和rel2可以看到： 传入softmax_cross_entropy_with_logits的logits是不需要进行softmax的。 如果将softmax后的值scaled传入softmax_cross_entropy_with_ logits就相当于进行了两次的softmax转换。</p></blockquote><p>对于已经用softmax转换过的scaled，在计算loss的时候不能再使用softmax_cross_entropy_with_logits了。应该自己写一个函数，如上面代码的result3。</p><p>下面用一组总和为1但是数组中每个值都不等于0或1的数组来代替标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">labels2=[[<span class="number">0.4</span>,<span class="number">0.1</span>,<span class="number">0.5</span>],[<span class="number">0.3</span>,<span class="number">0.6</span>,<span class="number">0.1</span>]]</span><br><span class="line">result4=tf.nn.softmax_cross_entropy_with_logits(labels=labels2,logits=logits)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"result4："</span>,result4)</span><br><span class="line"><span class="comment">#输出结果</span></span><br><span class="line">result4 [<span class="number">2.1721554</span> <span class="number">2.7696736</span>]</span><br></pre></td></tr></table></figure><p>与前面的result1对比发现，标准的one-hot的结果比较明显。</p><h4 id="sparse交叉熵"><a href="#sparse交叉熵" class="headerlink" title="sparse交叉熵"></a>sparse交叉熵</h4><p>使用sparse_softmax_cross_entropy_with_logits函数的用法，他需要使用非one-hot的标签，所以要把前面的标签换成具体的数值[2,1]。PS：这个labels能不能换成[1,2]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">labels3=[<span class="number">2</span>,<span class="number">1</span>]<span class="comment">#表明labels共有3个类，0、1、2。[2,1]等价于one-hot编码的001与010</span></span><br><span class="line">result5=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels3,logits=logits)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"result5："</span>,result5)</span><br><span class="line"><span class="comment">#输出结果</span></span><br><span class="line">result5 [<span class="number">0.02215516</span> <span class="number">3.0996735</span> ]</span><br></pre></td></tr></table></figure><p>result5与result1完全一样。</p><h3 id="计算loss值"><a href="#计算loss值" class="headerlink" title="计算loss值"></a>计算loss值</h3><p>对于softmax_cross_entropy_with_logits后的结果求loss直接取均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss=tf.reduce_mean(result1)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"loss"</span>,sess.run(loss))</span><br><span class="line"><span class="comment">#输出结果</span></span><br><span class="line"><span class="comment">#loss 1.5609143</span></span><br></pre></td></tr></table></figure><p>对于softmax后的结果，先使用-tf.reduce_sum(labels*tf.log(logits_scaled))，接着求均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss2=tf.reduce_mean(-tf.reduce_sum(labels*tf.log(logits_scaled),<span class="number">1</span>))</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"loss2:"</span>,loss2)</span><br><span class="line"><span class="comment">#输出结果</span></span><br><span class="line"><span class="comment">#loss 1.5609144</span></span><br></pre></td></tr></table></figure><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>梯度下降法是一个最优化算法， 通常也称为最速下降法， 常用于机器学习和人工智能中递归性地逼近最小偏差模型， 梯度下降的方向也就是用负梯度方向为搜索方向， 沿着梯度下降的方向求解极小值。  </p><p>在训练过程中，每次的正向传播后都会得到输出值与真实值的损失值。这个损失值越小越好，代表模型越好。于是梯度下降的算法就用在这里，帮助寻找最小的那个损失值，从而可以反推出对应的学习参数b和w，达到优化模型的效果。</p><p>常用的梯度下降方法可以分为：批量梯度下降、随机梯度下降、小批量梯度下降。</p><p>批量梯度下降：  遍历全部数据集算一次损失函数， 然后算函数对各个参数的梯度和更新梯度。 这种方法每更新一次参数， 都要把数据集里的所有样本看一遍， 计算量大， 计算速度慢， 不支持在线学习，称为batch gradient descent。</p><p>随机梯度下降：每看一个数据就算一下损失函数，然后求梯度更新参数。  这称为stochastic gradient descent， 随机梯度下降。 这个方法速度比较快， 但是收敛性能不太好， 可能在最优点附近晃来晃去， 命中不到最优点。 两次参数的更新也有可能互相抵消， 造成目标函数震荡比较剧烈  </p><p>小批量梯度下降：为了克服上面两种方法的缺点， 一般采用一种折中手段——小批的梯度下降。 这种方法把数据分为若干个批， 按批来更新参数， 这样一批中的一组数据共同决定了本次梯度的方向， 下降起来就不容易跑偏， 减少了随机性。 另一方面因为批量的样本数与整个数据集相比小了很多， 计算量也不是很大。  </p><h3 id="tensorflow中的梯度下降函数"><a href="#tensorflow中的梯度下降函数" class="headerlink" title="tensorflow中的梯度下降函数"></a>tensorflow中的梯度下降函数</h3><p>在tensorflow中是通过一个叫做Optimizer的优化器进行训练优化的。对于不同的优化器，在tensorflow会有不同的类：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191123112610.png" alt=""></p><p>在训练过程中，先实例化一个优化函数，并基于一定的学习率进行梯度优化训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer=tf.train.GradientDescentOptimizer(learning_rate)</span><br></pre></td></tr></table></figure><p>接着使用minimize()操作，接着传入损失值loss到这个操作。优化器就会按照循环的次数一次次沿着loss最小值的方向优化参数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;损失函数&quot;&gt;&lt;a href=&quot;#损失函数&quot; class=&quot;headerlink&quot; title=&quot;损失函数&quot;&gt;&lt;/a&gt;损失函数&lt;/h2&gt;&lt;h3 id=&quot;均值平方差&quot;&gt;&lt;a href=&quot;#均值平方差&quot; class=&quot;headerlink&quot; title=&quot;均值平方差&quot;&gt;
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow中的激活函数和分类函数</title>
    <link href="http://yoursite.com/2019/11/22/Tensorflow%E4%B8%AD%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%92%8C%E5%88%86%E7%B1%BB%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2019/11/22/Tensorflow中的激活函数和分类函数/</id>
    <published>2019-11-22T08:36:54.000Z</published>
    <updated>2019-11-22T12:49:46.543Z</updated>
    
    <content type="html"><![CDATA[<p>关于激活函数，我已经在一篇博客上讲解了它的常见种类和作用，详情点击<a href="[https://brickexperts.github.io/2019/09/03/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/](https://brickexperts.github.io/2019/09/03/激活函数/">激活函数</a>)。这篇博客一起来看下在tensorflow下的激活函数，并补充一些激活函数。顺提一下分类函数。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>激活函数的作用就是用来加入非线性因素的，以解决线性模型表达能力不足的缺陷。常用的激活函数有sigmoid，tanh，relu。</p><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>sigmoid在tensorflow下的对应函数为：</p><p>tf.nn.sigmoid(x,name=None)。从sigmoid的图像来看，随着x趋近正负无穷大，y对应的值越来越接近1或-1，这种情况叫做饱和。处于饱和态的激活函数意味着，当x=100和x=1000时的反映都是一样的，这样的特性转换相当于将1000大于100十倍这个信息丢失了。</p><h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><p>tanh在tensorflow下的对应函数为：</p><p>tf.nn.tanh(x,name=None)。  x取值也是从正无穷到负无穷， 但其对应的y值变为-1～1之间， 相对于Sigmoid函数有更广的值域。  但同样也拥有饱和问题。</p><h3 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h3><p>relu在tensorflow下的对应函数为：</p><p>tf.nn.relu(x,name=None)。该函数非常简单，大于0的留下，否则一律为0。relu函数运算简单，大大提升了机器的运行效率。还有tf.nn.relu6(x,name=None)，这是以6为阈值的relu函数。与relu函数类似的还有softplus函数，二者的区别是：Softplus函数会更加平滑，但是计算量很大。</p><blockquote><p>softplus的函数公式：f(x)=ln(1+e<sup>x</sup>)。在tensorflow中，Softplus函数对应的函数是tf.nn.softplus(x,name=None)</p></blockquote><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122191433.png" alt=""></p><p>虽然ReLU函数在信号响应上有很多优势， 但这仅仅在正向传播方面。 由于其对负值的全部舍去， 因此很容易使模型输出全零从而无法再进行训练。 例如， 随机初始化的w加入值中有个值是负值， 其对应的正值输入值特征也就被全部屏蔽了， 同理， 对应负值输入值反而被激活了。 这显然不是我们想要的结果。 于是在基于ReLU的基础上又演化出了一些变种函数， 举例如下：  </p><blockquote><p>Noise relus：为max中的x加了一个高斯分布的噪声</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122192702.png" alt=""></p><p>Leaky relus：在relu的基础上，保留一部分负值，让x为负时乘a，a小于等于1。也就是Leaky relus对负信号不是一昧的拒绝，而是缩小。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122192303.png" alt=""></p><p>在TensorFlow中， Leaky relus公式没有专门的函数， 不过可以利用现有函数组成而得到：</p><p>tf.maximum(x,leak*x,name=name) #leakl为传入的参数，可以设为0.01等。</p><p>Elus：当x小于0时，做了更复杂的变换。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122192444.png" alt=""></p><p>在tensorflow中，Elus函数对应的函数，tf.nn.elu(x,name=None)</p></blockquote><h3 id="Swish"><a href="#Swish" class="headerlink" title="Swish"></a>Swish</h3><p>Swish函数是谷歌公司发现的一个效果更优于Relu的激活函数。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122194816.png" alt=""></p><p>其中&beta;为x的缩放参数，一般情况默认为1即可。在tensorflow的低版本中，没有单独的Swish函数，可以手动封装。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Swish</span><span class="params">(x,beta=<span class="number">1</span>)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> x*tf.nn.sigmoid(x*beta)</span><br></pre></td></tr></table></figure><h2 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h2><p>对于上面讲的激活函数，其输出值只有两种（0、1，或-1、1，0、x），而现实生活中需要对某一问题进行某种分类，这时就需要使用softmax算法。</p><h3 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h3><p>softmax， 就是如果判断输入属于某一个类的概率大于属于其他类的概率， 那么这个类对应的值就逼近于1， 其他类的值就逼近于0。 该算法的主要应用就是多分类， 而且是互斥的， 即只能属于其中的一个类。 与sigmoid类的激活函数不同的是， 一般的激活函数只能分两类，所以可以理解成Softmax是Sigmoid类的激活函数的扩展。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122201749.png" alt=""></p><p> 把所有值用e的n次方计算出来， 求和后算每个值占的比率， 保证总和为1。一般就可以认为softmax得出的就是概率。</p><p>举个例子， 训练的模型可能推测一张包含9的图片代表数字9的概率是80%， 但是判断它是8的概率是5%（因为8和9都有上半部分相似的小圆） ，判断它代表其他数字的概率值更小。 于是取最大    概率的对应数值， 就是这个图片的分类了。 这是一个softmax回归。  </p><h3 id="常用的分类函数"><a href="#常用的分类函数" class="headerlink" title="常用的分类函数"></a>常用的分类函数</h3><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191122203519.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;关于激活函数，我已经在一篇博客上讲解了它的常见种类和作用，详情点击&lt;a href=&quot;[https://brickexperts.github.io/2019/09/03/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/](https://brick
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>识别图中模糊的手写数字</title>
    <link href="http://yoursite.com/2019/11/21/%E8%AF%86%E5%88%AB%E5%9B%BE%E4%B8%AD%E6%A8%A1%E7%B3%8A%E7%9A%84%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97/"/>
    <id>http://yoursite.com/2019/11/21/识别图中模糊的手写数字/</id>
    <published>2019-11-21T08:57:06.000Z</published>
    <updated>2019-11-25T12:25:16.033Z</updated>
    
    <content type="html"><![CDATA[<p>MNIST是一个入门级的计算机视觉数据集。MNIST数据集的官网是<a href="http://yann.lecun.com/exdb/mnist/，我们可以手动下载数据集。" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/，我们可以手动下载数据集。</a></p><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p>除了上面的手动下载数据集，tensorflow提供了一个库，可以直接用来自动下载MNIST。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"MNIST_data/"</span>,one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>运行上面的代码，会自动下载数据集并将文件解压到当前代码所在同级目录下的MNIST_data文件夹下。</p><p><strong>注意</strong>：代码中的one_hot=True，表示将样本标签转化为one_hot编码。解释one_hot编码，假如一共10类。0的one_hot为1000000000，1的one_hot编码为0100000000，2的one_hot编码为0010000000，等等。只有一个位是1，1所在的位置就代表第几类，从零开始数。</p><p>MNIST数据集中的图片是28x28Pixel，所以，每一幅图就是1行784列的数据，每一个值代表一个像素。</p><p>如果是黑白的图片，图片中的黑色的地方数值为0，有图案的地方数值为0~255之间的数字，代表其颜色的深度。</p><p>如果是彩色的图片，一个像素由三个值表示RGB（红，黄，蓝）。</p><h2 id="显示数据集信息"><a href="#显示数据集信息" class="headerlink" title="显示数据集信息"></a>显示数据集信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"输入数据为："</span>,mnist.train.images)</span><br><span class="line">print(<span class="string">"输入数据打印shape："</span>,mnist.train.images.shape)</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line">im=mnist.train.images[<span class="number">1</span>]</span><br><span class="line">im=im.reshape(<span class="number">-1</span>,<span class="number">28</span>)</span><br><span class="line">pylab.imshow(im)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure><p>运行代码得出结果：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191121201128.png" alt=""></p><p>这是一个55000行、784列的矩阵，即：这个数据集有55000张图片。</p><h2 id="MNIST数据集组成"><a href="#MNIST数据集组成" class="headerlink" title="MNIST数据集组成"></a>MNIST数据集组成</h2><p>在MNIST训练数据集中，mnist.train.images是一个形状为[55000,784]的张量。其中，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0~255之间。</p><p>MNIST数据集里包含三个数据集：训练集、测试集、验证集。训练集用于训练，测试集用于评估训练过程中的准确度，验证集用于评估最终模型的准确度。可使用以下命令查看里面的数据信息</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"测试集的shape："</span>,mnist.test.images.shape)</span><br><span class="line">print(<span class="string">"验证集的shape："</span>,mnist.validation.images.shape)</span><br></pre></td></tr></table></figure><p>运行完上面代码，可以发现在测试数据集里有10000条样本图片，验证集有5000个图片。</p><p>三个数据集还有分别对应的三个标签文件，用来标注每个图片上的数字是几。把图片和标签放在一起，称为“样本”。</p><p>MNIST数据集的标签是介于0～9之间的数字， 用来描述给定图片里表示的数字。标签数据是“one-hot vectors”： 一个one-hot向量，除了某一位的数字是1外， 其余各维度数字都是0。 例如， 标签0将表示为（[1， 0， 0， 0， 0， 0，0， 0， 0， 0， 0]） 。 因此， mnist.train.labels是一个[55000， 10]的数字矩阵。  </p><h2 id="定义变量"><a href="#定义变量" class="headerlink" title="定义变量"></a>定义变量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"MNIST_data/"</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">x=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line"><span class="comment">#标签</span></span><br><span class="line">y=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br></pre></td></tr></table></figure><p>代码中的None，代表此张量的第一个维度可以是任意长度的。</p><h2 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h2><h3 id="定义学习参数"><a href="#定义学习参数" class="headerlink" title="定义学习参数"></a>定义学习参数</h3><p>模型也需要权重值和偏置值，它们被统一称为学习参数。在Tensorflow，使用Variable来定义学习参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W=tf.Variable(tf.random_normal([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b=tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure><h3 id="定义正向传播"><a href="#定义正向传播" class="headerlink" title="定义正向传播"></a>定义正向传播</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred=tf.nn.softmax(tf.matual(x,W)+b)</span><br></pre></td></tr></table></figure><h3 id="定义反向传播"><a href="#定义反向传播" class="headerlink" title="定义反向传播"></a>定义反向传播</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#损失函数</span></span><br><span class="line">cost=tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=<span class="number">1</span>))</span><br><span class="line"><span class="comment">#定义超参数</span></span><br><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line"><span class="comment">#梯度下降</span></span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)</span><br></pre></td></tr></table></figure><p>首先，将正向传播生成的pred与样本标签y进行一次交叉熵的运算，然后取平均值。接着将cost作为一次正向传播的误差，通过梯度下降的优化方法找到能够使这个误差最小化的W和b。整个过程就是不断让损失值变小。因为损失值越小，才能表明输出的结果跟标签数据越接近。</p><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#要把整个训练样本集迭代25次</span></span><br><span class="line">train_epochs=<span class="number">25</span></span><br><span class="line"><span class="comment">#代表在训练过程中一次取100条数据进行训练</span></span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line"><span class="comment">#每训练一次就把具体的中间状态显示出来</span></span><br><span class="line">display_step=<span class="number">1</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="comment">#初始化op</span></span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> range(train_epochs):</span><br><span class="line">    avg_cost=<span class="number">0</span></span><br><span class="line">    total_batch=int(mnist.train.num_examples/batch_size)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">      batch_xs,batch_ys=mnist.train.next_batch(batch_size)</span><br><span class="line">      _,c=sess.run([optimizer,cost],feed_dict=&#123;x:batch_xs,y:batch_ys&#125;)</span><br><span class="line">      avg_cost+=c/total_batch</span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%display_step==<span class="number">0</span>:</span><br><span class="line">      print(<span class="string">"Epoch:"</span>,<span class="string">"%04d"</span> % (epoch+<span class="number">1</span>),<span class="string">"cost="</span>,<span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</span><br><span class="line">  print(<span class="string">"~~~~finish~~~~"</span>)</span><br></pre></td></tr></table></figure><h2 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h2><p>测试错误率的算法是：直接判断预测的结果与真实的标签是否相同，如是相同的就表示是正确的，如是不相同的，就表示是错误的。然后将正确的个数除以总个数，得到的值即为正确率。由于是one-hot编码，这里使用了tf.argmax函数返回one-hot编码中数值为1的哪个元素的下标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试 model</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Accuracy:"</span>, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure><h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><p>在代码的两处区域加入以下代码：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191121221831.png" alt=""></p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191121221920.png" alt=""></p><h2 id="读取模型"><a href="#读取模型" class="headerlink" title="读取模型"></a>读取模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"开始第二个会话"</span>)</span><br><span class="line">print(<span class="string">"Starting 2nd session..."</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># Initialize variables</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># Restore model weights from previously saved model</span></span><br><span class="line">    saver.restore(sess, model_path)</span><br><span class="line">    </span><br><span class="line">     <span class="comment"># 测试 model</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Accuracy:"</span>, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br><span class="line">    </span><br><span class="line">    output = tf.argmax(pred, <span class="number">1</span>)</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">2</span>)</span><br><span class="line">    outputval,predv = sess.run([output,pred], feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">    print(outputval,predv,batch_ys)</span><br><span class="line"></span><br><span class="line">    im = batch_xs[<span class="number">0</span>]</span><br><span class="line">    im = im.reshape(<span class="number">-1</span>,<span class="number">28</span>)</span><br><span class="line">    <span class="comment">#pylab.imshow(im)</span></span><br><span class="line">    <span class="comment">#pylab.show()</span></span><br><span class="line">    plt.imshow(im)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    im = batch_xs[<span class="number">1</span>]</span><br><span class="line">    im = im.reshape(<span class="number">-1</span>,<span class="number">28</span>)</span><br><span class="line">    pylab.imshow(im)</span><br><span class="line">    pylab.show()</span><br></pre></td></tr></table></figure><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"MNIST_data/"</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">x=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">y=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">W=tf.Variable(tf.random_normal([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b=tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"><span class="comment">#正向传播</span></span><br><span class="line">pred=tf.nn.softmax(tf.matmul(x,W)+b)</span><br><span class="line"><span class="comment">#反向传播</span></span><br><span class="line">cost=tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),))</span><br><span class="line">learning_rate=<span class="number">0.001</span></span><br><span class="line"><span class="comment">#梯度下降</span></span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br><span class="line"><span class="comment">#模型保存</span></span><br><span class="line">saver=tf.train.Saver()</span><br><span class="line">model_path=<span class="string">"./model.ckpt"</span></span><br><span class="line">train_epochs=<span class="number">50</span></span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">display_step=<span class="number">1</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="comment">#初始化op</span></span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> range(train_epochs):</span><br><span class="line">    avg_cost=<span class="number">0</span></span><br><span class="line">    total_batch=int(mnist.train.num_examples/batch_size)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">      batch_xs,batch_ys=mnist.train.next_batch(batch_size)</span><br><span class="line">      <span class="comment">#c代表每一个batch_size总的损失</span></span><br><span class="line">      _,c=sess.run([optimizer,cost],feed_dict=&#123;x:batch_xs,y:batch_ys&#125;)</span><br><span class="line">      avg_cost+=c/total_batch</span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%display_step==<span class="number">0</span>:</span><br><span class="line">      print(<span class="string">"Epoch:"</span>,<span class="string">"%04d"</span> % (epoch+<span class="number">1</span>),<span class="string">"cost="</span>,<span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</span><br><span class="line">  print(<span class="string">"~~~~finish~~~~"</span>)</span><br><span class="line">  <span class="comment"># 测试 model</span></span><br><span class="line">  correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">  <span class="comment"># 计算准确率，cast函数用于类型转换</span></span><br><span class="line">  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">  <span class="keyword">print</span> (<span class="string">"Accuracy:"</span>, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br><span class="line">  <span class="comment">#模型保存</span></span><br><span class="line">  save_path = saver.save(sess, model_path)</span><br><span class="line">  print(<span class="string">"Model saved in file: %s"</span> % save_path)</span><br><span class="line">print(<span class="string">"开始第二个会话"</span>)</span><br><span class="line">print(<span class="string">"Starting 2nd session..."</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># Initialize variables</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># Restore model weights from previously saved model</span></span><br><span class="line">    saver.restore(sess, model_path)</span><br><span class="line">    </span><br><span class="line">     <span class="comment"># 测试 model</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Accuracy:"</span>, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br><span class="line">    </span><br><span class="line">    output = tf.argmax(pred, <span class="number">1</span>)</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">2</span>)</span><br><span class="line">    outputval,predv = sess.run([output,pred], feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">    print(outputval,predv,batch_ys)</span><br><span class="line"></span><br><span class="line">    im = batch_xs[<span class="number">0</span>]</span><br><span class="line">    im = im.reshape(<span class="number">-1</span>,<span class="number">28</span>)</span><br><span class="line">    <span class="comment">#pylab.imshow(im)</span></span><br><span class="line">    <span class="comment">#pylab.show()</span></span><br><span class="line">    plt.imshow(im)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    im = batch_xs[<span class="number">1</span>]</span><br><span class="line">    im = im.reshape(<span class="number">-1</span>,<span class="number">28</span>)</span><br><span class="line">    pylab.imshow(im)</span><br><span class="line">    pylab.show()</span><br></pre></td></tr></table></figure><p>第70、71行的代码可以用68、69行的代码代替。pylab库结合了pyplot模块和numpy模块。</p><h2 id="把模糊数字换成我们自己的图片"><a href="#把模糊数字换成我们自己的图片" class="headerlink" title="把模糊数字换成我们自己的图片"></a>把模糊数字换成我们自己的图片</h2><p>研究以下，补。。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;MNIST是一个入门级的计算机视觉数据集。MNIST数据集的官网是&lt;a href=&quot;http://yann.lecun.com/exdb/mnist/，我们可以手动下载数据集。&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://yann.lecu
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="识别数字" scheme="http://yoursite.com/tags/%E8%AF%86%E5%88%AB%E6%95%B0%E5%AD%97/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow的eval用法</title>
    <link href="http://yoursite.com/2019/11/20/tensorflow%E7%9A%84eval%E7%94%A8%E6%B3%95/"/>
    <id>http://yoursite.com/2019/11/20/tensorflow的eval用法/</id>
    <published>2019-11-20T13:23:03.000Z</published>
    <updated>2019-11-20T13:26:25.219Z</updated>
    
    <content type="html"><![CDATA[<p>eval()其实就是tf.Tensor的session.run()的另一种写法。</p><p>1、eval()也是启动计算的一种方式。基于tensorflow基本原理，首先需要定义图，然后计算图，其中计算图的函数有常见的run()函数，如sess.run()，eval()也是类似。</p><p>2、eval()只能用于tf.tensor类对象，也就是有输出的operaton。没有输出的operation，使用session.run()。<br>t.eval() 等价于 tf.get_default_session().run(t)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;eval()其实就是tf.Tensor的session.run()的另一种写法。&lt;/p&gt;
&lt;p&gt;1、eval()也是启动计算的一种方式。基于tensorflow基本原理，首先需要定义图，然后计算图，其中计算图的函数有常见的run()函数，如sess.run()，eval()
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu下安装qt5</title>
    <link href="http://yoursite.com/2019/11/11/ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85qt5/"/>
    <id>http://yoursite.com/2019/11/11/ubuntu下安装qt5/</id>
    <published>2019-11-11T11:45:29.000Z</published>
    <updated>2019-11-19T06:49:11.077Z</updated>
    
    <content type="html"><![CDATA[<p>在官网下载相关文件，<a href="http://download.qt.io/archive/qt/" target="_blank" rel="noopener">官网</a></p><p>我下载的是qt5.11.1版本。点击进入，</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191119142332.png" alt=""></p><p>下载安装程序时需注意，只能下载qt-opensource-linux-x64-5.11.1.run，因为只有这个是在linux环境下的安装程序。新建一个名为Qt5.11.1的文件夹，将这个文件放进去。</p><p>在文件目录下打开终端，输入./run进行安装。接着点击next。可能会有要求填邮箱。点击skip跳过输入邮箱步骤。接下来更改程序安装目录，按照自己的需求修改。之后在select components步骤时，建议Select All。在License Agreement步骤时，选择Qt Installer LGPL Agreement。接着等待。进入安装目录，发现如下内容即为成功安装。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191119144311.png" alt=""></p><p>此时安装完后，仍就无法运行。我们需要安装相应的工具，以使得程序正常运行。</p><blockquote><p>sudo apt-get install gcc g++</p><p>sudo apt-get install libqt4-dev</p><p>sudo apt-get install build-essential</p></blockquote><p>以上内容全部安装完毕，进入目录下的Tools/Qtcreator/bin目录下，在终端输入./qtcreator</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191119144742.png" alt=""></p><p>接下来的使用就要靠各位读者自己摸索和学习了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在官网下载相关文件，&lt;a href=&quot;http://download.qt.io/archive/qt/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官网&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我下载的是qt5.11.1版本。点击进入，&lt;/p&gt;
&lt;p&gt;&lt;img src=
      
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
      <category term="ubuntu" scheme="http://yoursite.com/categories/Linux/ubuntu/"/>
    
    
      <category term="ubuntu" scheme="http://yoursite.com/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>用darknet训练自己的数据</title>
    <link href="http://yoursite.com/2019/11/09/%E7%94%A8darknet%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE/"/>
    <id>http://yoursite.com/2019/11/09/用darknet训练自己的数据/</id>
    <published>2019-11-09T13:53:32.000Z</published>
    <updated>2020-01-06T07:45:55.389Z</updated>
    
    <content type="html"><![CDATA[<p>本篇博客采用darknet训练自己的数据，那么在训练自己的数据之前，我们得先拥有自己数据，怎么得到呢?只能自己做了</p><h2 id="安装labelImg"><a href="#安装labelImg" class="headerlink" title="安装labelImg"></a>安装labelImg</h2><p>我用过精灵标注助手和labelImg两款标注工具，标注后得出得XML不一样。本篇博客采用labelImg工具标注图片。</p><p>环境：python3、ubuntu18.04</p><p><code>sudo apt-get install pyqt5-dev-tools</code><br><code>sudo pip3 install lxml</code></p><p>下载labelImg源码</p><p><code>git clone https://github.com/tzutalin/labelImg.git</code></p><p>进入labelImg目录下</p><p>cd labelImg </p><p>再make qt5py3，建议不要make all。出现下面这种结果即为成功</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110101542.png" alt=""></p><p>然后python3 labelImg.py。出现界面即为成功。woc，这是我最顺利的一次。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110101733.png" alt=""></p><h2 id="制作自己的数据集"><a href="#制作自己的数据集" class="headerlink" title="制作自己的数据集"></a>制作自己的数据集</h2><p>首先进入darknet目录下，再目录下新建文件夹VOC2019，并在VOC2019下新建Annotations，ImageSets，JPEGImages三个文件夹。在ImageSets新建Main文件夹。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110104912.png" alt=""></p><p>将自己的数据集图片放到JPEGImages目录下，将标注文件放到Annotations目录下。接着开始标注数据。过程就随便说以下。[Open Dir]或Ctrl+u选择要标注的图片所在的根目录，[CreateRectBox]或w开始标注，鼠标框选目标区域后选择对应的标签类别,按空格或Ctrl+s保存，[Next Image]或d切换到下一张图片，标注错误的选框可选中后按[Delete]删除。要注意的是，如果不是使用原有的目标检测物体的类别，我们要打开data/predefined_classes.txt，修改默认类别为要检测的类别。</p><p>接着再VOC2019下新建test.py文件，将以下代码拷贝进去。在ImageSets的Maxin文件夹下将生成四个文件：train.txt，val.txt，test.txt，trainval.txt。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">trainval_percent = <span class="number">0.1</span></span><br><span class="line">train_percent = <span class="number">0.9</span></span><br><span class="line">xmlfilepath = <span class="string">'Annotations'</span></span><br><span class="line">txtsavepath = <span class="string">'ImageSets\Main'</span></span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line"></span><br><span class="line">num = len(total_xml)</span><br><span class="line">list = range(num)</span><br><span class="line">tv = int(num * trainval_percent)</span><br><span class="line">tr = int(tv * train_percent)</span><br><span class="line">trainval = random.sample(list, tv)</span><br><span class="line">train = random.sample(trainval, tr)</span><br><span class="line"></span><br><span class="line">ftrainval = open(<span class="string">'ImageSets/Main/trainval.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">ftest = open(<span class="string">'ImageSets/Main/test.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">ftrain = open(<span class="string">'ImageSets/Main/train.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">fval = open(<span class="string">'ImageSets/Main/val.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list:</span><br><span class="line">    name = total_xml[i][:<span class="number">-4</span>] + <span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">        ftrainval.write(name)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">            ftest.write(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fval.write(name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftrain.write(name)</span><br><span class="line"></span><br><span class="line">ftrainval.close()</span><br><span class="line">ftrain.close()</span><br><span class="line">fval.close()</span><br><span class="line">ftest.close()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110123328.png" alt=""></p><p>YOLOV3的label标注的一行五个数分别代表类别（从 0 开始编号）， BoundingBox 中心 X 坐标，中心 Y 坐标，宽，高。这些坐标都是 0～1 的相对坐标。和我们刚才标注的label不同，因此我们需要下面的py文件帮我们转换label。</p><p><code>wget  https://pjreddie.com/media/files/voc_label.py</code></p><p>也可以在windows下好了拷到ubuntu下。总之把这个文件放到darknet文件夹下。打开voc_label.py文件，修改sets和classes。sets如下，classes根据自己的类别需要修改。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110222155.png" alt=""></p><p>打开终端输入<code>python voc_label.py</code>，于是在当前目录生成三个txt文件2019_train.txt，2019_val.txt，2019_test.txt。在VOCdevkit文件夹下的VOC2019也会多生成一个文件夹labels。点开里面的文件就会发现以及转化成YOLOv3需要的格式了。数据集的制作完成，bingo！！！</p><h2 id="局部修改"><a href="#局部修改" class="headerlink" title="局部修改"></a>局部修改</h2><p>1、打开darknet下的cfg文件夹，修改voc.data。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110222652.png" alt=""></p><p>根据自己的需要修改classes类别个数，train和valid的地址。names和backup不用修改。</p><p>2、修改data/voc.names和coco.names。打开对应的文件发现都是原本数据集里的类别，改成自己需求的类别就行。</p><p>3、修改参数文件cfg/yolov3-voc.cfg，用ctrl+f搜 yolo, 总共会搜出3个含有yolo的地方。每个地方都必须要改2处， filters：3*（5+len（classes））和classes类别数。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110223739.png" alt=""></p><p>可修改：random，原本是1，显存小改为0。（是否要多尺度输出。）</p><h2 id="报错-amp-训练"><a href="#报错-amp-训练" class="headerlink" title="报错&amp;训练"></a>报错&amp;训练</h2><p>首先下载darknet53的预训练模型：</p><p><code>wget https://pjreddie.com/media/files/darknet53.conv.74</code></p><p>开始训练：</p><p><code>./darknet detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74</code></p><p>你以为就这样结束了吗？我就知道没怎么简单。又报错了，报错信息如下。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191110144312.png" alt=""></p><p>检查文件和路径，完全正确。</p><p>上网找了解决方案，如下</p><p>下载一个notepad++，打开文件。</p><p>选择 视图 -&gt; 显示符号 -&gt; 显示所有符号；</p><p>选择 编辑 -&gt; 文档格式转换 -&gt; 转换为UNIX（LF）格式；</p><p>转换完成后的格式如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191119145931.png" alt=""></p><p>注：</p><p>1.注意检查最后一行是否有LF标志。</p><p>2.为保证不出错，将所有训练过程中使用到的相关文件都修改。</p><p>我使用了上面的方法，发现我的文件格式本来就是对的。不需要改。那是什么问题呢？后来和一位同学一起瞎改cfg目录下voc.data文件，将train和valid的路径改成如下这样：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191119150418.png" alt=""></p><p>才开始运行。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本篇博客采用darknet训练自己的数据，那么在训练自己的数据之前，我们得先拥有自己数据，怎么得到呢?只能自己做了&lt;/p&gt;
&lt;h2 id=&quot;安装labelImg&quot;&gt;&lt;a href=&quot;#安装labelImg&quot; class=&quot;headerlink&quot; title=&quot;安装label
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="darknet" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/darknet/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu下安装darknet</title>
    <link href="http://yoursite.com/2019/11/09/ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85darknet/"/>
    <id>http://yoursite.com/2019/11/09/ubuntu下安装darknet/</id>
    <published>2019-11-09T12:36:33.000Z</published>
    <updated>2019-11-19T04:57:42.547Z</updated>
    
    <content type="html"><![CDATA[<p>首先下载源码</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">clone</span> <span class="title">https</span>://github.com/pjreddie/darknet.git</span><br><span class="line">cd darknet</span><br></pre></td></tr></table></figure><p>进入darknet目录后，打开Makefile。用到那个将对应的0改为1。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109204621.png" alt=""></p><p>比如我没有GPU，就不用修改GPU为1。但我用到了opencv，将opencv的0改为1。</p><p>编译源码</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">make</span></span><br></pre></td></tr></table></figure><p>测试是否安装成功</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">./darknet</span></span><br></pre></td></tr></table></figure><p>此时看到如下信息即为安装成功。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109205410.png" alt=""></p><p>我在执行这步的时候报错了，报错信息如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109205513.png" alt=""></p><p>解决方案如下，在终端执行下面命令：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="string">/bin/bash</span> -c '<span class="keyword">echo</span> <span class="string">"/usr/local/lib"</span> &gt; <span class="string">/etc/ld.so.conf.d/opencv.conf</span>'</span><br><span class="line">sudo ldconfig</span><br></pre></td></tr></table></figure><p>安装成功后，可以先下载预训练模型测试效果。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> wget https:<span class="comment">//pjreddie.com/media/files/yolov3.weights </span></span><br><span class="line">./darknet detect cfg/yolov3<span class="selector-class">.cfg</span> yolov3<span class="selector-class">.weights</span> data/dog.jpg</span><br></pre></td></tr></table></figure><p>我在这里又报错了，报错信息如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109211403.png" alt=""></p><p>解决方案：sudo apt-get install libcanberra-gtk-module</p><p>再运行一次</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109212322.png" alt=""></p><p>可以看到YOLO的detection图。到这里，YOLOV3已经走通了，是时候加入自己的数据了。 请看下回分解。。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;首先下载源码&lt;/p&gt;
&lt;figure class=&quot;highlight crmsh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="darknet" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/darknet/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu下编译安装opencv</title>
    <link href="http://yoursite.com/2019/11/09/ubuntu%E4%B8%8B%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85opencv/"/>
    <id>http://yoursite.com/2019/11/09/ubuntu下编译安装opencv/</id>
    <published>2019-11-09T11:37:17.000Z</published>
    <updated>2019-11-19T05:21:00.124Z</updated>
    
    <content type="html"><![CDATA[<p>本篇博客使用的ubuntu版本是18.04和opencv3.2</p><p>首先安装CMAKE</p><p><code>sudo apt-get install cmake</code></p><p>接着安装一些依赖项</p><p><code>sudo apt-get install build-essential pkg-config</code></p><p>安装视频I/O包：</p><p><code>sudo apt-get install libgtk2.0-dev  libavcodec-dev libavformat-dev libswscale-dev</code></p><p>安装gtk2.0：</p><p><code>sudo apt-get install libgtk2.0-dev</code></p><p>安装常用图像工具包：</p><p><code>sudo apt-get install libtbb2 libtbb-dev libjpeg-dev libpng12-dev libtiff5-dev libjasper-dev libdc1394-22-dev</code></p><p>如果没有报错，那是最好的。但是我报错了。报错信息如下：</p><p><code>E: Package &#39;libpng12-dev&#39; has no installation candidate</code><br><code>E: Unable to locate package libjasper-dev</code></p><p>上网找了解决方案，首先先解决第一个错：</p><p><code>libpng12-dev</code>在Ubuntu16.04之后就被丢弃了，所以放弃用这个吧。把 <code>libpng12-dev</code> 换成 <code>libpng-dev</code> 就行了</p><p>接着是第二个错误：</p><p><code>sudo add-apt-repository &quot;deb http://security.ubuntu.com/ubuntu xenial-security main&quot;</code><br><code>sudo apt update</code><br><code>sudo apt install libjasper1 libjasper-dev</code></p><p>然后从官网下载源码，直接git clone。也可以从windows拷到虚拟机（要装VM tools）。<a href="https://github.com/opencv/opencv/tree/3.2.0" target="_blank" rel="noopener">网址</a></p><p><code>git clone https://github.com/opencv/opencv.git</code></p><p>在解压后的文件夹中新建build文件夹，用来存放编译文件。</p><p><code>mkdir build</code><br><code>cd build</code></p><p>在电脑上有多个版本的python时，可以通过-D PYTHON_DEFAULT_EXECUTABLE=$(which python3)来确定安装在哪个版本python上。</p><p><code>cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local -D PYTHON_DEFAULT_EXECUTABLE=​\$(which python3) ..</code></p><p>如果执行上面代码没有问题，直接make。接着再执行sudo make install。</p><p>我又报错了。。。。报错信息如下：</p><p> — ICV: Downloading ippicv_linux_20151201.tgz…<br>CMake Error at 3rdparty/ippicv/downloader.cmake:73 (file):<br>file DOWNLOAD HASH mismatch</p><p>for file: [/root/library/opencv/opencv-3.2.0/3rdparty/ippicv/downloads/linux-808b791a6eac9ed78d32a7666804320e/ippicv_linux_20151201.tgz]<br>expected hash: [808b791a6eac9ed78d32a7666804320e]<br>actual hash: [d41d8cd98f00b204e9800998ecf8427e]<br>status: [1;”Unsupported protocol”]</p><p>Call Stack (most recent call first):<br>3rdparty/ippicv/downloader.cmake:110 (_icv_downloader)<br>cmake/OpenCVFindIPP.cmake:243 (include)<br>cmake/OpenCVFindLibsPerf.cmake:37 (include)<br>CMakeLists.txt:558 (include)</p><p>CMake Error at 3rdparty/ippicv/downloader.cmake:77 (message):<br>ICV: Failed to download ICV package: ippicv_linux_20151201.tgz.<br>Status=1;”Unsupported protocol”<br>Call Stack (most recent call first):<br>3rdparty/ippicv/downloader.cmake:110 (_icv_downloader)<br>cmake/OpenCVFindIPP.cmake:243 (include)<br>cmake/OpenCVFindLibsPerf.cmake:37 (include)<br>CMakeLists.txt:558 (include)</p><p>— Configuring incomplete, errors occurred!<br>See also “/root/library/opencv/opencv-3.2.0/build/CMakeFiles/CMakeOutput.log”.<br>See also “/root/library/opencv/opencv-3.2.0/build/CMakeFiles/CMakeError.log”. </p><p>百度一下，这是因为我们在编译opencv的时候需要下载ippicv_linux_20151201.tgz，但是由于网络的原因，经常下载失败。解决方案：</p><p>手动下载ippicv_linux_20151201.tgz，网上都有资源。读者找一下。接着放入相关路径，我的路径是</p><p>home/opencv-3.2.0/3rdparty/ippicv/downloads/linux-808b791a6eac9ed78d32a7666804320e/。读者根据自己的路径放。</p><p>在重新执行cmake。</p><p>接着执行完cmake后，make编译，sudo make install 安装。</p><p>到这里还没装完我们要编译的文件，还有一些模块保留在opencv_contrib的资源库中。所以这个我们也要编译。</p><p>将opencv_contrib下到build的同级目录下，在build目录下打开终端或者在终端进入build目录，</p><p><code>cd  build</code><br><code>cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local -D PYTHON_DEFAULT_EXECUTABLE=$(which python3) -D OPENCV_EXTRA_MODULES_PATH=../opencv_contrib-3.2.0/modules/ ..</code><br><code>make</code><br><code>sudo make install</code></p><p>在终端运行python3，import cv2。没有报错，opencv安装就成功了。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109203044.png" alt=""></p><p>我装过好几次opencv，这是我最顺的一次。。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本篇博客使用的ubuntu版本是18.04和opencv3.2&lt;/p&gt;
&lt;p&gt;首先安装CMAKE&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt-get install cmake&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;接着安装一些依赖项&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt-ge
      
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
      <category term="ubuntu" scheme="http://yoursite.com/categories/Linux/ubuntu/"/>
    
    
      <category term="ubuntu" scheme="http://yoursite.com/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu下装python3和库</title>
    <link href="http://yoursite.com/2019/11/09/ubuntu%E4%B8%8B%E8%A3%85python3/"/>
    <id>http://yoursite.com/2019/11/09/ubuntu下装python3/</id>
    <published>2019-11-09T02:35:36.000Z</published>
    <updated>2019-11-19T05:52:22.773Z</updated>
    
    <content type="html"><![CDATA[<p>ubuntu下的环境配得我要吐了，全都是坑。一定要写博客避坑。后面还有编译opencv、tensorflow等环境。</p><p>本片博客安装的python版本是python3.5。<strong>不用卸载python2，不用卸载python2，不用卸载python2</strong></p><p>首先更新软件包：</p><p><code>sudo apt-get update</code></p><p>接着执行一下命令：</p><p><code>sudo apt-get install python3.5</code></p><p>安装pip3：</p><p><code>sudo apt-get install python3-pip</code></p><p>在这里我就报错了：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109115010.png" alt=""></p><p>上网找了解决方案：</p><p>第一种情况：进程中存在与apt相关的正在运行的进程</p><p>首先检查是否在运行apt，apt-get相关的进程。</p><p> <code>ps aux | grep -i apt</code> </p><p>如果存在与apt相关的正在运行的进程，kill掉</p><p><code>sudo kill -9 &lt;进程号&gt;</code></p><p>或者简单粗暴的直接kill掉：</p><p><code>sudo killall apt apt-get</code></p><p>再执行一次<code>sudo apt-get install python3-pip</code>。如果这还不行，那就是第二种情况了</p><p>第二种情况：</p><p>产生错误的根本原因是lock file。 loack file用于防止两个或多个进程使用相同的数据。 当运行apt或apt-commands时，它会在几个地方创建lock files。 当前一个apt命令未正确终止时，lock file未被删除，因此它们会阻止任何新的apt / apt-get命令实例，比如正在执行apt-get upgrade，在执行过程中直接ctrl+c取消了该操作，很有可能就会造成这种情况。要解决此问题，首先要删除lock file。</p><p>首先使用lsof命令获取持有lock file的进程的ID：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109121205.png" alt=""></p><p>如果三个命令都没有返回值，则说明没有正在运行的进程。如果返回了相应的进程，则需要kill掉。</p><p>接着删除所有的lock file：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109121413.png" alt=""></p><p>最后重新配置一下dpkg：</p><p><code>sudo dpkg --configure -a</code></p><p>到了这一步，没有报错的话，完事大吉。再执行<code>sudo apt-get python3-pip</code></p><p>但是，屋漏偏逢连阴雨。太难了。又报错了</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109121954.png" alt=""></p><p>接着找出正在锁定lock file的进程：</p><p><code>lsof /var/lib/dpkg/lock-frontend</code></p><p>如果上述命令返回进程，kill掉输出的进程。</p><p><code>sudo kill -9 进程号</code></p><p>删除lock file 并重新配置dpkg：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo rm /var/<span class="class"><span class="keyword">lib</span>/<span class="title">dpkg</span>/<span class="title">lock</span>-<span class="title">frontend</span></span></span><br><span class="line">sudo dpkg --configure -a</span><br></pre></td></tr></table></figure><p>再重新配置一下dpkg。</p><p>后面几步的命令集合：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109124103.png" alt=""></p><p>到了这里，就全部完成了。</p><p>接下来安装一些库：</p><p>先安装build依赖包：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191109132649.png" alt=""></p><p>接着就可以安装python库了。</p><p><code>sudo pip3 install numpy</code></p><p>等等一些库</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ubuntu下的环境配得我要吐了，全都是坑。一定要写博客避坑。后面还有编译opencv、tensorflow等环境。&lt;/p&gt;
&lt;p&gt;本片博客安装的python版本是python3.5。&lt;strong&gt;不用卸载python2，不用卸载python2，不用卸载python2&lt;/
      
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
      <category term="ubuntu" scheme="http://yoursite.com/categories/Linux/ubuntu/"/>
    
    
      <category term="ubuntu" scheme="http://yoursite.com/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Yolo算法实战</title>
    <link href="http://yoursite.com/2019/10/31/Yolo%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2019/10/31/Yolo算法实战/</id>
    <published>2019-10-31T12:27:47.000Z</published>
    <updated>2019-11-19T05:00:39.562Z</updated>
    
    <content type="html"><![CDATA[<h2 id="coco介绍"><a href="#coco介绍" class="headerlink" title="coco介绍"></a>coco介绍</h2><p>本次实战采用coco数据集。这个数据集是由微软团队提供的。<a href="http://cocodataset.org/#download" target="_blank" rel="noopener">下载网址</a></p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191031203750.png" alt=""></p><p>annotations是采用json格式标注的，包含三个信息：object instances(物体当前的实例信息)、object keypoints(关键点信息)、image caption(图像信息)</p><p>下图是标注文件的整体结构：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191031210251.png" alt=""></p><p>info是基本信息，image是图像信息，annotations是针对于图像数据的标注信息。下图是除了annotations字段其它字段展开后的具体信息：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191031210505.png" alt=""></p><p>我们要具体关注annotations的信息。annotations信息如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191031211132.png" alt=""></p><p>对于annotations，如果我们标注当前的图片为单个物体或多个物体时我们需要修改iscrowd和segmentation。</p><p>单个object时：</p><blockquote><p>iscrowd=0</p><p>segmentation=polygon</p></blockquote><p>多个objects时：</p><blockquote><p>iscrowd=1</p><p>segmentation=RLE</p></blockquote><h2 id="检测模型的搭建"><a href="#检测模型的搭建" class="headerlink" title="检测模型的搭建"></a>检测模型的搭建</h2><h3 id="Darknet的搭建"><a href="#Darknet的搭建" class="headerlink" title="Darknet的搭建"></a>Darknet的搭建</h3><p>Darknet是一个较为轻型的完全基于C与CUDA的开源深度学习框架。支持CPU和GPU两种计算方式。容易安装，且没有任何依赖项。</p><p> 在windows上我是看这篇博客配好darknet的。<a href="https://blog.csdn.net/lvsehaiyang1993/article/details/81032826" target="_blank" rel="noopener">https://blog.csdn.net/lvsehaiyang1993/article/details/81032826</a> </p><p>注意在使用darknet的时候最后如果出现Couldn’t open file: D:/darknet/data/coco.names。重新下一次zip文件、解压再编译一次。博客中说会有predictions.png文件，我并没有找到。百度是说，电脑内存不够运算。</p><p>后面训练的时候，有报错</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191103104157.png" alt=""></p><p>在网上没有找到解决方案。所以更换了系统再配一次。</p><p>在ubuntu上我配了一次。配得我都吐了，最后还把opencv装到python2上。过程不写了，网上都是。也都不是。坑踩踩就好了。我的博客有教程</p><h3 id="Darknet解读"><a href="#Darknet解读" class="headerlink" title="Darknet解读"></a>Darknet解读</h3><p>下面的部分图片是windows。</p><p>Darknet文件结构：</p><p>src、include、obj：存放了darknet的源码和编译后的文件</p><p>cfg：存放了作者提供好的各种各样的网络配置文件</p><p>打开cfg文件夹下的yolov3.cfg文件，下图网络配置信息的含义。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191102204940.png" alt=""></p><p>接下去的就是主干网络。一组中括号加上网络层的名字定义当前的网络属于哪一层。接着是训练过程中用到的信息。然后就是中括号加上convolutional定义卷积层和卷积层的参数，同样定义了池化层和池化层参数。略过，我们直接看Yolo层</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191102211807.png" alt=""></p><p>接着打开coco.data文件，配置如下：</p><p>在windows下，我没有找到train和valid两个文件列表。linux也没有找到</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191102213118.png" alt=""></p><p>data：存放了接下来用到的数据</p><p>script：存放了一些脚本</p><p>python：存放了darknet编译出来针对于python的接口</p><p>examples：存放了我们可能会用到的函数接口</p><p>backup：存放了模型训练时中间结果。比如说，在训练1000次的时候存一个model，10000次的时候存一个model。这个训练多少次保存一次模型，也是可以修改的。在examples文件夹下的detector.c文件的138行修改。<img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191102164144.png" alt=""></p><p><strong>注意：每次修改darknet配置，都要重新编译。</strong></p><h3 id="Darknet的使用"><a href="#Darknet的使用" class="headerlink" title="Darknet的使用"></a>Darknet的使用</h3><p>安装完darknet后，在终端运行./darknet，</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191103191816.png" alt=""></p><p>在window上运行darknet就行了</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191102164403.png" alt=""></p><p>这句话告诉我们调用darknet来进行模型训练，我们需要采用的格式为./darknet 函数来完成调用。</p><p>在ubuntu进行数据增强：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191103192537.png" alt=""></p><p>在windows上显示不出来。我怀疑是因为我的windows上没有编译运行opencv，编译过后应该可以运行的。大家可以试一下。</p><p>训练命令：</p><p>./darknet detector train cfg/coco.data  cfg/yolov3.cfg  </p><p>采用预训练的模型：</p><p>./darknet detector train cfg/coco.data  cfg/yolov3.cfg  cfg/yolov3_20000.weights</p><p>测试命令：</p><p>./darknet detector test cfg/coco.data  cfg/yolov3.cfg  backup/yolov3_20000.weights data/giraffe.jpg -thresh 0.4</p><p>-thresh用于阈值筛选</p><p>在example下，darknet有提供python的接口。我们也可以利用这个接口完成模型测试。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;coco介绍&quot;&gt;&lt;a href=&quot;#coco介绍&quot; class=&quot;headerlink&quot; title=&quot;coco介绍&quot;&gt;&lt;/a&gt;coco介绍&lt;/h2&gt;&lt;p&gt;本次实战采用coco数据集。这个数据集是由微软团队提供的。&lt;a href=&quot;http://cocodatas
      
    
    </summary>
    
      <category term="目标检测" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="One-stage" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/One-stage/"/>
    
      <category term="Yolo" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/One-stage/Yolo/"/>
    
    
      <category term="Yolo算法" scheme="http://yoursite.com/tags/Yolo%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Yolo系列算法</title>
    <link href="http://yoursite.com/2019/10/29/Yolo-%E7%B3%BB%E5%88%97%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2019/10/29/Yolo-系列算法/</id>
    <published>2019-10-29T01:50:12.000Z</published>
    <updated>2019-11-19T05:57:59.823Z</updated>
    
    <content type="html"><![CDATA[<p>对于目标检测，我们最多到底能检测多少个类别呢？对于Yolo来说，是9000个。这是非常厉害的，所以，接下来看看Yolo的三代算法Yolo v1、Yolo v2、Yolo v3。</p><p>目标检测经历了一个高度的符合人类的直觉的过程。既需要识别出目标的位置，将图片划分成小图片扔进算法中去，当算法认为某物体在这个小区域上之时，那么检测完成。那我们就认为这个物体在这个小图片上了。而这个思路，正是比较早期的目标检测思路，比如R-CNN。后来的Fast R-CNN，Faster R-CNN虽有改进，比如不再是将图片一块块的传进CNN提取特征，而是整体放进CNN提取特征图后，再做进一步处理，但依旧是整体流程分为 ‘区域提取’和‘目标分类’两部分（two-stage），这样做的一个特点是虽然确保了精度，但速度非常慢。而Yolo将物体检测任务当作一个regression（回归）问题来处理，每张图像只需要“看一眼”就能得出图像中都有哪些物体和这些物体的位置。其实Yolo展开就是you only look once。Yolo是One-stage算法。</p><h2 id="Yolo-v1"><a href="#Yolo-v1" class="headerlink" title="Yolo v1"></a>Yolo v1</h2><h3 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h3><p>YOLO v1的核心思想在于将目标检测作为回归问题解决 ，YOLO v1首先会把原始图片放缩到448×448的尺寸，放缩到这个尺寸是为了后面整除来的方便。然后将图片划分成SxS个区域，注意这个区域的概念不同于上文提及将图片划分成N个区域扔进算法的区域不同。上文提及的区域是将图片进行剪裁，或者说把图片的某个局部的像素输入算法中，而这里的划分区域，只的是逻辑上的划分。 </p><p> 如果一个对象的中心落在某个单元格上，那么这个单元格负责预测这个物体。每个单元格需要预测B(超参数)个边界框（bbox）值(bbox值包括坐标和宽高)，同时为每个bbox值预测一个置信度(confidence scores)。此后以每个单元格为单位进行预测分析。</p><p>这个置信度并不只是该边界框是待检测目标的概率，而是该边界框是待检测目标的概率乘上该边界框和真实位置的IoU（框之间的交集除以并集）的积。通过乘上这个交并比，反映出该边界框预测位置的精度。如下式所示：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029112732.png" alt=""></p><p> 每个边界框对应于5个输出，分别是x，y，w，h和置信度。其中x，y代表边界框的中心离开其所在网格单元格边界的偏移。w，h代表边界框真实宽高相对于整幅图像的比例。x，y，w，h这几个参数都已经被限制到了区间[0,1]上。除此以外，每个单元格还产生C个概率(有多少类物体，C就是多少)。<strong>注意，我们不管B的大小，每个单元格只产生一组这样的概率。</strong> </p><p>然后我们让每个网格预测的class信息和bounding box预测的confidence信息相乘，就得到每个bounding box的class-specific confidence score: </p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029143235.png" alt=""></p><p>P(Class<sub>i</sub>)就是每个网络预测的类别信息。 这个乘积即encode了预测的box属于某一类的概率，也有该box准确度的信息。 得到每个box的class-specific confidence score以后，设置阈值，滤掉得分低的boxes，对保留的boxes进行NMS处理，就得到最终的检测结果。</p><h3 id="网络模型架构"><a href="#网络模型架构" class="headerlink" title="网络模型架构"></a>网络模型架构</h3><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029143846.png" alt=""></p><p> 网络结构借鉴了 GoogLeNet 。24个卷积层，2个全连接层。 </p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>YOLO v1全部使用了均方差（mean squared error）作为损失（loss）函数。由三部分组成：坐标误差、IOU误差和分类误差。</p><p>考虑到每种loss的贡献率，YOLO v1给坐标误差（coordErr）设置权重λcoord=5。在计算IoU误差时，包含物体的格子与不包含物体的格子（此处的‘包含’是指存在一个物体，它的中心坐标落入到格子内），二者的IOU误差对网络loss的贡献值是不同的。若采用相同的权值，那么不包含物体的格子的置信度值近似为0，变相放大了包含物体的格子的置信度误差，在计算网络参数梯度时的影响。为解决这个问题，YOLO 使用λnoobj（置信度误差）=0.5修正iouErr。</p><p> 对于相等的误差值，大物体误差对检测的影响应小于小物体误差对检测的影响。这是因为，相同的位置偏差占大物体的比例远小于同等偏差占小物体的比例。YOLO将物体大小的信息项（w和h）进行求平方根来改进这个问题，但并不能完全解决这个问题。 </p><p>所以，Loss计算公式：                                                              PS：连数学符号都没认全，我太难了</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029145518.png" alt=""></p><p>后面看别人的博客，才知道公式意思如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029151345.png" alt=""></p><p>在激活函数上：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029144700.png" alt=""></p><p> 在最后一层使用的是标准的线性激活函数，其他的层都使用leaky rectified 线性激活函数。 </p><h2 id="Yolo-v2-Yolo-9000"><a href="#Yolo-v2-Yolo-9000" class="headerlink" title="Yolo v2/Yolo 9000"></a>Yolo v2/Yolo 9000</h2><p>YOLO v1对于bounding box的定位不是很好，在精度上比同类网络还有一定的差距，所以YOLOv2对于速度和精度做了很大的优化，并且吸收了同类网络的优点，一步步做出尝试。</p><p>YOLO v2在v1基础上做出改进后提出。其受到Faster RCNN方法的启发，引入了anchor（先验框）。同时使用了K-Means方法，对anchor数量进行了讨论，在精度和速度之间做出折中。并且修改了网络结构，去掉了全连接层，改成了全卷积结构。在训练时引入了世界树（WordTree）结构，将检测和分类问题做成了一个统一的框架，并且提出了一种层次性联合训练方法，将ImageNet分类数据集和COCO检测数据集同时对模型训练。</p><h3 id="预测更准确"><a href="#预测更准确" class="headerlink" title="预测更准确"></a>预测更准确</h3><h4 id="batch-normalization"><a href="#batch-normalization" class="headerlink" title="batch normalization"></a>batch normalization</h4><p>YOLOv2对每批数据都做了一个归一化预处理。通过在每一个卷积层后添加batch normalization，极大的改善了收敛速度同时减少了对其它正则方法的依赖（Yolo v2不在使用dropout），使得mAP获得了提升。（mAP：平均精度均值（mean Average Precision））</p><p> 通常，一次训练会输入一批样本（batch）进入神经网络。批规一化在神经网络的每一层，在网络（线性变换）输出后和激活函数（非线性变换）之前增加一个批归一化层（BN），BN层进行如下变换：①对该批样本的各特征量（对于中间层来说，就是每一个神经元）分别进行归一化处理，分别使每个特征的数据分布变换为均值0，方差1。从而使得每一批训练样本在每一层都有类似的分布。这一变换不需要引入额外的参数。②对上一步的输出再做一次线性变换，假设上一步的输出为Z，则Z1=γZ + β。这里γ、β是可以训练的参数。增加这一变换是因为上一步骤中强制改变了特征数据的分布，可能影响了原有数据的信息表达能力。增加的线性变换使其有机会恢复其原本的信息。 </p><h4 id="使用高分辨率图像"><a href="#使用高分辨率图像" class="headerlink" title="使用高分辨率图像"></a>使用高分辨率图像</h4><p>YOLOv1在分辨率为224×224的图片上进行预训练，在正式训练时将分辨率提升到448×448，这需要模型去适应新的分辨率。但是YOLOv2是直接使用448×448的输入， 所以YOLO2在采用 224*224 图像进行分类模型预训练后，再采用 448*448 的高分辨率样本对分类模型进行微调（10个epoch），使网络特征逐渐适应 448*448 的分辨率。然后再使用 448*448 的检测样本进行训练，缓解了分辨率突然切换造成的影响。 </p><h4 id="采用先验框anchor"><a href="#采用先验框anchor" class="headerlink" title="采用先验框anchor"></a>采用先验框anchor</h4><p>在预测框的数量上，由于YOLOv2将网络的输入分辨率调整到416×416，下采样率为32，多次卷积后得到13×13的特征图（feature map）。在这上面使用9种anchor boxes，得到13×13×9=1521个，这比YOLOv1大多了。PS：我也不知道为什么突然就变416了？</p><p>YOLOv1利用全连接层的数据完成边框的预测，会导致丢失较多的空间信息，使定位不准。在YOLOv2中作者借鉴了Faster R-CNN中的anchor思想，来改善全连接层带来的影响。</p><p>Anchor是RPN（region proposal network）网络在Faster R-CNN中的一个关键步骤，是在卷积特征图上进行滑窗操作，每一个中心可以预测9种不同大小的候选框。</p><p>为了引入anchor boxes来预测候选框，作者在网络中去掉了全连接层。并去掉了最后的一个池化层以确保输出的卷积特征图有更高的分辨率。然后，通过缩减网络，让图片输入分辨率为416 * 416，目的是为了让后面产生的卷积特征图宽高都为奇数，这样就可以产生一个中心框（center cell）。YOLO算法的作者观察到，大物体通常占据了图像的中间位置，可以只用中心的一个框来预测这些物体的位置，否则就要用中间的4个格子来进行预测，这个技巧可稍稍提升效率。最后，YOLOv2使用了卷积层降采样（采样因子为32），使得输入卷积网络的416 * 416图片最终得到13 * 13的卷积特征图（416/32=13）</p><h4 id="聚类提取先验框尺度。"><a href="#聚类提取先验框尺度。" class="headerlink" title="聚类提取先验框尺度。"></a>聚类提取先验框尺度。</h4><p>使用anchor的时候，anchor boxes的宽和高往往是人工选定的。虽然在训练过程中，网络也会调整宽和高。但一开始就选择了更好的宽和高，网络就更容易得到准确的预测位置。为了使网络更易学到准确的预测位置，作者使用了K-means聚类方法类训练bounding boxes，可以自动找到更好的框宽高维度。传统的K-means聚类方法使用的是欧氏距离函数，也就意味着较大的框会比较小的框产生更多的误差，聚类结果可能会偏离。为此，作者采用IOU得分作为评价标准，这样的话，误差就和框的尺度无关。最终的距离函数为：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029224241.png" alt=""></p><p>centroid是聚类时被选作中心的边框，box就是其它边框，d就是两者间的“距离”。IOU越大，“距离”越近。YOLO2给出的聚类分析结果如下图所示： </p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029224317.png" alt=""></p><p>上图左边是选择不同的聚类k值情况下，得到的k个centroid边框，计算样本中标注的边框与各centroid的Avg IOU。显然，边框数k越多，Avg IOU越大。YOLO2选择k=5作为边框数量与IOU的折中。对比手工选择的先验框，使用5个聚类框即可达到61 Avg IOU，相当于9个手工设置的先验框60.9 Avg IOU。 </p><h4 id="约束预测边框的位置"><a href="#约束预测边框的位置" class="headerlink" title="约束预测边框的位置"></a>约束预测边框的位置</h4><p> 借鉴于Faster RCNN的先验框方法，在训练的早期阶段，其位置预测容易不稳定。其位置预测公式为： </p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030172721.png" alt=""></p><p>其中，x，y是预测边框的中心，x<sub>a</sub>，y<sub>a</sub>是先验框(anchor)的中心点坐标，&omega;<sub>a</sub>，h<sub>a</sub>是先验框(anchor)的宽和高，t<sub>x</sub>，t<sub>y</sub>是要学习的参数。在Yolo论文中写的是x=(t<sub>x</sub>*&omega;<sub>a</sub>)-x<sub>a</sub>，根据Faster RCNN，应该是“+”。</p><p>由于t<sub>x</sub>，t<sub>y</sub>的取值没有任何约束，因此预测边框的中心可能出现在任何位置，导致训练早期阶段不容易稳定。Yolo 调整了预测公式，将预测边框的中心约束在特定的grid网格内。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030193343.png" alt=""></p><p>其中，b<sub>x</sub>、b<sub>y</sub>、b<sub>w</sub>、b<sub>h</sub>是预测边框的中心和宽高。Pr(object) * IOU(b,object)是预测边框的置信度，Yolo v1是直接预测置信度的值，这里对预测参数t<sub>0</sub>进行&sigma;(sigmoid)变换后作为置信度的值。c<sub>x</sub>，c<sub>y</sub>是当前网格左上角的距离，要先将网格大小归一化，即令一个网格的宽=1，高=1。p<sub>w</sub>，p<sub>h</sub>是先验框的宽和高。t<sub>x</sub>、t<sub>y</sub>、t<sub>w</sub>、t<sub>h</sub>、t<sub>o</sub>是要学习的参数，分别用于预测边框的中心和宽高，以及置信度。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030195154.png" alt=""></p><p>参考上图，由于σ函数将t<sub>x</sub>、t<sub>y</sub>约束在(0,1)范围内，所以根据上面的计算公式，预测边框的蓝色中心点被约束在蓝色背景的网格内。约束边框位置使得模型更容易学习，且预测更为稳定。 </p><h4 id="passthrough层检测细粒度特征"><a href="#passthrough层检测细粒度特征" class="headerlink" title="passthrough层检测细粒度特征"></a>passthrough层检测细粒度特征</h4><p>对象检测面临的一个问题是图像中对象会有大有小，输入图像经过多层网络提取特征，最后输出的特征图中（比如YOLO2中输入416*416经过卷积网络下采样最后输出是13*13），较小的对象可能特征已经不明显甚至被忽略掉了。为了更好的检测出一些比较小的对象，最后输出的特征图需要保留一些更细节的信息。</p><p>YOLO2引入一种称为passthrough层的方法在特征图中保留一些细节信息。具体来说，就是在最后一个pooling之前，特征图的大小是26*26*512，将其1拆4，直接传递（passthrough）到pooling后（并且又经过一组卷积）的特征图，两者叠加到一起作为输出的特征图。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030200424.png" alt=""></p><p>一拆4是什么拆的呢？举个例子，如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/7baff56b-42aa-31db-8db5-768957bdec3f.jpg" alt=""></p><p>还有其它拆法。就不具述了。</p><h4 id="多尺度图像训练"><a href="#多尺度图像训练" class="headerlink" title="多尺度图像训练"></a>多尺度图像训练</h4><p> 因为去掉了全连接层，YOLO2可以输入任何尺寸的图像。因为整个网络下采样倍数是32，作者采用了{320,352,…,608}等10种输入图像的尺寸，这些尺寸的输入图像对应输出的特征图宽和高是{10,11,…19}。训练时每10个batch就随机更换一种尺寸，使网络能够适应各种大小的对象检测。 </p><h3 id="速度更快"><a href="#速度更快" class="headerlink" title="速度更快"></a>速度更快</h3><p>大多数目标检测的框架是建立在VGG-16上的。为了进一步提升速度，Yolo v2提出了Darknet-19网络结构。Darknet-19(19层卷积层和5层池化层)比VGG-16小一些，精度不弱于VGG-16，但浮点运算量减少到约1/5。</p><p> YOLO2的训练主要包括三个阶段。第一阶段就是先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为 224*224 ，共训练160个epochs。然后第二阶段将网络的输入调整为 448*448 ，继续在ImageNet数据集上finetune分类模型，训练10个epochs。第三个阶段就是修改Darknet-19分类模型为检测模型，移除最后一个卷积层、global avgpooling层以及softmax层，并且新增了三个 3*3*1024卷积层，同时增加了一个passthrough层，最后使用 1<em>1 卷积层输出预测结果，输出的channels数为：**num_anchors\</em>(5+num_classes)** ，和训练采用的数据集有关系。对于VOC数据集(20种分类对象)，假如anchor数为5，输出的channels就是125。</p><h3 id="识别对象更多"><a href="#识别对象更多" class="headerlink" title="识别对象更多"></a>识别对象更多</h3><p>论文提出了一种联合训练的机制：使用识别数据集训练模型识别相关部分，使用分类数据集训练模型分类相关部分。</p><p>众多周知，检测数据集的标注要比分类数据集打标签繁琐的多，所以ImageNet分类数据集比VOC等检测数据集高出几个数量级。所以在YOLOv1中，边界框的预测其实并不依赖于物体的标签，YOLOv2实现了在分类和检测数据集上的联合训练。对于检测数据集，可以用来学习预测物体的边界框、置信度以及为物体分类，而对于分类数据集可以仅用来学习分类，但是其可以大大扩充模型所能检测的物体种类。</p><p>作者选择在COCO和ImageNet数据集上进行联合训练，遇到的第一问题是两者的类别并不是完全互斥的，比如”Norfolk terrier”明显属于”dog”，所以作者提出了一种层级分类方法（Hierarchical classification），根据各个类别之间的从属关系（根据WordNet）建立一种树结构WordTree，结合COCO和ImageNet建立的词树（WordTree）如下图所示：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191029195823.png" alt=""></p><p>WordTree中的根节点为”physical object”，每个节点的子节点都属于同一子类，可以对它们进行softmax处理。在给出某个类别的预测概率时，需要找到其所在的位置，遍历这个路径，然后计算路径上各个节点的概率之积。</p><p>在训练时，如果是检测样本，按照YOLOv2的loss计算误差，而对于分类样本，只计算分类误差。在预测时，YOLOv2给出的置信度就是  ，同时会给出边界框位置以及一个树状概率图。在这个概率图中找到概率最高的路径，当达到某一个阈值时停止，就用当前节点表示预测的类别。</p><h2 id="Yolo-v3"><a href="#Yolo-v3" class="headerlink" title="Yolo v3"></a>Yolo v3</h2><p>YOLO v3没有太多的创新，主要是借鉴一些好的方案融合到YOLO里面。不过效果还是不错的，在保持速度优势的前提下，提升了预测精度，尤其是加强了对小物体的识别能力。</p><h3 id="新的网络结构"><a href="#新的网络结构" class="headerlink" title="新的网络结构"></a>新的网络结构</h3><p>在基本的图像特征提取方面，Yolo v3采用了称之为Darknet-53的网络结构(含有53个卷积层)，它借鉴了残差网络residual network的做法，在一些层之间设置了快捷链路(shortcut connections)。</p><h3 id="利用多尺度特征进行对象预测"><a href="#利用多尺度特征进行对象预测" class="headerlink" title="利用多尺度特征进行对象预测"></a>利用多尺度特征进行对象预测</h3><p>YOLO2曾采用passthrough结构来检测细粒度特征，在YOLO3更进一步采用了3个不同尺度的特征图来进行对象检测。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030221243.png" alt=""></p><p>结合上图看，卷积网络在79层后，经过下方几个黄色的卷积层得到一种尺度的检测结果。相比输入图像，这里用于检测的特征图有32倍的下采样。比如输入是416*416的话，这里的特征图就是13*13了。由于下采样倍数高，这里特征图的感受野比较大，因此适合检测图像中尺寸比较大的对象。</p><p>为了实现细粒度的检测，第79层的特征图又开始作上采样（从79层往右开始上采样卷积），然后与第61层特征图融合（Concatenation），这样得到第91层较细粒度的特征图，同样经过几个卷积层后得到相对输入图像16倍下采样的特征图。它具有中等尺度的感受野，适合检测中等尺度的对象。</p><p>最后，第91层特征图再次上采样，并与第36层特征图融合（Concatenation），最后得到相对输入图像8倍下采样的特征图。它的感受野最小，适合检测小尺寸的对象。</p><h3 id="9种尺度的先验框"><a href="#9种尺度的先验框" class="headerlink" title="9种尺度的先验框"></a>9种尺度的先验框</h3><p>随着输出的特征图的数量和尺度的变化，先验框的尺寸也需要相应的调整。YOLO2已经开始采用K-means聚类得到先验框的尺寸，YOLO3延续了这种方法，为每种下采样尺度设定3种先验框，总共聚类出9种尺寸的先验框。在COCO数据集这9个先验框是：(10x13)，(16x30)，(33x23)，(30x61)，(62x45)，(59x119)，(116x90)，(156x198)，(373x326)。</p><p>分配上，在最小的13*13特征图上（有最大的感受野）应用较大的先验框(116x90)，(156x198)，(373x326)，适合检测较大的对象。中等的26*26特征图上（中等感受野）应用中等的先验框(30x61)，(62x45)，(59x119)，适合检测中等大小的对象。较大的52*52特征图上（较小的感受野）应用较小的先验框(10x13)，(16x30)，(33x23)，适合检测较小的对象。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030221659.png" alt=""></p><p>感受一下9种先验框的尺寸，下图中蓝色框为聚类得到的先验框。黄色框式ground truth，红框是对象中心点所在的网格。 </p><p>13*13:</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030222109.png" alt=""></p><p>26*26:</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030222209.png" alt=""></p><p>52*52:</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030222240.png" alt=""></p><h2 id="对象分类softmax改成logistic"><a href="#对象分类softmax改成logistic" class="headerlink" title="对象分类softmax改成logistic"></a><strong>对象分类softmax改成logistic</strong></h2><p>预测对象类别时不使用softmax，改成使用logistic的输出进行预测。这样能够支持多标签对象（比如一个人有Woman 和 Person两个标签）。</p><h2 id="输入映射到输出"><a href="#输入映射到输出" class="headerlink" title="输入映射到输出"></a>输入映射到输出</h2><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191030223023.png" alt=""></p><p>不考虑神经网络结构细节的话，总的来说，对于一个输入图像，YOLO3将其映射到3个尺度的输出张量，代表图像各个位置存在各种对象的概率。</p><p>我们看一下YOLO3共进行了多少个预测。对于一个416*416的输入图像，在每个尺度的特征图的每个网格设置3个先验框，总共有 13*13*3 + 26*26*3 + 52*52*3 = 10647 个预测。每一个预测是一个(4+1+80)=85维向量，这个85维向量包含边框坐标（4个数值），边框置信度（1个数值），对象类别的概率（对于COCO数据集，有80种对象）。</p><p>对比一下，YOLO2采用13*13*5 = 845个预测，YOLO3的尝试预测边框数量增加了10多倍，而且是在不同分辨率上进行，所以mAP以及对小物体的检测效果有一定的提升。</p><p>本篇文章使用了较多的他人的图片，如有侵权，请联系我删掉。QQ：1171708687</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于目标检测，我们最多到底能检测多少个类别呢？对于Yolo来说，是9000个。这是非常厉害的，所以，接下来看看Yolo的三代算法Yolo v1、Yolo v2、Yolo v3。&lt;/p&gt;
&lt;p&gt;目标检测经历了一个高度的符合人类的直觉的过程。既需要识别出目标的位置，将图片划分成
      
    
    </summary>
    
      <category term="目标检测" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="One-stage" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/One-stage/"/>
    
      <category term="Yolo" scheme="http://yoursite.com/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/One-stage/Yolo/"/>
    
    
      <category term="Yolo算法" scheme="http://yoursite.com/tags/Yolo%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
