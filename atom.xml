<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>DY的个人博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-03-16T03:51:09.096Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>湛蓝星空</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>高效寻找开源项目</title>
    <link href="http://yoursite.com/2020/03/16/%E9%AB%98%E6%95%88%E5%AF%BB%E6%89%BE%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    <id>http://yoursite.com/2020/03/16/高效寻找开源项目/</id>
    <published>2020-03-16T03:04:39.000Z</published>
    <updated>2020-03-16T03:51:09.096Z</updated>
    
    <content type="html"><![CDATA[<p>今天我们来讲一下如何在github上高效的寻找适合自己的开源项目</p><p>首先，我们来明确一下github的一些因素。随便打开一个项目，如下所示：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200316112254.png" alt=""></p><p>上面的红框都是一些搜索的标准，还有star和fork数表明这个项目是否火热，也是搜索的标准</p><p>比如，我们在自学了python的Djange后，打算在github找小项目练练手，我们就直接在搜索框打Django，如下</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200316113214.png" alt=""></p><p>接着发现项目非常的多。那怎么搜索名字里面包含Django的呢？用in:name Django</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200316113405.png" alt=""></p><p>我们就可以找出名字里面包含Django的项目了。</p><p>然后我们还可以用项目的火热程度对我们寻找的项目划分范围：stars:&gt;3000</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200316113638.png" alt=""></p><p>star数小于3000的项目就被过滤掉了。fork同理</p><p>当然我们还可以在描述里搜也可以在readme里搜。同时我们还可以限制语言(language)和更新时间(pushed)</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200316114547.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天我们来讲一下如何在github上高效的寻找适合自己的开源项目&lt;/p&gt;
&lt;p&gt;首先，我们来明确一下github的一些因素。随便打开一个项目，如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/Brickexpe
      
    
    </summary>
    
      <category term="git和github" scheme="http://yoursite.com/categories/git%E5%92%8Cgithub/"/>
    
    
      <category term="github" scheme="http://yoursite.com/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>GAN介绍</title>
    <link href="http://yoursite.com/2020/03/06/GAN%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2020/03/06/GAN介绍/</id>
    <published>2020-03-06T00:49:56.000Z</published>
    <updated>2020-03-06T02:01:43.822Z</updated>
    
    <content type="html"><![CDATA[<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>对抗神经网络其实是两个网络的组合，可以理解为一个网络生成模拟数据，另一个网络判断生成的数据是真实的还是模拟的。生成模拟数据的网络要不断优化自己让判别网络判断不出来，判别网络也要优化自己让自己判断得更准确。二者形成对抗，故称为对抗神经网络（GAN）。</p><h2 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h2><p>GAN由generator(生成式模型)和discriminator(判别式模型)两部分组成</p><p> generator：主要是从训练数据中产生相同分布得samples，对于输入x，类别标签y，在生成式模型中估计器联合概率分布</p><p>discriminator：判断输入是真实数据还是generator生成的数据，采用的是监督学习方法</p><p>上面两个模型结合后，经过大量次数的迭代训练会使generator尽可能模拟出以假乱真的样本，而discriminator会有更精确的鉴别真伪数据的能力，最后会达到纳什均衡，也就是discriminator对于generator的数据鉴别结果为正确率和错误率各占50%。</p><p>如下图：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200306092909.png" alt=""></p><p>生成式模型又叫生成器。他先用一个随机编码向量来输出一个模拟样本</p><p>判别式模型又叫判别器，它的输入是一个样本（可以是真实样本，也可以是模拟样本），输出一个判断该样本是样本是真样本还是模拟样本的结果</p><p>监督学习神经网络就属于discriminator，只需要学习generator。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;原理&quot;&gt;&lt;a href=&quot;#原理&quot; class=&quot;headerlink&quot; title=&quot;原理&quot;&gt;&lt;/a&gt;原理&lt;/h2&gt;&lt;p&gt;对抗神经网络其实是两个网络的组合，可以理解为一个网络生成模拟数据，另一个网络判断生成的数据是真实的还是模拟的。生成模拟数据的网络要不断优化自
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="对抗神经网络" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>理解各种熵</title>
    <link href="http://yoursite.com/2020/03/03/%E7%90%86%E8%A7%A3%E5%90%84%E7%A7%8D%E7%86%B5/"/>
    <id>http://yoursite.com/2020/03/03/理解各种熵/</id>
    <published>2020-03-03T03:56:25.000Z</published>
    <updated>2020-04-10T07:02:49.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p>假设随机从口袋取硬币，口袋里有各一个蓝色的、红色的、绿色的、橘色的硬币。我们的目标是：问最少的问题，得到正确的答案。如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303143547.png" alt=""></p><p>每个硬币都有1/4的概率被选中，1/4(概率)*2(问题个数)<em>4(球的数量)=2。平均需要问两道题才能找出不同颜色的球，也就是说期望值是2，也叫做<em>*信息熵</em></em>。</p><p>如果改变一下上个例子，变成袋子中1/8的硬币是绿色的，1/8的是橘色的，1/4是红色的，1/2是蓝色的。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303144317.png" alt=""></p><p>蓝色硬币概率为1/2，所以只需要一个问题就知道是还是不是蓝色，红色硬币概率为1/4，需要两个问题，以此类推，橘色和绿色硬币需要3个问题。所以，信息熵=期望=1/2x1+1/4x2+1/8x3+1/8x3=1.75</p><p>所以，问题个数的期望是：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303150107.png" alt=""></p><p> 这个式子就是<strong>信息熵</strong>的表达式。也可以写作：<img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303162354.png" alt=""></p><p>简单来说, 其意义就是<strong>在最优化策略下, 猜到颜色所需要的问题的个数。熵代表的是随机变量或整个系统的不确定性，信息熵越大，随机变量或系统的不确定性就越大。</strong></p><h2 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h2><p>从信息熵公式可得，<strong>随机变量的取值个数越多，状态数也就越多，信息熵就越大，混乱程度就越大</strong>。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303172821.png" alt=""></p><h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>口袋还是1/8的硬币是绿色的，1/8的是橘色的，1/4是红色的，1/2是蓝色的，但是换一个策略：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303151023.png" alt=""></p><p>需要问的问题数=1/8x2+1/8x2+1/4x2+1/4x2=2。2就是这个策略的交叉熵，而最优策略的交叉熵是1.75。而1/8概率橘色硬币和1/2概率的蓝色硬币一样，都是需要两个问题得到颜色。也就是说，小球的分布为(1/4,1/4,1/4,1/4)，这个分布就是非真实分布</p><p>给定一个策略，交叉熵就是在该策略下猜中颜色所需要的问题的期望值。<strong>交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。</strong>交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案，越优的策略，交叉熵越低，具有最低的交叉熵策略就是最优的策略。而在此时，交叉熵=信息熵。因此，我们通常需要最小化交叉熵，也间接证明了我们的算法所算出的非真实分布接近真实分布。交叉熵也叫对数似然</p><p>交叉熵公式：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303164523.png" alt=""></p><h2 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h2><p>条件熵H(Y|X)表示在已知随机变量X的条件下随机变量Y的不确定性。条件熵H(Y|X)定义为X给定条件下Y的条件概率分布的熵对X的数学期望。条件熵也被称为信息增益，信息增益越大，特征表现越好。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303171644.png" alt=""></p><p>条件熵(Y|X)等于联合熵H(X,Y)减去单独的熵H(X)，H(Y|X)=H(X,Y)-H(X)。</p><h2 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h2><p>相对熵又称为KL散度，它表示2个函数或概率分布的差异性：差异越大则相对熵越大，差异越小则相对熵越小。设p为概率分布，q为另一分布</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200303171137.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;信息熵&quot;&gt;&lt;a href=&quot;#信息熵&quot; class=&quot;headerlink&quot; title=&quot;信息熵&quot;&gt;&lt;/a&gt;信息熵&lt;/h2&gt;&lt;p&gt;假设随机从口袋取硬币，口袋里有各一个蓝色的、红色的、绿色的、橘色的硬币。我们的目标是：问最少的问题，得到正确的答案。如下：&lt;/p&gt;

      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>自编码综合实现</title>
    <link href="http://yoursite.com/2020/02/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%BB%BC%E5%90%88%E5%AE%9E%E7%8E%B0/"/>
    <id>http://yoursite.com/2020/02/29/自编码综合实现/</id>
    <published>2020-02-29T11:28:18.000Z</published>
    <updated>2020-03-02T11:57:26.949Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h2><p>自编码常用方法：代替和级联</p><p>栈式自编码会将网络中的中间层作为下一个网络的输入进行训练，我们可以得到网络中每一个中间层的原始值，为了能有更好的效果，还可以使用级联的方式进一步优化网络参数。在已有的模型上接着优化参数的步骤习惯上成为“微调”。但是通常在大量已标注训练数据的情况下使用。在这样的情况下，微调能显著提升分类器性能。但如果有大量未标注数据，”微调“作用有限</p><h2 id="去噪-栈式"><a href="#去噪-栈式" class="headerlink" title="去噪+栈式"></a>去噪+栈式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"/data/"</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line">train_X=mnist.train.images</span><br><span class="line">train_Y=mnist.train.labels</span><br><span class="line">test_X=mnist.train.images</span><br><span class="line">test_Y=mnist.train.labels</span><br><span class="line"></span><br><span class="line">n_input=<span class="number">784</span></span><br><span class="line">n_hidden_1=<span class="number">256</span></span><br><span class="line">n_hidden_2=<span class="number">128</span></span><br><span class="line">n_classes=<span class="number">10</span></span><br><span class="line"></span><br><span class="line">x=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_input])</span><br><span class="line">y=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_input])</span><br><span class="line">dropout_keep_prob=tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line">l2x=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_hidden_1])</span><br><span class="line">l2y=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_hidden_1])</span><br><span class="line">l3x=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_hidden_2])</span><br><span class="line">l3y=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_classes])</span><br><span class="line"></span><br><span class="line">weights=&#123;</span><br><span class="line">    <span class="string">"h1"</span>:tf.Variable(tf.random_normal([n_input,n_hidden_1])),</span><br><span class="line">    <span class="string">"l1_h2"</span>:tf.Variable(tf.random_normal([n_hidden_1,n_hidden_1])),</span><br><span class="line">    <span class="string">"l1_out"</span>:tf.Variable(tf.random_normal([n_hidden_1,n_input])),</span><br><span class="line">    </span><br><span class="line">    <span class="string">"l2_h1"</span>:tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),</span><br><span class="line">    <span class="string">"l2_h2"</span>:tf.Variable(tf.random_normal([n_hidden_2,n_hidden_2])),</span><br><span class="line">    <span class="string">"l2_out"</span>:tf.Variable(tf.random_normal([n_hidden_2,n_hidden_1])),</span><br><span class="line"></span><br><span class="line">    <span class="string">"out"</span>:tf.Variable(tf.random_normal([n_hidden_2,n_classes]))</span><br><span class="line">      &#125;</span><br><span class="line">biases=&#123;</span><br><span class="line">  <span class="string">"b1"</span>:tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">  <span class="string">"l1_b2"</span>:tf.Variable(tf.zeros(n_hidden_1)),</span><br><span class="line">  <span class="string">"l1_out"</span>:tf.Variable(tf.zeros(n_input)),</span><br><span class="line"></span><br><span class="line">  <span class="string">"l2_b1"</span>:tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">  <span class="string">"l2_b2"</span>:tf.Variable(tf.zeros(n_hidden_2)),</span><br><span class="line">  <span class="string">"l2_out"</span>:tf.Variable(tf.zeros(n_hidden_1)),</span><br><span class="line"></span><br><span class="line">  <span class="string">"out"</span>:tf.Variable(tf.zeros(n_classes))</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，要建立4个网络：每一层都用一个网格来训练训练，于是我们需要训练3个网格，最后再把训练好的各个层组合到一起，形成第4个网络。所以我们在上面代码中为每一层网络定义了占位符，接着定义了学习参数。</p><h3 id="第一层网络结构"><a href="#第一层网络结构" class="headerlink" title="第一层网络结构"></a>第一层网络结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">l1_out=tf.nn.sigmoid(tf.add(tf.matmul(x,weights[<span class="string">"h1"</span>]),biases[<span class="string">"b1"</span>]))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">noise_l1_autodecoder</span><span class="params">(layer_1,_weights,_biases,_keep_prob)</span>:</span></span><br><span class="line">  layer_1out=tf.nn.dropout(layer_1,_keep_prob)</span><br><span class="line">  layer_2=tf.nn.sigmoid(tf.add(tf.matmul(layer_1out,_weights[<span class="string">"l1_h2"</span>]),_biases[<span class="string">"l1_b2"</span>]))</span><br><span class="line">  layer_2out=tf.nn.dropout(layer_2,_keep_prob)</span><br><span class="line">  <span class="keyword">return</span> tf.nn.sigmoid(tf.add(tf.matmul(layer_2out,_weights[<span class="string">"l1_out"</span>]),_biases[<span class="string">"l1_out"</span>]))</span><br><span class="line"></span><br><span class="line">l1_reconstruction=noise_l1_autodecoder(l1_out,weights,biases,dropout_keep_prob)</span><br><span class="line">l1_cost=tf.reduce_mean(tf.pow(l1_reconstruction-y,<span class="number">2</span>))</span><br><span class="line">l1_optm=tf.train.AdamOptimizer(<span class="number">0.01</span>).minimize(l1_cost)</span><br></pre></td></tr></table></figure><h3 id="第二层网络结构"><a href="#第二层网络结构" class="headerlink" title="第二层网络结构"></a>第二层网络结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l2_autodecoder</span><span class="params">(layer1_2,_weight,_biases)</span>:</span></span><br><span class="line">  layer1_2out=tf.nn.sigmoid(tf.add(tf.matmul(layer1_2,_weight[<span class="string">"l2_h2"</span>]),_biases[<span class="string">"l2_b2"</span>]))</span><br><span class="line">  <span class="keyword">return</span> tf.nn.sigmoid(tf.matmul(layer1_2out,_weight[<span class="string">"l2_out"</span>])+_biases[<span class="string">"l2_out"</span>])</span><br><span class="line">l2_out=tf.nn.sigmoid(tf.add(tf.matmul(l2x,weights[<span class="string">"l2_h1"</span>]),biases[<span class="string">"l2_b1"</span>]))</span><br><span class="line">l2_reconstruction=l2_autodecoder(l2_out,weights,biases)</span><br><span class="line">l2_cost=tf.reduce_mean(tf.pow(l2_reconstruction-l2y,<span class="number">2</span>))</span><br><span class="line">optm2=tf.train.AdamOptimizer(<span class="number">0.01</span>).minimize(l2_cost)</span><br></pre></td></tr></table></figure><h3 id="第三层网络结构"><a href="#第三层网络结构" class="headerlink" title="第三层网络结构"></a>第三层网络结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">l3_out = tf.matmul(l3x, weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br><span class="line">l3_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=l3_out, labels=l3y))</span><br><span class="line">l3_optm = tf.train.AdamOptimizer(<span class="number">0.01</span>).minimize(l3_cost)</span><br></pre></td></tr></table></figure><h3 id="定义级联网络结构"><a href="#定义级联网络结构" class="headerlink" title="定义级联网络结构"></a>定义级联网络结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l1_l2out = tf.nn.sigmoid(tf.add(tf.matmul(l1_out, weights[<span class="string">'l2_h1'</span>]), biases[<span class="string">'l2_b1'</span>])) </span><br><span class="line">pred = tf.matmul(l1_l2out, weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br><span class="line">cost3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=l3y))</span><br><span class="line">optm3 = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(cost3)</span><br></pre></td></tr></table></figure><h3 id="第一层网络训练"><a href="#第一层网络训练" class="headerlink" title="第一层网络训练"></a>第一层网络训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">epochs     = <span class="number">50</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">disp_step  = <span class="number">10</span></span><br><span class="line">load_epoch =<span class="number">49</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"开始训练"</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            batch_xs_noisy = batch_xs + <span class="number">0.3</span>*np.random.randn(batch_size, <span class="number">784</span>)</span><br><span class="line">            feeds = &#123;x: batch_xs_noisy, y: batch_xs, dropout_keep_prob: <span class="number">0.5</span>&#125;</span><br><span class="line">            sess.run(l1_optm, feed_dict=feeds)</span><br><span class="line">            total_cost += sess.run(l1_cost, feed_dict=feeds)</span><br><span class="line">        <span class="keyword">if</span> epoch % disp_step == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Epoch %02d/%02d average cost: %.6f"</span> </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))           </span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"完成"</span>)    </span><br><span class="line">    <span class="comment">#结果可视化</span></span><br><span class="line">    show_num = <span class="number">10</span></span><br><span class="line">    test_noisy = mnist.test.images[:show_num] + <span class="number">0.3</span>*np.random.randn(show_num, <span class="number">784</span>)</span><br><span class="line">    encode_decode = sess.run(</span><br><span class="line">        l1_reconstruction, feed_dict=&#123;x: test_noisy, dropout_keep_prob: <span class="number">1.</span>&#125;)</span><br><span class="line">    f, a = plt.subplots(<span class="number">3</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(show_num):</span><br><span class="line">        a[<span class="number">0</span>][i].imshow(np.reshape(test_noisy[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">1</span>][i].imshow(np.reshape(mnist.test.images[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">2</span>][i].matshow(np.reshape(encode_decode[i], (<span class="number">28</span>, <span class="number">28</span>)), cmap=plt.get_cmap(<span class="string">'gray'</span>))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h3 id="第二层网络训练"><a href="#第二层网络训练" class="headerlink" title="第二层网络训练"></a>第二层网络训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"开始训练"</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">            l1_h = sess.run(l1_out, feed_dict=&#123;x: batch_xs, y: batch_xs, dropout_keep_prob: <span class="number">1.</span>&#125;)</span><br><span class="line">            _,l2cost = sess.run([optm2,l2_cost], feed_dict=&#123;l2x: l1_h, l2y: l1_h &#125;)</span><br><span class="line">            total_cost += l2cost      </span><br><span class="line">        <span class="keyword">if</span> epoch % disp_step == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Epoch %02d/%02d average cost: %.6f"</span> </span><br><span class="line">                % (epoch, epochs, total_cost/num_batch))      </span><br><span class="line">    print(sess.run(weights[<span class="string">'h1'</span>])) </span><br><span class="line">    <span class="keyword">print</span> (weights[<span class="string">'h1'</span>].name)  </span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"完成  layer_2 训练"</span>)</span><br><span class="line">    <span class="comment">#结果可视化</span></span><br><span class="line">    show_num = <span class="number">10</span></span><br><span class="line">    testvec = mnist.test.images[:show_num]</span><br><span class="line">    out1vec = sess.run(l1_out, feed_dict=&#123;x: testvec,y: testvec, dropout_keep_prob: <span class="number">1.</span>&#125;)</span><br><span class="line">    out2vec = sess.run(l2_reconstruction, feed_dict=&#123;l2x: out1vec&#125;)</span><br><span class="line">    f, a = plt.subplots(<span class="number">3</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(show_num):</span><br><span class="line">        a[<span class="number">0</span>][i].imshow(np.reshape(testvec[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">1</span>][i].matshow(np.reshape(out1vec[i], (<span class="number">16</span>, <span class="number">16</span>)), cmap=plt.get_cmap(<span class="string">'gray'</span>))</span><br><span class="line">        a[<span class="number">2</span>][i].matshow(np.reshape(out2vec[i], (<span class="number">16</span>, <span class="number">16</span>)), cmap=plt.get_cmap(<span class="string">'gray'</span>))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h3 id="第三层网络训练"><a href="#第三层网络训练" class="headerlink" title="第三层网络训练"></a>第三层网络训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"开始训练"</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)               </span><br><span class="line">            l1_h = sess.run(l1_out, feed_dict=&#123;x: batch_xs, y: batch_xs, dropout_keep_prob: <span class="number">1.</span>&#125;)               </span><br><span class="line">            l2_h = sess.run(l2_out, feed_dict=&#123;l2x: l1_h, l2y: l1_h &#125;)</span><br><span class="line">            _,l3cost = sess.run([l3_optm,l3_cost], feed_dict=&#123;l3x: l2_h, l3y: batch_ys&#125;)</span><br><span class="line">            total_cost += l3cost</span><br><span class="line">        <span class="keyword">if</span> epoch % disp_step == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Epoch %02d/%02d average cost: %.6f"</span> </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"完成  layer_3 训练"</span>)</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试 model</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(l3y, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Accuracy:"</span>, accuracy.eval(&#123;x: mnist.test.images, l3y: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure><p>可以看出，每层的训练参数叠在一起，网络会有比较好的表现</p><h3 id="级联微调"><a href="#级联微调" class="headerlink" title="级联微调"></a>级联微调</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"开始训练"</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            </span><br><span class="line">            feeds = &#123;x: batch_xs, l3y: batch_ys&#125;</span><br><span class="line">            sess.run(optm3, feed_dict=feeds)</span><br><span class="line">            total_cost += sess.run(cost3, feed_dict=feeds)</span><br><span class="line">        <span class="keyword">if</span> epoch % disp_step == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Epoch %02d/%02d average cost: %.6f"</span> </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">           </span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"完成  级联 训练"</span>)</span><br><span class="line">    <span class="comment"># 测试 model</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(l3y, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Accuracy:"</span>, accuracy.eval(&#123;x: mnist.test.images, l3y: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure><p>从结果看，由于网络模型中各层的初始值都已经训练好了，所以一开始就是很低的错误率，且每次的迭代后，错误率都有很大幅度的下降。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;常用方法&quot;&gt;&lt;a href=&quot;#常用方法&quot; class=&quot;headerlink&quot; title=&quot;常用方法&quot;&gt;&lt;/a&gt;常用方法&lt;/h2&gt;&lt;p&gt;自编码常用方法：代替和级联&lt;/p&gt;
&lt;p&gt;栈式自编码会将网络中的中间层作为下一个网络的输入进行训练，我们可以得到网络中每一个
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="自编码网络" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>栈式自编码网络</title>
    <link href="http://yoursite.com/2020/02/27/%E6%A0%88%E5%BC%8F%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2020/02/27/栈式自编码网络/</id>
    <published>2020-02-27T11:49:12.000Z</published>
    <updated>2020-03-01T04:35:17.761Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>栈式自编码神经网络（SA）是对自编码网络的一种使用方法，是一个由多层训练好的自编码器组成的神经网络。由于网络中的每一层都是单独训练而来，相当于都初始化一个合理的数值。所以，这样的网络会更容易训练，并且有更快的收敛性及更高的准确度。</p><p>栈式自编码常常被用于预训练深度神经网络之前的权重预训练步骤</p><p>（1）训练一个自编码器，得到原始输入的一阶特征表示h<sup>(1)</sup>，也就是下图的feature I  </p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200227204238.png" alt=""></p><p>（2）将上一步输出的特征h<sup>(1)</sup>作为输入，对其进行再一次自编码，并同时获取特征h<sup>(2)</sup></p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200227204328.png" alt=""></p><p>（3）把上一步的特征h<sup>(2)</sup>连上softmax分类器，得到了一个图片数字标签分类的模型</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200227204531.png" alt=""></p><p>（4）把这三层结合起来，就构成一个包含两个隐藏层加一个softmax的栈式编码网络，它可以对数字图片分类</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200227204752.png" alt=""></p><h2 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h2><p>看了上面的步骤，我们不经疑问：为什么要这么麻烦？直接使用多层神经网络训练不是也可以？之所以使用这种方法，主要有以下优点：</p><p>1、每一层都可以单独训练，保证降维特征的可控性</p><p>2、对于高维度的分类问题， 一下拿出一套完整可用的模型相对来讲并不是容易的事， 因为节点太多， 参数太多， 一味地增加深度只会使结果越来越不可控， 成为测底的黑盒， 而使用栈式自编码逐层降维， 可以将复杂问题简单化， 更容易完成任务。</p><p>3、任意深层， 理论上是越深层的神经网络对现实的拟合度越高， 但是传统的多层神经网络，由于使用的是误差反向传播方式， 导致层越深，传播的误差越小。 栈式自编码巧妙地绕过这个问题， 直接使用降维后的特征值进行二次训练， 可以任意层数的加深。  </p><p>栈式自编码网络具有强大的表达能力和深度神经网络的所有优点，它通常能够获取到输入的“层次型分组”或者“部分整体分解”结构，自编码其倾向于学习得到与样本相对应的低维向量，该向量可以更好地表示高位样本的数据特征</p><p>如果网络输入的是图像，第一层会学习边特征，二层会学习组合边、角等，更高层会学习更形象的特征</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;栈式自编码神经网络（SA）是对自编码网络的一种使用方法，是一个由多层训练好的自编码器组成的神经网络。由于网络中的每一层都是单独训练而来，相当
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="自编码网络" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>去噪自编码网络</title>
    <link href="http://yoursite.com/2020/02/27/%E5%8E%BB%E5%99%AA%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2020/02/27/去噪自编码网络/</id>
    <published>2020-02-27T11:23:10.000Z</published>
    <updated>2020-02-29T02:42:17.121Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>要想取得好的特征只靠重构输入数据是不够的，实际上，还需要让这些特征具有抗干扰的能力，即当输入数据发生一定程度的扰动时，生成的特征仍然保持不变。这时需要添加噪声为模型增加更大的困难。在这种情况下训练出来的模型才会有更好的鲁棒性，于是就有了去噪自编码网络</p><p>去噪自编码网络（DA）是在自动编码的基础上，训练数据加入噪声，输出的标签仍是原始的样本（没有加入噪声的），这样自动编码器必须学习去除噪声而获得真正的没有被噪声污染过的输入特征。因此，这就迫使编码器去学习输入信号的更加鲁棒的特征表达，即具有更加强悍的泛化能力</p><p>在实际训练中，人为加入噪声有两种途径：</p><p>（1）在选择训练数据集时，额外选择一些样本集以外的数据</p><p>（2）改变已有的样本数据集中的数据</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_X   = mnist.train.images</span><br><span class="line">train_Y = mnist.train.labels</span><br><span class="line">test_X    = mnist.test.images</span><br><span class="line">test_Y  = mnist.test.labels</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line">n_input    = <span class="number">784</span> </span><br><span class="line">n_hidden_1 = <span class="number">256</span> </span><br><span class="line"></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, n_input])</span><br><span class="line">y = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, n_input])</span><br><span class="line">dropout_keep_prob = tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line"></span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'h1'</span>: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</span><br><span class="line">    <span class="string">'h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_1])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_input]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'b1'</span>: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    <span class="string">'b2'</span>: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.zeros([n_input]))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">denoise_auto_encoder</span><span class="params">(_X, _weights, _biases, _keep_prob)</span>:</span></span><br><span class="line">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights[<span class="string">'h1'</span>]), _biases[<span class="string">'b1'</span>])) </span><br><span class="line">    layer_1out = tf.nn.dropout(layer_1, _keep_prob) </span><br><span class="line">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1out, _weights[<span class="string">'h2'</span>]), _biases[<span class="string">'b2'</span>])) </span><br><span class="line">    layer_2out = tf.nn.dropout(layer_2, _keep_prob) </span><br><span class="line">    <span class="keyword">return</span> tf.nn.sigmoid(tf.matmul(layer_2out, _weights[<span class="string">'out'</span>]) + _biases[<span class="string">'out'</span>])</span><br><span class="line"></span><br><span class="line">reconstruction = denoise_auto_encoder(x, weights, biases, dropout_keep_probcost = tf.reduce_mean(tf.pow(reconstruction-y, <span class="number">2</span>))</span><br><span class="line">optm = tf.train.AdamOptimizer(<span class="number">0.01</span>).minimize(cost) </span><br><span class="line"></span><br><span class="line">epochs     = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">disp_step  = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"开始训练"</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            <span class="comment">#制造噪声</span></span><br><span class="line">            batch_xs_noisy = batch_xs + <span class="number">0.3</span>*np.random.randn(batch_size, <span class="number">784</span>)</span><br><span class="line">            feeds = &#123;x: batch_xs_noisy, y: batch_xs, dropout_keep_prob: <span class="number">1.</span>&#125;</span><br><span class="line">            sess.run(optm, feed_dict=feeds)</span><br><span class="line">            total_cost += sess.run(cost, feed_dict=feeds)</span><br><span class="line">        <span class="keyword">if</span> epoch % disp_step == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Epoch %02d/%02d average cost: %.6f"</span> </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"完成"</span>)</span><br><span class="line">    show_num = <span class="number">10</span></span><br><span class="line">    test_noisy = mnist.test.images[:show_num] + <span class="number">0.3</span>*np.random.randn(show_num, <span class="number">784</span>)</span><br><span class="line">    encode_decode = sess.run(</span><br><span class="line">        reconstruction, feed_dict=&#123;x: test_noisy, dropout_keep_prob: <span class="number">1.</span>&#125;)</span><br><span class="line">    f, a = plt.subplots(<span class="number">3</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(show_num):</span><br><span class="line">        a[<span class="number">0</span>][i].imshow(np.reshape(test_noisy[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">1</span>][i].imshow(np.reshape(mnist.test.images[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">2</span>][i].matshow(np.reshape(encode_decode[i], (<span class="number">28</span>, <span class="number">28</span>)), cmap=plt.get_cmap(<span class="string">'gray'</span>))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;要想取得好的特征只靠重构输入数据是不够的，实际上，还需要让这些特征具有抗干扰的能力，即当输入数据发生一定程度的扰动时，生成的特征仍然保持不变
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="自编码网络" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>自编码网络介绍</title>
    <link href="http://yoursite.com/2020/02/27/%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2020/02/27/自编码网络介绍/</id>
    <published>2020-02-27T03:10:16.000Z</published>
    <updated>2020-02-28T12:49:12.670Z</updated>
    
    <content type="html"><![CDATA[<p>深度学习领域主要有两种训练模式：一种是监督学习，另一种是非监督学习。前者有样本有标签，后者只有样本。此外还有半监督学习，半监督学习属于非监督学习领域</p><p>相对于监督学习来说，非监督学习就显得简单得多。非监督学习能让网络直接使用样本进行训练，不需要准备标签。接下来我们就来学习一个非监督模型的网络——自编码网络</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>人们看一张图时，一般是扫一眼物体，大致会得到图片的诸多特征。而计算机是逐个元素去读，怎么让计算机也具有人类的能力呢？用自编码网络</p><p>自编码网络是非监督学习领域中的一种，可以自动从无标注的数据中学习特征，是一种以重构输入信号为目标的神经网络，它可以给出比原始数据更好的特征描述，具有较强的特征学习能力，在深度学习中常用自编码网络生成的特征来取代原始数据，以得到更好的结果</p><p>自编码（AE）网络是输入等于输出的网络，最基本的模型可以是为三层神经网络，也就是输入层、隐藏层、输出层。其中，输入层的样本也会充当输出层的标签。即：这个神经网络就是一种尽可能复现输入信号的神经网络。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200227133126.png" alt=""></p><p>在上图中，自编码器要求输出尽可能等于输入，并且其隐藏层必须满足一定的稀疏性，是通过将隐藏层中的后一层个数比前一层神经元个数少的方式来实现稀疏效果的。相当于隐藏层对输入进行了压缩，并在输出层中解压缩。整个过程是一定会丢失信息的，但训练能够使丢失的信息尽量减少，最大化地保留其主要特征。这样的自动编码器可以捕捉代表输入数据的最重要的因素，类似PCA算法。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"/data/"</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line"><span class="comment">#第一层隐藏层节点</span></span><br><span class="line">n_hidden_1=<span class="number">256</span></span><br><span class="line"><span class="comment">#第二层隐藏层节点</span></span><br><span class="line">n_hidden_2=<span class="number">128</span></span><br><span class="line">n_input=<span class="number">784</span> <span class="comment">#28*28</span></span><br><span class="line">x=tf.placeholder(<span class="string">"float"</span>,[<span class="literal">None</span>,n_input])</span><br><span class="line">y=x</span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'encoder_h1'</span>: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</span><br><span class="line">    <span class="string">'encoder_h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</span><br><span class="line">    <span class="string">'decoder_h1'</span>: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),</span><br><span class="line">    <span class="string">'decoder_h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_input])),</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'encoder_b1'</span>: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    <span class="string">'encoder_b2'</span>: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    <span class="string">'decoder_b1'</span>: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    <span class="string">'decoder_b2'</span>: tf.Variable(tf.zeros([n_input])),</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#编码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encoder</span><span class="params">(x)</span>:</span></span><br><span class="line">  layer_1=tf.nn.sigmoid(tf.add(tf.matmul(x,weights[<span class="string">"encoder_h1"</span>]),biases[<span class="string">"encoder_b1"</span>]))</span><br><span class="line">  layer_2=tf.nn.sigmoid(tf.add(tf.matmul(layer_1,weights[<span class="string">"encoder_h2"</span>]),biases[<span class="string">"encoder_b2"</span>]))</span><br><span class="line">  <span class="keyword">return</span> layer_2</span><br><span class="line"><span class="comment">#解码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decoder</span><span class="params">(x)</span>:</span></span><br><span class="line">  layer_1=tf.nn.sigmoid(tf.add(tf.matmul(x,weights[<span class="string">"decoder_h1"</span>]),biases[<span class="string">"decoder_b1"</span>]))</span><br><span class="line">  layer_2=tf.nn.sigmoid(tf.add(tf.matmul(layer_1,weights[<span class="string">"decoder_h2"</span>]),biases[<span class="string">"decoder_b2"</span>]))</span><br><span class="line">  <span class="keyword">return</span> layer_2</span><br><span class="line">encoder_out=encoder(x)</span><br><span class="line">pred=decoder(encoder_out)</span><br><span class="line">cost = tf.reduce_mean(tf.pow(y - pred, <span class="number">2</span>))</span><br><span class="line">optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)</span><br><span class="line"><span class="comment"># 训练参数</span></span><br><span class="line">training_epochs = <span class="number">100</span>  </span><br><span class="line">batch_size = <span class="number">256</span>     </span><br><span class="line">display_step = <span class="number">10</span>     </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):   </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)<span class="comment">#取数据</span></span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs&#125;)<span class="comment"># 训练模型</span></span><br><span class="line">        <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch+<span class="number">1</span>),<span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(c))</span><br><span class="line">    print(<span class="string">"完成!"</span>)  </span><br><span class="line">    <span class="comment"># 测试</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 计算错误率</span></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Accuracy:"</span>, <span class="number">1</span>-accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.images&#125;))</span><br><span class="line"></span><br><span class="line">    show_num = <span class="number">10</span></span><br><span class="line">    reconstruction = sess.run(</span><br><span class="line">        pred, feed_dict=&#123;x: mnist.test.images[:show_num]&#125;)</span><br><span class="line">    f, a = plt.subplots(<span class="number">2</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>, <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(show_num):</span><br><span class="line">        a[<span class="number">0</span>][i].imshow(np.reshape(mnist.test.images[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">1</span>][i].imshow(np.reshape(reconstruction[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h2 id="线性解码器"><a href="#线性解码器" class="headerlink" title="线性解码器"></a>线性解码器</h2><p>在上面的代码中，使用的激活函数是sigmoid，这是一个S型激活函数，输出范围是[0,1]。当我们对最终提取的特征节点采用该激活函数时，就相当于对输入限制或缩放，使其位于[0,1]范围中。有一些数据集，比如MNIST，能方便地将输出缩放到[0,1]中，但是很难满足对输入值的要求。利用一个恒等式来作为激活函数，就可以解决这个问题，f(z)=z，即：没有激活函数。</p><p><strong>注意：这个只是对最后的输出层而言，隐藏层要使用激活函数</strong></p><p>由多个带有S型激活函数的隐藏层及一个线性输出层构成的自编码器，成为线性解码器</p><h2 id="自编码的卷积网络"><a href="#自编码的卷积网络" class="headerlink" title="自编码的卷积网络"></a>自编码的卷积网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">learning_rate = <span class="number">0.01</span>    </span><br><span class="line">n_hidden_1 = <span class="number">256</span></span><br><span class="line">n_hidden_2 = <span class="number">64</span></span><br><span class="line">n_hidden_3 = <span class="number">16</span></span><br><span class="line">n_hidden_4 = <span class="number">2</span></span><br><span class="line">n_input = <span class="number">784</span> </span><br><span class="line"></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>,n_input])</span><br><span class="line">y=x</span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'encoder_h1'</span>: tf.Variable(tf.random_normal([n_input, n_hidden_1],)),</span><br><span class="line">    <span class="string">'encoder_h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2],)),</span><br><span class="line">    <span class="string">'encoder_h3'</span>: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3],)),</span><br><span class="line">    <span class="string">'encoder_h4'</span>: tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4],)),</span><br><span class="line"></span><br><span class="line">    <span class="string">'decoder_h1'</span>: tf.Variable(tf.random_normal([n_hidden_4, n_hidden_3],)),</span><br><span class="line">    <span class="string">'decoder_h2'</span>: tf.Variable(tf.random_normal([n_hidden_3, n_hidden_2],)),</span><br><span class="line">    <span class="string">'decoder_h3'</span>: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1],)),</span><br><span class="line">    <span class="string">'decoder_h4'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_input],)),</span><br><span class="line">&#125; </span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'encoder_b1'</span>: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    <span class="string">'encoder_b2'</span>: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    <span class="string">'encoder_b3'</span>: tf.Variable(tf.zeros([n_hidden_3])),</span><br><span class="line">    <span class="string">'encoder_b4'</span>: tf.Variable(tf.zeros([n_hidden_4])),</span><br><span class="line"></span><br><span class="line">    <span class="string">'decoder_b1'</span>: tf.Variable(tf.zeros([n_hidden_3])),</span><br><span class="line">    <span class="string">'decoder_b2'</span>: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    <span class="string">'decoder_b3'</span>: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    <span class="string">'decoder_b4'</span>: tf.Variable(tf.zeros([n_input])),</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encoder</span><span class="params">(x)</span>:</span></span><br><span class="line">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[<span class="string">'encoder_h1'</span>]),biases[<span class="string">'encoder_b1'</span>]))</span><br><span class="line">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[<span class="string">'encoder_h2'</span>]),biases[<span class="string">'encoder_b2'</span>]))</span><br><span class="line">    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights[<span class="string">'encoder_h3'</span>]),biases[<span class="string">'encoder_b3'</span>]))</span><br><span class="line">    layer_4 = tf.add(tf.matmul(layer_3, weights[<span class="string">'encoder_h4'</span>]),biases[<span class="string">'encoder_b4'</span>])</span><br><span class="line">    <span class="keyword">return</span> layer_4</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decoder</span><span class="params">(x)</span>:</span></span><br><span class="line">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[<span class="string">'decoder_h1'</span>]),biases[<span class="string">'decoder_b1'</span>]))</span><br><span class="line">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[<span class="string">'decoder_h2'</span>]), biases[<span class="string">'decoder_b2'</span>]))</span><br><span class="line">    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights[<span class="string">'decoder_h3'</span>]),biases[<span class="string">'decoder_b3'</span>]))</span><br><span class="line">    layer_4 = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, weights[<span class="string">'decoder_h4'</span>]),biases[<span class="string">'decoder_b4'</span>]))</span><br><span class="line">    <span class="keyword">return</span> layer_4</span><br><span class="line"></span><br><span class="line">encoder_op = encoder(x) </span><br><span class="line">y_pred = decoder(encoder_op)</span><br><span class="line">cost = tf.reduce_mean(tf.pow(y - y_pred, <span class="number">2</span>))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)</span><br><span class="line">training_epochs = <span class="number">100</span> </span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">display_step = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  </span><br><span class="line">        <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch+<span class="number">1</span>),<span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(c))</span><br><span class="line">    print(<span class="string">"完成!"</span>)</span><br><span class="line">    show_num = <span class="number">10</span></span><br><span class="line">    encode_decode = sess.run(</span><br><span class="line">        y_pred, feed_dict=&#123;x: mnist.test.images[:show_num]&#125;)</span><br><span class="line">    f, a = plt.subplots(<span class="number">2</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>, <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(show_num):</span><br><span class="line">        a[<span class="number">0</span>][i].imshow(np.reshape(mnist.test.images[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">1</span>][i].imshow(np.reshape(encode_decode[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>如果读者得到更好的特征提取效果，可以将压缩的层数变得更多，但是由于sigmoid函数的缺陷，无法使用更深的层，所以只能做成4层压缩。这有一个解决办法——使用栈式自编码器</p><h2 id="使用自编码的卷积网络"><a href="#使用自编码的卷积网络" class="headerlink" title="使用自编码的卷积网络"></a>使用自编码的卷积网络</h2><p>自编码结构不仅只用在全连接网络上，还可用在卷积网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#最大池化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_with_argmax</span><span class="params">(net, stride)</span>:</span></span><br><span class="line">    _, mask = tf.nn.max_pool_with_argmax( net,ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    mask = tf.stop_gradient(mask)</span><br><span class="line">    net = tf.nn.max_pool(net, ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) </span><br><span class="line">    <span class="keyword">return</span> net, mask</span><br><span class="line"><span class="comment">#4*4----2*2--=2*2 【6，8，12，16】    </span></span><br><span class="line"><span class="comment">#反池化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpool</span><span class="params">(net, mask, stride)</span>:</span></span><br><span class="line">    ksize = [<span class="number">1</span>, stride, stride, <span class="number">1</span>]</span><br><span class="line">    input_shape = net.get_shape().as_list()</span><br><span class="line">    output_shape = (input_shape[<span class="number">0</span>], input_shape[<span class="number">1</span>] * ksize[<span class="number">1</span>], input_shape[<span class="number">2</span>] * ksize[<span class="number">2</span>], input_shape[<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">    one_like_mask = tf.ones_like(mask)</span><br><span class="line">    batch_range = tf.reshape(tf.range(output_shape[<span class="number">0</span>], dtype=tf.int64), shape=[input_shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    b = one_like_mask * batch_range</span><br><span class="line">    y = mask // (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>])</span><br><span class="line">    x = mask % (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>]) // output_shape[<span class="number">3</span>]</span><br><span class="line">    feature_range = tf.range(output_shape[<span class="number">3</span>], dtype=tf.int64)</span><br><span class="line">    f = one_like_mask * feature_range</span><br><span class="line"></span><br><span class="line">    updates_size = tf.size(net)</span><br><span class="line">    indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [<span class="number">4</span>, updates_size]))</span><br><span class="line">    values = tf.reshape(net, [updates_size])</span><br><span class="line">    ret = tf.scatter_nd(indices, values, output_shape)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                        strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)  </span><br><span class="line">                        </span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_conv_1 = <span class="number">16</span> </span><br><span class="line">n_conv_2 = <span class="number">32</span> </span><br><span class="line">n_input = <span class="number">784</span></span><br><span class="line">batchsize = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, [batchsize, n_input])</span><br><span class="line"></span><br><span class="line">x_image = tf.reshape(x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encoder</span><span class="params">(x)</span>:</span></span><br><span class="line">    h_conv1 = tf.nn.relu(conv2d(x, weights[<span class="string">'encoder_conv1'</span>]) + biases[<span class="string">'encoder_conv1'</span>])</span><br><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_conv1, weights[<span class="string">'encoder_conv2'</span>]) + biases[<span class="string">'encoder_conv2'</span>])  </span><br><span class="line">    <span class="keyword">return</span> h_conv2,h_conv1</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decoder</span><span class="params">(x,conv1)</span>:</span></span><br><span class="line">    t_conv1 = tf.nn.conv2d_transpose(x-biases[<span class="string">'decoder_conv2'</span>], weights[<span class="string">'decoder_conv2'</span>], conv1.shape,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">    t_x_image = tf.nn.conv2d_transpose(t_conv1-biases[<span class="string">'decoder_conv1'</span>], weights[<span class="string">'decoder_conv1'</span>], x_image.shape,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> t_x_image</span><br><span class="line"></span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'encoder_conv1'</span>: tf.Variable(tf.truncated_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, n_conv_1],stddev=<span class="number">0.1</span>)),</span><br><span class="line">    <span class="string">'encoder_conv2'</span>: tf.Variable(tf.random_normal([<span class="number">3</span>, <span class="number">3</span>, n_conv_1, n_conv_2],stddev=<span class="number">0.1</span>)),</span><br><span class="line">    <span class="string">'decoder_conv1'</span>: tf.Variable(tf.random_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, n_conv_1],stddev=<span class="number">0.1</span>)),</span><br><span class="line">    <span class="string">'decoder_conv2'</span>: tf.Variable(tf.random_normal([<span class="number">3</span>, <span class="number">3</span>, n_conv_1, n_conv_2],stddev=<span class="number">0.1</span>))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'encoder_conv1'</span>: tf.Variable(tf.zeros([n_conv_1])),</span><br><span class="line">    <span class="string">'encoder_conv2'</span>: tf.Variable(tf.zeros([n_conv_2])),</span><br><span class="line">    <span class="string">'decoder_conv1'</span>: tf.Variable(tf.zeros([n_conv_1])),</span><br><span class="line">    <span class="string">'decoder_conv2'</span>: tf.Variable(tf.zeros([n_conv_2])),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">encoder_out,conv1 = encoder(x_image)</span><br><span class="line">h_pool2, mask = max_pool_with_argmax(encoder_out, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">h_upool = unpool(h_pool2, mask, <span class="number">2</span>)</span><br><span class="line">pred = decoder(h_upool,conv1)</span><br><span class="line"></span><br><span class="line">cost = tf.reduce_mean(tf.pow(x_image - pred, <span class="number">2</span>))</span><br><span class="line">optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line">training_epochs = <span class="number">20</span>  </span><br><span class="line"></span><br><span class="line">display_step = <span class="number">5</span>   </span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())   </span><br><span class="line">    total_batch = int(mnist.train.num_examples/batchsize)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):       </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batchsize)</span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">        <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch+<span class="number">1</span>),<span class="string">"cost="</span>, <span class="string">"&#123;:.9f&#125;"</span>.format(c))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"完成!"</span>)   </span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(batchsize)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Error:"</span>, cost.eval(&#123;x: batch_xs&#125;))</span><br><span class="line">    show_num = <span class="number">10</span></span><br><span class="line">    reconstruction = sess.run(</span><br><span class="line">        pred, feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">    f, a = plt.subplots(<span class="number">2</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>, <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(show_num):</span><br><span class="line">        a[<span class="number">0</span>][i].imshow(np.reshape(batch_xs[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">        a[<span class="number">1</span>][i].imshow(np.reshape(reconstruction[i], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;深度学习领域主要有两种训练模式：一种是监督学习，另一种是非监督学习。前者有样本有标签，后者只有样本。此外还有半监督学习，半监督学习属于非监督学习领域&lt;/p&gt;
&lt;p&gt;相对于监督学习来说，非监督学习就显得简单得多。非监督学习能让网络直接使用样本进行训练，不需要准备标签。接下来我
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="自编码网络" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>复现VGG</title>
    <link href="http://yoursite.com/2020/02/24/%E5%A4%8D%E7%8E%B0VGG/"/>
    <id>http://yoursite.com/2020/02/24/复现VGG/</id>
    <published>2020-02-24T14:07:07.000Z</published>
    <updated>2020-02-26T02:55:52.067Z</updated>
    
    <content type="html"><![CDATA[<p>本文参考： <a href="https://www.icourse163.org/learn/PKU-1002536002?tid=1206591210#/learn/content" target="_blank" rel="noopener">https://www.icourse163.org/learn/PKU-1002536002?tid=1206591210#/learn/content</a> </p><p>项目结构</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200225191018.png" alt=""></p><p>VGG16.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">VGG_MEAN = [<span class="number">103.939</span>, <span class="number">116.779</span>, <span class="number">123.68</span>] <span class="comment"># 样本 RGB 的平均值</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vgg16</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vgg16_path=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> vgg16_path <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">             vgg16_path = os.path.join(os.getcwd(), <span class="string">"vgg16.npy"</span>) <span class="comment"># os.getcwd() 方法用于返回当前工作目录。</span></span><br><span class="line">             print(vgg16_path)</span><br><span class="line">             self.data_dict = np.load(vgg16_path, encoding=<span class="string">'latin1'</span>).item() <span class="comment"># 遍历其内键值对，导入模型参数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.data_dict: <span class="comment">#遍历 data_dict 中的每个键</span></span><br><span class="line">            <span class="keyword">print</span> (x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, images)</span>:</span></span><br><span class="line">        <span class="comment"># plt.figure("process pictures")</span></span><br><span class="line">        print(<span class="string">"build model started"</span>)</span><br><span class="line">        start_time = time.time() <span class="comment"># 获取前向传播的开始时间</span></span><br><span class="line">        rgb_scaled = images * <span class="number">255.0</span> <span class="comment"># 逐像素乘以 255.0（根据原论文所述的初始化步骤）</span></span><br><span class="line">        <span class="comment"># 从 GRB 转换色彩通道到 BGR，也可使用 cv 中的 GRBtoBGR</span></span><br><span class="line">        red, green, blue = tf.split(rgb_scaled,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">assert</span> red.get_shape().as_list()[<span class="number">1</span>:] == [<span class="number">224</span>, <span class="number">224</span>, <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">assert</span> green.get_shape().as_list()[<span class="number">1</span>:] == [<span class="number">224</span>, <span class="number">224</span>, <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">assert</span> blue.get_shape().as_list()[<span class="number">1</span>:] == [<span class="number">224</span>, <span class="number">224</span>, <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 以上 assert 都是加入断言，用来判断每个操作后的维度变化是否和预期一致</span></span><br><span class="line">        bgr = tf.concat([</span><br><span class="line">            blue - VGG_MEAN[<span class="number">0</span>],</span><br><span class="line">            green - VGG_MEAN[<span class="number">1</span>],</span><br><span class="line">            red - VGG_MEAN[<span class="number">2</span>]],<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 逐样本减去每个通道的像素平均值，这种操作可以移除图像的平均亮度值，该方法常用在灰度图像上</span></span><br><span class="line">        <span class="keyword">assert</span> bgr.get_shape().as_list()[<span class="number">1</span>:] == [<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>]</span><br><span class="line">        <span class="comment"># 接下来构建 VGG 的 16 层网络（包含 5 段卷积， 3 层全连接），并逐层根据命名空间读取网络参数</span></span><br><span class="line">        <span class="comment"># 第一段卷积，含有两个卷积层，后面接最大池化层，用来缩小图片尺寸</span></span><br><span class="line">        self.conv1_1 = self.conv_layer(bgr, <span class="string">"conv1_1"</span>)</span><br><span class="line">        <span class="comment"># 传入命名空间的 name，来获取该层的卷积核和偏置，并做卷积运算，最后返回经过经过激活函数后的值</span></span><br><span class="line">        self.conv1_2 = self.conv_layer(self.conv1_1, <span class="string">"conv1_2"</span>)</span><br><span class="line">        <span class="comment"># 根据传入的 pooling 名字对该层做相应的池化操作</span></span><br><span class="line">        self.pool1 = self.max_pool_2x2(self.conv1_2, <span class="string">"pool1"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下面的前向传播过程与第一段同理</span></span><br><span class="line">        <span class="comment"># 第二段卷积，同样包含两个卷积层，一个最大池化层</span></span><br><span class="line">        self.conv2_1 = self.conv_layer(self.pool1, <span class="string">"conv2_1"</span>)</span><br><span class="line">        self.conv2_2 = self.conv_layer(self.conv2_1, <span class="string">"conv2_2"</span>)</span><br><span class="line">        self.pool2 = self.max_pool_2x2(self.conv2_2, <span class="string">"pool2"</span>)</span><br><span class="line">        <span class="comment"># 第三段卷积，包含三个卷积层，一个最大池化层</span></span><br><span class="line">        self.conv3_1 = self.conv_layer(self.pool2, <span class="string">"conv3_1"</span>)</span><br><span class="line">        self.conv3_2 = self.conv_layer(self.conv3_1, <span class="string">"conv3_2"</span>)</span><br><span class="line">        self.conv3_3 = self.conv_layer(self.conv3_2, <span class="string">"conv3_3"</span>)</span><br><span class="line">        self.pool3 = self.max_pool_2x2(self.conv3_3, <span class="string">"pool3"</span>)</span><br><span class="line">        <span class="comment"># 第四段卷积，包含三个卷积层，一个最大池化层</span></span><br><span class="line">        self.conv4_1 = self.conv_layer(self.pool3, <span class="string">"conv4_1"</span>)</span><br><span class="line">        self.conv4_2 = self.conv_layer(self.conv4_1, <span class="string">"conv4_2"</span>)</span><br><span class="line">        self.conv4_3 = self.conv_layer(self.conv4_2, <span class="string">"conv4_3"</span>)</span><br><span class="line">        self.pool4 = self.max_pool_2x2(self.conv4_3, <span class="string">"pool4"</span>)</span><br><span class="line">        <span class="comment"># 第五段卷积，包含三个卷积层，一个最大池化层</span></span><br><span class="line">        self.conv5_1 = self.conv_layer(self.pool4, <span class="string">"conv5_1"</span>)</span><br><span class="line">        self.conv5_2 = self.conv_layer(self.conv5_1, <span class="string">"conv5_2"</span>)</span><br><span class="line">        self.conv5_3 = self.conv_layer(self.conv5_2, <span class="string">"conv5_3"</span>)</span><br><span class="line">        self.pool5 = self.max_pool_2x2(self.conv5_3, <span class="string">"pool5"</span>)</span><br><span class="line">        <span class="comment"># 第六层全连接</span></span><br><span class="line">        self.fc6 = self.fc_layer(self.pool5, <span class="string">"fc6"</span>) <span class="comment"># 根据命名空间 name 做加权求和运算</span></span><br><span class="line">        <span class="keyword">assert</span> self.fc6.get_shape().as_list()[<span class="number">1</span>:] == [<span class="number">4096</span>] <span class="comment"># 4096 是该层输出后的长度</span></span><br><span class="line">        self.relu6 = tf.nn.relu(self.fc6) <span class="comment"># 经过 relu 激活函数</span></span><br><span class="line">        <span class="comment"># 第七层全连接，和上一层同理</span></span><br><span class="line">        self.fc7 = self.fc_layer(self.relu6, <span class="string">"fc7"</span>)</span><br><span class="line">        self.relu7 = tf.nn.relu(self.fc7)</span><br><span class="line">        <span class="comment"># 第八层全连接</span></span><br><span class="line">        self.fc8 = self.fc_layer(self.relu7, <span class="string">"fc8"</span>)</span><br><span class="line">        <span class="comment"># 经过最后一层的全连接后，再做 softmax 分类，得到属于各类别的概率</span></span><br><span class="line">        self.prob = tf.nn.softmax(self.fc8, name=<span class="string">"prob"</span>)</span><br><span class="line">        end_time = time.time() <span class="comment"># 得到前向传播的结束时间</span></span><br><span class="line">        print((<span class="string">"time consuming: %f"</span> % (end_time-start_time)))</span><br><span class="line">        self.data_dict = <span class="literal">None</span> <span class="comment"># 清空本次读取到的模型参数字典</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义卷积运算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv_layer</span><span class="params">(self, x, name)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name): <span class="comment"># 根据命名空间找到对应卷积层的网络参数</span></span><br><span class="line">            w = self.get_conv_filter(name) <span class="comment"># 读到该层的卷积核</span></span><br><span class="line">            conv = tf.nn.conv2d(x, w, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) <span class="comment"># 卷积计算</span></span><br><span class="line">            conv_biases = self.get_bias(name) <span class="comment"># 读到偏置项</span></span><br><span class="line">            result = tf.nn.relu(tf.nn.bias_add(conv, conv_biases)) <span class="comment"># 加上偏置，并做激活计算</span></span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">    <span class="comment"># 定义获取卷积核的函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_conv_filter</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        <span class="comment"># 根据命名空间 name 从参数字典中取到对应的卷积核</span></span><br><span class="line">        <span class="keyword">return</span> tf.constant(self.data_dict[name][<span class="number">0</span>], name=<span class="string">"filter"</span>)</span><br><span class="line">    <span class="comment"># 定义获取偏置项的函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(self, name)</span>:</span></span><br><span class="line">    <span class="comment"># 根据命名空间 name 从参数字典中取到对应的卷积核</span></span><br><span class="line">        <span class="keyword">return</span> tf.constant(self.data_dict[name][<span class="number">1</span>], name=<span class="string">"biases"</span>)</span><br><span class="line">    <span class="comment"># 定义最大池化操作</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(self, x, name)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)</span><br><span class="line">    <span class="comment"># 定义全连接层的前向传播计算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fc_layer</span><span class="params">(self, x, name)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name): <span class="comment"># 根据命名空间 name 做全连接层的计算</span></span><br><span class="line">            shape = x.get_shape().as_list() <span class="comment"># 获取该层的维度信息列表</span></span><br><span class="line">            <span class="comment"># print ("fc_layer shape ",shape)</span></span><br><span class="line">            dim = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> shape[<span class="number">1</span>:]:</span><br><span class="line">                dim *= i <span class="comment"># 将每层的维度相乘</span></span><br><span class="line">            <span class="comment"># 改变特征图的形状，也就是将得到的多维特征做拉伸操作，只在进入第六层全连接层做该操作</span></span><br><span class="line">            x = tf.reshape(x, [<span class="number">-1</span>, dim])</span><br><span class="line">            w = self.get_fc_weight(name)<span class="comment"># 读到权重值</span></span><br><span class="line">            b = self.get_bias(name) <span class="comment"># 读到偏置项值</span></span><br><span class="line">            result = tf.nn.bias_add(tf.matmul(x, w), b) <span class="comment"># 对该层输入做加权求和，再加上偏置</span></span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">    <span class="comment"># 定义获取权重的函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_fc_weight</span><span class="params">(self, name)</span>:</span> <span class="comment"># 根据命名空间 name 从参数字典中取到对应的权重</span></span><br><span class="line">        <span class="keyword">return</span> tf.constant(self.data_dict[name][<span class="number">0</span>], name=<span class="string">"weights"</span>)</span><br></pre></td></tr></table></figure><p>utils.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io, transform</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line"></span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">'SimHei'</span>] <span class="comment"># 正常显示中文标签</span></span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span> <span class="comment"># 正常显示正负号</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span><span class="params">(path)</span>:</span></span><br><span class="line">    fig = plt.figure(<span class="string">"Centre and Resize"</span>)</span><br><span class="line">    img = io.imread(path) <span class="comment"># 根据传入的路径读入图片</span></span><br><span class="line">    img = img / <span class="number">255.0</span> <span class="comment"># 将像素归一化到[0,1]</span></span><br><span class="line">    <span class="comment"># 将该画布分为一行三列</span></span><br><span class="line">    ax0 = fig.add_subplot(<span class="number">131</span>) <span class="comment"># 把下面的图像放在该画布的第一个位置</span></span><br><span class="line">    ax0.set_xlabel(<span class="string">u'Original Picture'</span>) <span class="comment"># 添加子标签</span></span><br><span class="line">    ax0.imshow(img) <span class="comment"># 添加展示该图像</span></span><br><span class="line"></span><br><span class="line">    short_edge = min(img.shape[:<span class="number">2</span>]) <span class="comment"># 找到该图像的最短边</span></span><br><span class="line">    y = (img.shape[<span class="number">0</span>] - short_edge) // <span class="number">2</span></span><br><span class="line">    x = (img.shape[<span class="number">1</span>] - short_edge) // <span class="number">2</span> <span class="comment"># 把图像的 w 和 h 分别减去最短边，并求平均</span></span><br><span class="line">    crop_img = img[y:y+short_edge, x:x+short_edge] <span class="comment"># 取出切分出的中心图像</span></span><br><span class="line"></span><br><span class="line">    print(crop_img.shape)</span><br><span class="line">    ax1 = fig.add_subplot(<span class="number">132</span>) <span class="comment"># 把下面的图像放在该画布的第二个位置</span></span><br><span class="line">    ax1.set_xlabel(<span class="string">u"Centre Picture"</span>) <span class="comment"># 添加子标签</span></span><br><span class="line">    ax1.imshow(crop_img)</span><br><span class="line"></span><br><span class="line">    re_img = transform.resize(crop_img, (<span class="number">224</span>, <span class="number">224</span>)) <span class="comment"># resize 成固定的 imag_szie</span></span><br><span class="line"></span><br><span class="line">    ax2 = fig.add_subplot(<span class="number">133</span>) <span class="comment"># 把下面的图像放在该画布的第三个位置</span></span><br><span class="line">    ax2.set_xlabel(<span class="string">u"Resize Picture"</span>) <span class="comment"># 添加子标签</span></span><br><span class="line">    ax2.imshow(re_img)</span><br><span class="line"></span><br><span class="line">    img_ready = re_img.reshape((<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img_ready</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义百分比转换函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">percent</span><span class="params">(value)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'%.2f%%'</span> % (value * <span class="number">100</span>)</span><br></pre></td></tr></table></figure><p>Nclasses.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br><span class="line">819</span><br><span class="line">820</span><br><span class="line">821</span><br><span class="line">822</span><br><span class="line">823</span><br><span class="line">824</span><br><span class="line">825</span><br><span class="line">826</span><br><span class="line">827</span><br><span class="line">828</span><br><span class="line">829</span><br><span class="line">830</span><br><span class="line">831</span><br><span class="line">832</span><br><span class="line">833</span><br><span class="line">834</span><br><span class="line">835</span><br><span class="line">836</span><br><span class="line">837</span><br><span class="line">838</span><br><span class="line">839</span><br><span class="line">840</span><br><span class="line">841</span><br><span class="line">842</span><br><span class="line">843</span><br><span class="line">844</span><br><span class="line">845</span><br><span class="line">846</span><br><span class="line">847</span><br><span class="line">848</span><br><span class="line">849</span><br><span class="line">850</span><br><span class="line">851</span><br><span class="line">852</span><br><span class="line">853</span><br><span class="line">854</span><br><span class="line">855</span><br><span class="line">856</span><br><span class="line">857</span><br><span class="line">858</span><br><span class="line">859</span><br><span class="line">860</span><br><span class="line">861</span><br><span class="line">862</span><br><span class="line">863</span><br><span class="line">864</span><br><span class="line">865</span><br><span class="line">866</span><br><span class="line">867</span><br><span class="line">868</span><br><span class="line">869</span><br><span class="line">870</span><br><span class="line">871</span><br><span class="line">872</span><br><span class="line">873</span><br><span class="line">874</span><br><span class="line">875</span><br><span class="line">876</span><br><span class="line">877</span><br><span class="line">878</span><br><span class="line">879</span><br><span class="line">880</span><br><span class="line">881</span><br><span class="line">882</span><br><span class="line">883</span><br><span class="line">884</span><br><span class="line">885</span><br><span class="line">886</span><br><span class="line">887</span><br><span class="line">888</span><br><span class="line">889</span><br><span class="line">890</span><br><span class="line">891</span><br><span class="line">892</span><br><span class="line">893</span><br><span class="line">894</span><br><span class="line">895</span><br><span class="line">896</span><br><span class="line">897</span><br><span class="line">898</span><br><span class="line">899</span><br><span class="line">900</span><br><span class="line">901</span><br><span class="line">902</span><br><span class="line">903</span><br><span class="line">904</span><br><span class="line">905</span><br><span class="line">906</span><br><span class="line">907</span><br><span class="line">908</span><br><span class="line">909</span><br><span class="line">910</span><br><span class="line">911</span><br><span class="line">912</span><br><span class="line">913</span><br><span class="line">914</span><br><span class="line">915</span><br><span class="line">916</span><br><span class="line">917</span><br><span class="line">918</span><br><span class="line">919</span><br><span class="line">920</span><br><span class="line">921</span><br><span class="line">922</span><br><span class="line">923</span><br><span class="line">924</span><br><span class="line">925</span><br><span class="line">926</span><br><span class="line">927</span><br><span class="line">928</span><br><span class="line">929</span><br><span class="line">930</span><br><span class="line">931</span><br><span class="line">932</span><br><span class="line">933</span><br><span class="line">934</span><br><span class="line">935</span><br><span class="line">936</span><br><span class="line">937</span><br><span class="line">938</span><br><span class="line">939</span><br><span class="line">940</span><br><span class="line">941</span><br><span class="line">942</span><br><span class="line">943</span><br><span class="line">944</span><br><span class="line">945</span><br><span class="line">946</span><br><span class="line">947</span><br><span class="line">948</span><br><span class="line">949</span><br><span class="line">950</span><br><span class="line">951</span><br><span class="line">952</span><br><span class="line">953</span><br><span class="line">954</span><br><span class="line">955</span><br><span class="line">956</span><br><span class="line">957</span><br><span class="line">958</span><br><span class="line">959</span><br><span class="line">960</span><br><span class="line">961</span><br><span class="line">962</span><br><span class="line">963</span><br><span class="line">964</span><br><span class="line">965</span><br><span class="line">966</span><br><span class="line">967</span><br><span class="line">968</span><br><span class="line">969</span><br><span class="line">970</span><br><span class="line">971</span><br><span class="line">972</span><br><span class="line">973</span><br><span class="line">974</span><br><span class="line">975</span><br><span class="line">976</span><br><span class="line">977</span><br><span class="line">978</span><br><span class="line">979</span><br><span class="line">980</span><br><span class="line">981</span><br><span class="line">982</span><br><span class="line">983</span><br><span class="line">984</span><br><span class="line">985</span><br><span class="line">986</span><br><span class="line">987</span><br><span class="line">988</span><br><span class="line">989</span><br><span class="line">990</span><br><span class="line">991</span><br><span class="line">992</span><br><span class="line">993</span><br><span class="line">994</span><br><span class="line">995</span><br><span class="line">996</span><br><span class="line">997</span><br><span class="line">998</span><br><span class="line">999</span><br><span class="line">1000</span><br><span class="line">1001</span><br><span class="line">1002</span><br><span class="line">1003</span><br><span class="line">1004</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment"># 每个图像的真实标签，以及对应的索引值</span></span><br><span class="line">labels = &#123;</span><br><span class="line"> <span class="number">0</span>: <span class="string">'tench\n Tinca tinca'</span>,</span><br><span class="line"> <span class="number">1</span>: <span class="string">'goldfish\n Carassius auratus'</span>,</span><br><span class="line"> <span class="number">2</span>: <span class="string">'great white shark\n white shark\n man-eater\n man-eating shark\n Carcharodon carcharias'</span>,</span><br><span class="line"> <span class="number">3</span>: <span class="string">'tiger shark\n Galeocerdo cuvieri'</span>,</span><br><span class="line"> <span class="number">4</span>: <span class="string">'hammerhead\n hammerhead shark'</span>,</span><br><span class="line"> <span class="number">5</span>: <span class="string">'electric ray\n crampfish\n numbfish\n torpedo'</span>,</span><br><span class="line"> <span class="number">6</span>: <span class="string">'stingray'</span>,</span><br><span class="line"> <span class="number">7</span>: <span class="string">'cock'</span>,</span><br><span class="line"> <span class="number">8</span>: <span class="string">'hen'</span>,</span><br><span class="line"> <span class="number">9</span>: <span class="string">'ostrich\n Struthio camelus'</span>,</span><br><span class="line"> <span class="number">10</span>: <span class="string">'brambling\n Fringilla montifringilla'</span>,</span><br><span class="line"> <span class="number">11</span>: <span class="string">'goldfinch\n Carduelis carduelis'</span>,</span><br><span class="line"> <span class="number">12</span>: <span class="string">'house finch\n linnet\n Carpodacus mexicanus'</span>,</span><br><span class="line"> <span class="number">13</span>: <span class="string">'junco\n snowbird'</span>,</span><br><span class="line"> <span class="number">14</span>: <span class="string">'indigo bunting\n indigo finch\n indigo bird\n Passerina cyanea'</span>,</span><br><span class="line"> <span class="number">15</span>: <span class="string">'robin\n American robin\n Turdus migratorius'</span>,</span><br><span class="line"> <span class="number">16</span>: <span class="string">'bulbul'</span>,</span><br><span class="line"> <span class="number">17</span>: <span class="string">'jay'</span>,</span><br><span class="line"> <span class="number">18</span>: <span class="string">'magpie'</span>,</span><br><span class="line"> <span class="number">19</span>: <span class="string">'chickadee'</span>,</span><br><span class="line"> <span class="number">20</span>: <span class="string">'water ouzel\n dipper'</span>,</span><br><span class="line"> <span class="number">21</span>: <span class="string">'kite'</span>,</span><br><span class="line"> <span class="number">22</span>: <span class="string">'bald eagle\n American eagle\n Haliaeetus leucocephalus'</span>,</span><br><span class="line"> <span class="number">23</span>: <span class="string">'vulture'</span>,</span><br><span class="line"> <span class="number">24</span>: <span class="string">'great grey owl\n great gray owl\n Strix nebulosa'</span>,</span><br><span class="line"> <span class="number">25</span>: <span class="string">'European fire salamander\n Salamandra salamandra'</span>,</span><br><span class="line"> <span class="number">26</span>: <span class="string">'common newt\n Triturus vulgaris'</span>,</span><br><span class="line"> <span class="number">27</span>: <span class="string">'eft'</span>,</span><br><span class="line"> <span class="number">28</span>: <span class="string">'spotted salamander\n Ambystoma maculatum'</span>,</span><br><span class="line"> <span class="number">29</span>: <span class="string">'axolotl\n mud puppy\n Ambystoma mexicanum'</span>,</span><br><span class="line"> <span class="number">30</span>: <span class="string">'bullfrog\n Rana catesbeiana'</span>,</span><br><span class="line"> <span class="number">31</span>: <span class="string">'tree frog\n tree-frog'</span>,</span><br><span class="line"> <span class="number">32</span>: <span class="string">'tailed frog\n bell toad\n ribbed toad\n tailed toad\n Ascaphus trui'</span>,</span><br><span class="line"> <span class="number">33</span>: <span class="string">'loggerhead\n loggerhead turtle\n Caretta caretta'</span>,</span><br><span class="line"> <span class="number">34</span>: <span class="string">'leatherback turtle\n leatherback\n leathery turtle\n Dermochelys coriacea'</span>,</span><br><span class="line"> <span class="number">35</span>: <span class="string">'mud turtle'</span>,</span><br><span class="line"> <span class="number">36</span>: <span class="string">'terrapin'</span>,</span><br><span class="line"> <span class="number">37</span>: <span class="string">'box turtle\n box tortoise'</span>,</span><br><span class="line"> <span class="number">38</span>: <span class="string">'banded gecko'</span>,</span><br><span class="line"> <span class="number">39</span>: <span class="string">'common iguana\n iguana\n Iguana iguana'</span>,</span><br><span class="line"> <span class="number">40</span>: <span class="string">'American chameleon\n anole\n Anolis carolinensis'</span>,</span><br><span class="line"> <span class="number">41</span>: <span class="string">'whiptail\n whiptail lizard'</span>,</span><br><span class="line"> <span class="number">42</span>: <span class="string">'agama'</span>,</span><br><span class="line"> <span class="number">43</span>: <span class="string">'frilled lizard\n Chlamydosaurus kingi'</span>,</span><br><span class="line"> <span class="number">44</span>: <span class="string">'alligator lizard'</span>,</span><br><span class="line"> <span class="number">45</span>: <span class="string">'Gila monster\n Heloderma suspectum'</span>,</span><br><span class="line"> <span class="number">46</span>: <span class="string">'green lizard\n Lacerta viridis'</span>,</span><br><span class="line"> <span class="number">47</span>: <span class="string">'African chameleon\n Chamaeleo chamaeleon'</span>,</span><br><span class="line"> <span class="number">48</span>: <span class="string">'Komodo dragon\n Komodo lizard\n dragon lizard\n giant lizard\n Varanus komodoensis'</span>,</span><br><span class="line"> <span class="number">49</span>: <span class="string">'African crocodile\n Nile crocodile\n Crocodylus niloticus'</span>,</span><br><span class="line"> <span class="number">50</span>: <span class="string">'American alligator\n Alligator mississipiensis'</span>,</span><br><span class="line"> <span class="number">51</span>: <span class="string">'triceratops'</span>,</span><br><span class="line"> <span class="number">52</span>: <span class="string">'thunder snake\n worm snake\n Carphophis amoenus'</span>,</span><br><span class="line"> <span class="number">53</span>: <span class="string">'ringneck snake\n ring-necked snake\n ring snake'</span>,</span><br><span class="line"> <span class="number">54</span>: <span class="string">'hognose snake\n puff adder\n sand viper'</span>,</span><br><span class="line"> <span class="number">55</span>: <span class="string">'green snake\n grass snake'</span>,</span><br><span class="line"> <span class="number">56</span>: <span class="string">'king snake\n kingsnake'</span>,</span><br><span class="line"> <span class="number">57</span>: <span class="string">'garter snake\n grass snake'</span>,</span><br><span class="line"> <span class="number">58</span>: <span class="string">'water snake'</span>,</span><br><span class="line"> <span class="number">59</span>: <span class="string">'vine snake'</span>,</span><br><span class="line"> <span class="number">60</span>: <span class="string">'night snake\n Hypsiglena torquata'</span>,</span><br><span class="line"> <span class="number">61</span>: <span class="string">'boa constrictor\n Constrictor constrictor'</span>,</span><br><span class="line"> <span class="number">62</span>: <span class="string">'rock python\n rock snake\n Python sebae'</span>,</span><br><span class="line"> <span class="number">63</span>: <span class="string">'Indian cobra\n Naja naja'</span>,</span><br><span class="line"> <span class="number">64</span>: <span class="string">'green mamba'</span>,</span><br><span class="line"> <span class="number">65</span>: <span class="string">'sea snake'</span>,</span><br><span class="line"> <span class="number">66</span>: <span class="string">'horned viper\n cerastes\n sand viper\n horned asp\n Cerastes cornutus'</span>,</span><br><span class="line"> <span class="number">67</span>: <span class="string">'diamondback\n diamondback rattlesnake\n Crotalus adamanteus'</span>,</span><br><span class="line"> <span class="number">68</span>: <span class="string">'sidewinder\n horned rattlesnake\n Crotalus cerastes'</span>,</span><br><span class="line"> <span class="number">69</span>: <span class="string">'trilobite'</span>,</span><br><span class="line"> <span class="number">70</span>: <span class="string">'harvestman\n daddy longlegs\n Phalangium opilio'</span>,</span><br><span class="line"> <span class="number">71</span>: <span class="string">'scorpion'</span>,</span><br><span class="line"> <span class="number">72</span>: <span class="string">'black and gold garden spider\n Argiope aurantia'</span>,</span><br><span class="line"> <span class="number">73</span>: <span class="string">'barn spider\n Araneus cavaticus'</span>,</span><br><span class="line"> <span class="number">74</span>: <span class="string">'garden spider\n Aranea diademata'</span>,</span><br><span class="line"> <span class="number">75</span>: <span class="string">'black widow\n Latrodectus mactans'</span>,</span><br><span class="line"> <span class="number">76</span>: <span class="string">'tarantula'</span>,</span><br><span class="line"> <span class="number">77</span>: <span class="string">'wolf spider\n hunting spider'</span>,</span><br><span class="line"> <span class="number">78</span>: <span class="string">'tick'</span>,</span><br><span class="line"> <span class="number">79</span>: <span class="string">'centipede'</span>,</span><br><span class="line"> <span class="number">80</span>: <span class="string">'black grouse'</span>,</span><br><span class="line"> <span class="number">81</span>: <span class="string">'ptarmigan'</span>,</span><br><span class="line"> <span class="number">82</span>: <span class="string">'ruffed grouse\n partridge\n Bonasa umbellus'</span>,</span><br><span class="line"> <span class="number">83</span>: <span class="string">'prairie chicken\n prairie grouse\n prairie fowl'</span>,</span><br><span class="line"> <span class="number">84</span>: <span class="string">'peacock'</span>,</span><br><span class="line"> <span class="number">85</span>: <span class="string">'quail'</span>,</span><br><span class="line"> <span class="number">86</span>: <span class="string">'partridge'</span>,</span><br><span class="line"> <span class="number">87</span>: <span class="string">'African grey\n African gray\n Psittacus erithacus'</span>,</span><br><span class="line"> <span class="number">88</span>: <span class="string">'macaw'</span>,</span><br><span class="line"> <span class="number">89</span>: <span class="string">'sulphur-crested cockatoo\n Kakatoe galerita\n Cacatua galerita'</span>,</span><br><span class="line"> <span class="number">90</span>: <span class="string">'lorikeet'</span>,</span><br><span class="line"> <span class="number">91</span>: <span class="string">'coucal'</span>,</span><br><span class="line"> <span class="number">92</span>: <span class="string">'bee eater'</span>,</span><br><span class="line"> <span class="number">93</span>: <span class="string">'hornbill'</span>,</span><br><span class="line"> <span class="number">94</span>: <span class="string">'hummingbird'</span>,</span><br><span class="line"> <span class="number">95</span>: <span class="string">'jacamar'</span>,</span><br><span class="line"> <span class="number">96</span>: <span class="string">'toucan'</span>,</span><br><span class="line"> <span class="number">97</span>: <span class="string">'drake'</span>,</span><br><span class="line"> <span class="number">98</span>: <span class="string">'red-breasted merganser\n Mergus serrator'</span>,</span><br><span class="line"> <span class="number">99</span>: <span class="string">'goose'</span>,</span><br><span class="line"> <span class="number">100</span>: <span class="string">'black swan\n Cygnus atratus'</span>,</span><br><span class="line"> <span class="number">101</span>: <span class="string">'tusker'</span>,</span><br><span class="line"> <span class="number">102</span>: <span class="string">'echidna\n spiny anteater\n anteater'</span>,</span><br><span class="line"> <span class="number">103</span>: <span class="string">'platypus\n duckbill\n duckbilled platypus\n duck-billed platypus\n Ornithorhynchus anatinus'</span>,</span><br><span class="line"> <span class="number">104</span>: <span class="string">'wallaby\n brush kangaroo'</span>,</span><br><span class="line"> <span class="number">105</span>: <span class="string">'koala\n koala bear\n kangaroo bear\n native bear\n Phascolarctos cinereus'</span>,</span><br><span class="line"> <span class="number">106</span>: <span class="string">'wombat'</span>,</span><br><span class="line"> <span class="number">107</span>: <span class="string">'jellyfish'</span>,</span><br><span class="line"> <span class="number">108</span>: <span class="string">'sea anemone\n anemone'</span>,</span><br><span class="line"> <span class="number">109</span>: <span class="string">'brain coral'</span>,</span><br><span class="line"> <span class="number">110</span>: <span class="string">'flatworm\n platyhelminth'</span>,</span><br><span class="line"> <span class="number">111</span>: <span class="string">'nematode\n nematode worm\n roundworm'</span>,</span><br><span class="line"> <span class="number">112</span>: <span class="string">'conch'</span>,</span><br><span class="line"> <span class="number">113</span>: <span class="string">'snail'</span>,</span><br><span class="line"> <span class="number">114</span>: <span class="string">'slug'</span>,</span><br><span class="line"> <span class="number">115</span>: <span class="string">'sea slug\n nudibranch'</span>,</span><br><span class="line"> <span class="number">116</span>: <span class="string">'chiton\n coat-of-mail shell\n sea cradle\n polyplacophore'</span>,</span><br><span class="line"> <span class="number">117</span>: <span class="string">'chambered nautilus\n pearly nautilus\n nautilus'</span>,</span><br><span class="line"> <span class="number">118</span>: <span class="string">'Dungeness crab\n Cancer magister'</span>,</span><br><span class="line"> <span class="number">119</span>: <span class="string">'rock crab\n Cancer irroratus'</span>,</span><br><span class="line"> <span class="number">120</span>: <span class="string">'fiddler crab'</span>,</span><br><span class="line"> <span class="number">121</span>: <span class="string">'king crab\n Alaska crab\n Alaskan king crab\n Alaska king crab\n Paralithodes camtschatica'</span>,</span><br><span class="line"> <span class="number">122</span>: <span class="string">'American lobster\n Northern lobster\n Maine lobster\n Homarus americanus'</span>,</span><br><span class="line"> <span class="number">123</span>: <span class="string">'spiny lobster\n langouste\n rock lobster\n crawfish\n crayfish\n sea crawfish'</span>,</span><br><span class="line"> <span class="number">124</span>: <span class="string">'crayfish\n crawfish\n crawdad\n crawdaddy'</span>,</span><br><span class="line"> <span class="number">125</span>: <span class="string">'hermit crab'</span>,</span><br><span class="line"> <span class="number">126</span>: <span class="string">'isopod'</span>,</span><br><span class="line"> <span class="number">127</span>: <span class="string">'white stork\n Ciconia ciconia'</span>,</span><br><span class="line"> <span class="number">128</span>: <span class="string">'black stork\n Ciconia nigra'</span>,</span><br><span class="line"> <span class="number">129</span>: <span class="string">'spoonbill'</span>,</span><br><span class="line"> <span class="number">130</span>: <span class="string">'flamingo'</span>,</span><br><span class="line"> <span class="number">131</span>: <span class="string">'little blue heron\n Egretta caerulea'</span>,</span><br><span class="line"> <span class="number">132</span>: <span class="string">'American egret\n great white heron\n Egretta albus'</span>,</span><br><span class="line"> <span class="number">133</span>: <span class="string">'bittern'</span>,</span><br><span class="line"> <span class="number">134</span>: <span class="string">'crane'</span>,</span><br><span class="line"> <span class="number">135</span>: <span class="string">'limpkin\n Aramus pictus'</span>,</span><br><span class="line"> <span class="number">136</span>: <span class="string">'European gallinule\n Porphyrio porphyrio'</span>,</span><br><span class="line"> <span class="number">137</span>: <span class="string">'American coot\n marsh hen\n mud hen\n water hen\n Fulica americana'</span>,</span><br><span class="line"> <span class="number">138</span>: <span class="string">'bustard'</span>,</span><br><span class="line"> <span class="number">139</span>: <span class="string">'ruddy turnstone\n Arenaria interpres'</span>,</span><br><span class="line"> <span class="number">140</span>: <span class="string">'red-backed sandpiper\n dunlin\n Erolia alpina'</span>,</span><br><span class="line"> <span class="number">141</span>: <span class="string">'redshank\n Tringa totanus'</span>,</span><br><span class="line"> <span class="number">142</span>: <span class="string">'dowitcher'</span>,</span><br><span class="line"> <span class="number">143</span>: <span class="string">'oystercatcher\n oyster catcher'</span>,</span><br><span class="line"> <span class="number">144</span>: <span class="string">'pelican'</span>,</span><br><span class="line"> <span class="number">145</span>: <span class="string">'king penguin\n Aptenodytes patagonica'</span>,</span><br><span class="line"> <span class="number">146</span>: <span class="string">'albatross\n mollymawk'</span>,</span><br><span class="line"> <span class="number">147</span>: <span class="string">'grey whale\n gray whale\n devilfish\n Eschrichtius gibbosus\n Eschrichtius robustus'</span>,</span><br><span class="line"> <span class="number">148</span>: <span class="string">'killer whale\n killer\n orca\n grampus\n sea wolf\n Orcinus orca'</span>,</span><br><span class="line"> <span class="number">149</span>: <span class="string">'dugong\n Dugong dugon'</span>,</span><br><span class="line"> <span class="number">150</span>: <span class="string">'sea lion'</span>,</span><br><span class="line"> <span class="number">151</span>: <span class="string">'Chihuahua'</span>,</span><br><span class="line"> <span class="number">152</span>: <span class="string">'Japanese spaniel'</span>,</span><br><span class="line"> <span class="number">153</span>: <span class="string">'Maltese dog\n Maltese terrier\n Maltese'</span>,</span><br><span class="line"> <span class="number">154</span>: <span class="string">'Pekinese\n Pekingese\n Peke'</span>,</span><br><span class="line"> <span class="number">155</span>: <span class="string">'Shih-Tzu'</span>,</span><br><span class="line"> <span class="number">156</span>: <span class="string">'Blenheim spaniel'</span>,</span><br><span class="line"> <span class="number">157</span>: <span class="string">'papillon'</span>,</span><br><span class="line"> <span class="number">158</span>: <span class="string">'toy terrier'</span>,</span><br><span class="line"> <span class="number">159</span>: <span class="string">'Rhodesian ridgeback'</span>,</span><br><span class="line"> <span class="number">160</span>: <span class="string">'Afghan hound\n Afghan'</span>,</span><br><span class="line"> <span class="number">161</span>: <span class="string">'basset\n basset hound'</span>,</span><br><span class="line"> <span class="number">162</span>: <span class="string">'beagle'</span>,</span><br><span class="line"> <span class="number">163</span>: <span class="string">'bloodhound\n sleuthhound'</span>,</span><br><span class="line"> <span class="number">164</span>: <span class="string">'bluetick'</span>,</span><br><span class="line"> <span class="number">165</span>: <span class="string">'black-and-tan coonhound'</span>,</span><br><span class="line"> <span class="number">166</span>: <span class="string">'Walker hound\n Walker foxhound'</span>,</span><br><span class="line"> <span class="number">167</span>: <span class="string">'English foxhound'</span>,</span><br><span class="line"> <span class="number">168</span>: <span class="string">'redbone'</span>,</span><br><span class="line"> <span class="number">169</span>: <span class="string">'borzoi\n Russian wolfhound'</span>,</span><br><span class="line"> <span class="number">170</span>: <span class="string">'Irish wolfhound'</span>,</span><br><span class="line"> <span class="number">171</span>: <span class="string">'Italian greyhound'</span>,</span><br><span class="line"> <span class="number">172</span>: <span class="string">'whippet'</span>,</span><br><span class="line"> <span class="number">173</span>: <span class="string">'Ibizan hound\n Ibizan Podenco'</span>,</span><br><span class="line"> <span class="number">174</span>: <span class="string">'Norwegian elkhound\n elkhound'</span>,</span><br><span class="line"> <span class="number">175</span>: <span class="string">'otterhound\n otter hound'</span>,</span><br><span class="line"> <span class="number">176</span>: <span class="string">'Saluki\n gazelle hound'</span>,</span><br><span class="line"> <span class="number">177</span>: <span class="string">'Scottish deerhound\n deerhound'</span>,</span><br><span class="line"> <span class="number">178</span>: <span class="string">'Weimaraner'</span>,</span><br><span class="line"> <span class="number">179</span>: <span class="string">'Staffordshire bullterrier\n Staffordshire bull terrier'</span>,</span><br><span class="line"> <span class="number">180</span>: <span class="string">'American Staffordshire terrier\n Staffordshire terrier\n American pit bull terrier\n pit bull terrier'</span>,</span><br><span class="line"> <span class="number">181</span>: <span class="string">'Bedlington terrier'</span>,</span><br><span class="line"> <span class="number">182</span>: <span class="string">'Border terrier'</span>,</span><br><span class="line"> <span class="number">183</span>: <span class="string">'Kerry blue terrier'</span>,</span><br><span class="line"> <span class="number">184</span>: <span class="string">'Irish terrier'</span>,</span><br><span class="line"> <span class="number">185</span>: <span class="string">'Norfolk terrier'</span>,</span><br><span class="line"> <span class="number">186</span>: <span class="string">'Norwich terrier'</span>,</span><br><span class="line"> <span class="number">187</span>: <span class="string">'Yorkshire terrier'</span>,</span><br><span class="line"> <span class="number">188</span>: <span class="string">'wire-haired fox terrier'</span>,</span><br><span class="line"> <span class="number">189</span>: <span class="string">'Lakeland terrier'</span>,</span><br><span class="line"> <span class="number">190</span>: <span class="string">'Sealyham terrier\n Sealyham'</span>,</span><br><span class="line"> <span class="number">191</span>: <span class="string">'Airedale\n Airedale terrier'</span>,</span><br><span class="line"> <span class="number">192</span>: <span class="string">'cairn\n cairn terrier'</span>,</span><br><span class="line"> <span class="number">193</span>: <span class="string">'Australian terrier'</span>,</span><br><span class="line"> <span class="number">194</span>: <span class="string">'Dandie Dinmont\n Dandie Dinmont terrier'</span>,</span><br><span class="line"> <span class="number">195</span>: <span class="string">'Boston bull\n Boston terrier'</span>,</span><br><span class="line"> <span class="number">196</span>: <span class="string">'miniature schnauzer'</span>,</span><br><span class="line"> <span class="number">197</span>: <span class="string">'giant schnauzer'</span>,</span><br><span class="line"> <span class="number">198</span>: <span class="string">'standard schnauzer'</span>,</span><br><span class="line"> <span class="number">199</span>: <span class="string">'Scotch terrier\n Scottish terrier\n Scottie'</span>,</span><br><span class="line"> <span class="number">200</span>: <span class="string">'Tibetan terrier\n chrysanthemum dog'</span>,</span><br><span class="line"> <span class="number">201</span>: <span class="string">'silky terrier\n Sydney silky'</span>,</span><br><span class="line"> <span class="number">202</span>: <span class="string">'soft-coated wheaten terrier'</span>,</span><br><span class="line"> <span class="number">203</span>: <span class="string">'West Highland white terrier'</span>,</span><br><span class="line"> <span class="number">204</span>: <span class="string">'Lhasa\n Lhasa apso'</span>,</span><br><span class="line"> <span class="number">205</span>: <span class="string">'flat-coated retriever'</span>,</span><br><span class="line"> <span class="number">206</span>: <span class="string">'curly-coated retriever'</span>,</span><br><span class="line"> <span class="number">207</span>: <span class="string">'golden retriever'</span>,</span><br><span class="line"> <span class="number">208</span>: <span class="string">'Labrador retriever'</span>,</span><br><span class="line"> <span class="number">209</span>: <span class="string">'Chesapeake Bay retriever'</span>,</span><br><span class="line"> <span class="number">210</span>: <span class="string">'German short-haired pointer'</span>,</span><br><span class="line"> <span class="number">211</span>: <span class="string">'vizsla\n Hungarian pointer'</span>,</span><br><span class="line"> <span class="number">212</span>: <span class="string">'English setter'</span>,</span><br><span class="line"> <span class="number">213</span>: <span class="string">'Irish setter\n red setter'</span>,</span><br><span class="line"> <span class="number">214</span>: <span class="string">'Gordon setter'</span>,</span><br><span class="line"> <span class="number">215</span>: <span class="string">'Brittany spaniel'</span>,</span><br><span class="line"> <span class="number">216</span>: <span class="string">'clumber\n clumber spaniel'</span>,</span><br><span class="line"> <span class="number">217</span>: <span class="string">'English springer\n English springer spaniel'</span>,</span><br><span class="line"> <span class="number">218</span>: <span class="string">'Welsh springer spaniel'</span>,</span><br><span class="line"> <span class="number">219</span>: <span class="string">'cocker spaniel\n English cocker spaniel\n cocker'</span>,</span><br><span class="line"> <span class="number">220</span>: <span class="string">'Sussex spaniel'</span>,</span><br><span class="line"> <span class="number">221</span>: <span class="string">'Irish water spaniel'</span>,</span><br><span class="line"> <span class="number">222</span>: <span class="string">'kuvasz'</span>,</span><br><span class="line"> <span class="number">223</span>: <span class="string">'schipperke'</span>,</span><br><span class="line"> <span class="number">224</span>: <span class="string">'groenendael'</span>,</span><br><span class="line"> <span class="number">225</span>: <span class="string">'malinois'</span>,</span><br><span class="line"> <span class="number">226</span>: <span class="string">'briard'</span>,</span><br><span class="line"> <span class="number">227</span>: <span class="string">'kelpie'</span>,</span><br><span class="line"> <span class="number">228</span>: <span class="string">'komondor'</span>,</span><br><span class="line"> <span class="number">229</span>: <span class="string">'Old English sheepdog\n bobtail'</span>,</span><br><span class="line"> <span class="number">230</span>: <span class="string">'Shetland sheepdog\n Shetland sheep dog\n Shetland'</span>,</span><br><span class="line"> <span class="number">231</span>: <span class="string">'collie'</span>,</span><br><span class="line"> <span class="number">232</span>: <span class="string">'Border collie'</span>,</span><br><span class="line"> <span class="number">233</span>: <span class="string">'Bouvier des Flandres\n Bouviers des Flandres'</span>,</span><br><span class="line"> <span class="number">234</span>: <span class="string">'Rottweiler'</span>,</span><br><span class="line"> <span class="number">235</span>: <span class="string">'German shepherd\n German shepherd dog\n German police dog\n alsatian'</span>,</span><br><span class="line"> <span class="number">236</span>: <span class="string">'Doberman\n Doberman pinscher'</span>,</span><br><span class="line"> <span class="number">237</span>: <span class="string">'miniature pinscher'</span>,</span><br><span class="line"> <span class="number">238</span>: <span class="string">'Greater Swiss Mountain dog'</span>,</span><br><span class="line"> <span class="number">239</span>: <span class="string">'Bernese mountain dog'</span>,</span><br><span class="line"> <span class="number">240</span>: <span class="string">'Appenzeller'</span>,</span><br><span class="line"> <span class="number">241</span>: <span class="string">'EntleBucher'</span>,</span><br><span class="line"> <span class="number">242</span>: <span class="string">'boxer'</span>,</span><br><span class="line"> <span class="number">243</span>: <span class="string">'bull mastiff'</span>,</span><br><span class="line"> <span class="number">244</span>: <span class="string">'Tibetan mastiff'</span>,</span><br><span class="line"> <span class="number">245</span>: <span class="string">'French bulldog'</span>,</span><br><span class="line"> <span class="number">246</span>: <span class="string">'Great Dane'</span>,</span><br><span class="line"> <span class="number">247</span>: <span class="string">'Saint Bernard\n St Bernard'</span>,</span><br><span class="line"> <span class="number">248</span>: <span class="string">'Eskimo dog\n husky'</span>,</span><br><span class="line"> <span class="number">249</span>: <span class="string">'malamute\n malemute\n Alaskan malamute'</span>,</span><br><span class="line"> <span class="number">250</span>: <span class="string">'Siberian husky'</span>,</span><br><span class="line"> <span class="number">251</span>: <span class="string">'dalmatian\n coach dog\n carriage dog'</span>,</span><br><span class="line"> <span class="number">252</span>: <span class="string">'affenpinscher\n monkey pinscher\n monkey dog'</span>,</span><br><span class="line"> <span class="number">253</span>: <span class="string">'basenji'</span>,</span><br><span class="line"> <span class="number">254</span>: <span class="string">'pug\n pug-dog'</span>,</span><br><span class="line"> <span class="number">255</span>: <span class="string">'Leonberg'</span>,</span><br><span class="line"> <span class="number">256</span>: <span class="string">'Newfoundland\n Newfoundland dog'</span>,</span><br><span class="line"> <span class="number">257</span>: <span class="string">'Great Pyrenees'</span>,</span><br><span class="line"> <span class="number">258</span>: <span class="string">'Samoyed\n Samoyede'</span>,</span><br><span class="line"> <span class="number">259</span>: <span class="string">'Pomeranian'</span>,</span><br><span class="line"> <span class="number">260</span>: <span class="string">'chow\n chow chow'</span>,</span><br><span class="line"> <span class="number">261</span>: <span class="string">'keeshond'</span>,</span><br><span class="line"> <span class="number">262</span>: <span class="string">'Brabancon griffon'</span>,</span><br><span class="line"> <span class="number">263</span>: <span class="string">'Pembroke\n Pembroke Welsh corgi'</span>,</span><br><span class="line"> <span class="number">264</span>: <span class="string">'Cardigan\n Cardigan Welsh corgi'</span>,</span><br><span class="line"> <span class="number">265</span>: <span class="string">'toy poodle'</span>,</span><br><span class="line"> <span class="number">266</span>: <span class="string">'miniature poodle'</span>,</span><br><span class="line"> <span class="number">267</span>: <span class="string">'standard poodle'</span>,</span><br><span class="line"> <span class="number">268</span>: <span class="string">'Mexican hairless'</span>,</span><br><span class="line"> <span class="number">269</span>: <span class="string">'timber wolf\n grey wolf\n gray wolf\n Canis lupus'</span>,</span><br><span class="line"> <span class="number">270</span>: <span class="string">'white wolf\n Arctic wolf\n Canis lupus tundrarum'</span>,</span><br><span class="line"> <span class="number">271</span>: <span class="string">'red wolf\n maned wolf\n Canis rufus\n Canis niger'</span>,</span><br><span class="line"> <span class="number">272</span>: <span class="string">'coyote\n prairie wolf\n brush wolf\n Canis latrans'</span>,</span><br><span class="line"> <span class="number">273</span>: <span class="string">'dingo\n warrigal\n warragal\n Canis dingo'</span>,</span><br><span class="line"> <span class="number">274</span>: <span class="string">'dhole\n Cuon alpinus'</span>,</span><br><span class="line"> <span class="number">275</span>: <span class="string">'African hunting dog\n hyena dog\n Cape hunting dog\n Lycaon pictus'</span>,</span><br><span class="line"> <span class="number">276</span>: <span class="string">'hyena\n hyaena'</span>,</span><br><span class="line"> <span class="number">277</span>: <span class="string">'red fox\n Vulpes vulpes'</span>,</span><br><span class="line"> <span class="number">278</span>: <span class="string">'kit fox\n Vulpes macrotis'</span>,</span><br><span class="line"> <span class="number">279</span>: <span class="string">'Arctic fox\n white fox\n Alopex lagopus'</span>,</span><br><span class="line"> <span class="number">280</span>: <span class="string">'grey fox\n gray fox\n Urocyon cinereoargenteus'</span>,</span><br><span class="line"> <span class="number">281</span>: <span class="string">'tabby\n tabby cat'</span>,</span><br><span class="line"> <span class="number">282</span>: <span class="string">'tiger cat'</span>,</span><br><span class="line"> <span class="number">283</span>: <span class="string">'Persian cat'</span>,</span><br><span class="line"> <span class="number">284</span>: <span class="string">'Siamese cat\n Siamese'</span>,</span><br><span class="line"> <span class="number">285</span>: <span class="string">'Egyptian cat'</span>,</span><br><span class="line"> <span class="number">286</span>: <span class="string">'cougar\n puma\n catamount\n mountain lion\n painter\n panther\n Felis concolor'</span>,</span><br><span class="line"> <span class="number">287</span>: <span class="string">'lynx\n catamount'</span>,</span><br><span class="line"> <span class="number">288</span>: <span class="string">'leopard\n Panthera pardus'</span>,</span><br><span class="line"> <span class="number">289</span>: <span class="string">'snow leopard\n ounce\n Panthera uncia'</span>,</span><br><span class="line"> <span class="number">290</span>: <span class="string">'jaguar\n panther\n Panthera onca\n Felis onca'</span>,</span><br><span class="line"> <span class="number">291</span>: <span class="string">'lion\n king of beasts\n Panthera leo'</span>,</span><br><span class="line"> <span class="number">292</span>: <span class="string">'tiger\n Panthera tigris'</span>,</span><br><span class="line"> <span class="number">293</span>: <span class="string">'cheetah\n chetah\n Acinonyx jubatus'</span>,</span><br><span class="line"> <span class="number">294</span>: <span class="string">'brown bear\n bruin\n Ursus arctos'</span>,</span><br><span class="line"> <span class="number">295</span>: <span class="string">'American black bear\n black bear\n Ursus americanus\n Euarctos americanus'</span>,</span><br><span class="line"> <span class="number">296</span>: <span class="string">'ice bear\n polar bear\n Ursus Maritimus\n Thalarctos maritimus'</span>,</span><br><span class="line"> <span class="number">297</span>: <span class="string">'sloth bear\n Melursus ursinus\n Ursus ursinus'</span>,</span><br><span class="line"> <span class="number">298</span>: <span class="string">'mongoose'</span>,</span><br><span class="line"> <span class="number">299</span>: <span class="string">'meerkat\n mierkat'</span>,</span><br><span class="line"> <span class="number">300</span>: <span class="string">'tiger beetle'</span>,</span><br><span class="line"> <span class="number">301</span>: <span class="string">'ladybug\n ladybeetle\n lady beetle\n ladybird\n ladybird beetle'</span>,</span><br><span class="line"> <span class="number">302</span>: <span class="string">'ground beetle\n carabid beetle'</span>,</span><br><span class="line"> <span class="number">303</span>: <span class="string">'long-horned beetle\n longicorn\n longicorn beetle'</span>,</span><br><span class="line"> <span class="number">304</span>: <span class="string">'leaf beetle\n chrysomelid'</span>,</span><br><span class="line"> <span class="number">305</span>: <span class="string">'dung beetle'</span>,</span><br><span class="line"> <span class="number">306</span>: <span class="string">'rhinoceros beetle'</span>,</span><br><span class="line"> <span class="number">307</span>: <span class="string">'weevil'</span>,</span><br><span class="line"> <span class="number">308</span>: <span class="string">'fly'</span>,</span><br><span class="line"> <span class="number">309</span>: <span class="string">'bee'</span>,</span><br><span class="line"> <span class="number">310</span>: <span class="string">'ant\n emmet\n pismire'</span>,</span><br><span class="line"> <span class="number">311</span>: <span class="string">'grasshopper\n hopper'</span>,</span><br><span class="line"> <span class="number">312</span>: <span class="string">'cricket'</span>,</span><br><span class="line"> <span class="number">313</span>: <span class="string">'walking stick\n walkingstick\n stick insect'</span>,</span><br><span class="line"> <span class="number">314</span>: <span class="string">'cockroach\n roach'</span>,</span><br><span class="line"> <span class="number">315</span>: <span class="string">'mantis\n mantid'</span>,</span><br><span class="line"> <span class="number">316</span>: <span class="string">'cicada\n cicala'</span>,</span><br><span class="line"> <span class="number">317</span>: <span class="string">'leafhopper'</span>,</span><br><span class="line"> <span class="number">318</span>: <span class="string">'lacewing\n lacewing fly'</span>,</span><br><span class="line"> <span class="number">319</span>: <span class="string">"dragonfly\n darning needle\n devil's darning needle\n sewing needle\n snake feeder\n snake doctor\n mosquito hawk\n skeeter hawk"</span>,</span><br><span class="line"> <span class="number">320</span>: <span class="string">'damselfly'</span>,</span><br><span class="line"> <span class="number">321</span>: <span class="string">'admiral'</span>,</span><br><span class="line"> <span class="number">322</span>: <span class="string">'ringlet\n ringlet butterfly'</span>,</span><br><span class="line"> <span class="number">323</span>: <span class="string">'monarch\n monarch butterfly\n milkweed butterfly\n Danaus plexippus'</span>,</span><br><span class="line"> <span class="number">324</span>: <span class="string">'cabbage butterfly'</span>,</span><br><span class="line"> <span class="number">325</span>: <span class="string">'sulphur butterfly\n sulfur butterfly'</span>,</span><br><span class="line"> <span class="number">326</span>: <span class="string">'lycaenid\n lycaenid butterfly'</span>,</span><br><span class="line"> <span class="number">327</span>: <span class="string">'starfish\n sea star'</span>,</span><br><span class="line"> <span class="number">328</span>: <span class="string">'sea urchin'</span>,</span><br><span class="line"> <span class="number">329</span>: <span class="string">'sea cucumber\n holothurian'</span>,</span><br><span class="line"> <span class="number">330</span>: <span class="string">'wood rabbit\n cottontail\n cottontail rabbit'</span>,</span><br><span class="line"> <span class="number">331</span>: <span class="string">'hare'</span>,</span><br><span class="line"> <span class="number">332</span>: <span class="string">'Angora\n Angora rabbit'</span>,</span><br><span class="line"> <span class="number">333</span>: <span class="string">'hamster'</span>,</span><br><span class="line"> <span class="number">334</span>: <span class="string">'porcupine\n hedgehog'</span>,</span><br><span class="line"> <span class="number">335</span>: <span class="string">'fox squirrel\n eastern fox squirrel\n Sciurus niger'</span>,</span><br><span class="line"> <span class="number">336</span>: <span class="string">'marmot'</span>,</span><br><span class="line"> <span class="number">337</span>: <span class="string">'beaver'</span>,</span><br><span class="line"> <span class="number">338</span>: <span class="string">'guinea pig\n Cavia cobaya'</span>,</span><br><span class="line"> <span class="number">339</span>: <span class="string">'sorrel'</span>,</span><br><span class="line"> <span class="number">340</span>: <span class="string">'zebra'</span>,</span><br><span class="line"> <span class="number">341</span>: <span class="string">'hog\n pig\n grunter\n squealer\n Sus scrofa'</span>,</span><br><span class="line"> <span class="number">342</span>: <span class="string">'wild boar\n boar\n Sus scrofa'</span>,</span><br><span class="line"> <span class="number">343</span>: <span class="string">'warthog'</span>,</span><br><span class="line"> <span class="number">344</span>: <span class="string">'hippopotamus\n hippo\n river horse\n Hippopotamus amphibius'</span>,</span><br><span class="line"> <span class="number">345</span>: <span class="string">'ox'</span>,</span><br><span class="line"> <span class="number">346</span>: <span class="string">'water buffalo\n water ox\n Asiatic buffalo\n Bubalus bubalis'</span>,</span><br><span class="line"> <span class="number">347</span>: <span class="string">'bison'</span>,</span><br><span class="line"> <span class="number">348</span>: <span class="string">'ram\n tup'</span>,</span><br><span class="line"> <span class="number">349</span>: <span class="string">'bighorn\n bighorn sheep\n cimarron\n Rocky Mountain bighorn\n Rocky Mountain sheep\n Ovis canadensis'</span>,</span><br><span class="line"> <span class="number">350</span>: <span class="string">'ibex\n Capra ibex'</span>,</span><br><span class="line"> <span class="number">351</span>: <span class="string">'hartebeest'</span>,</span><br><span class="line"> <span class="number">352</span>: <span class="string">'impala\n Aepyceros melampus'</span>,</span><br><span class="line"> <span class="number">353</span>: <span class="string">'gazelle'</span>,</span><br><span class="line"> <span class="number">354</span>: <span class="string">'Arabian camel\n dromedary\n Camelus dromedarius'</span>,</span><br><span class="line"> <span class="number">355</span>: <span class="string">'llama'</span>,</span><br><span class="line"> <span class="number">356</span>: <span class="string">'weasel'</span>,</span><br><span class="line"> <span class="number">357</span>: <span class="string">'mink'</span>,</span><br><span class="line"> <span class="number">358</span>: <span class="string">'polecat\n fitch\n foulmart\n foumart\n Mustela putorius'</span>,</span><br><span class="line"> <span class="number">359</span>: <span class="string">'black-footed ferret\n ferret\n Mustela nigripes'</span>,</span><br><span class="line"> <span class="number">360</span>: <span class="string">'otter'</span>,</span><br><span class="line"> <span class="number">361</span>: <span class="string">'skunk\n polecat\n wood pussy'</span>,</span><br><span class="line"> <span class="number">362</span>: <span class="string">'badger'</span>,</span><br><span class="line"> <span class="number">363</span>: <span class="string">'armadillo'</span>,</span><br><span class="line"> <span class="number">364</span>: <span class="string">'three-toed sloth\n ai\n Bradypus tridactylus'</span>,</span><br><span class="line"> <span class="number">365</span>: <span class="string">'orangutan\n orang\n orangutang\n Pongo pygmaeus'</span>,</span><br><span class="line"> <span class="number">366</span>: <span class="string">'gorilla\n Gorilla gorilla'</span>,</span><br><span class="line"> <span class="number">367</span>: <span class="string">'chimpanzee\n chimp\n Pan troglodytes'</span>,</span><br><span class="line"> <span class="number">368</span>: <span class="string">'gibbon\n Hylobates lar'</span>,</span><br><span class="line"> <span class="number">369</span>: <span class="string">'siamang\n Hylobates syndactylus\n Symphalangus syndactylus'</span>,</span><br><span class="line"> <span class="number">370</span>: <span class="string">'guenon\n guenon monkey'</span>,</span><br><span class="line"> <span class="number">371</span>: <span class="string">'patas\n hussar monkey\n Erythrocebus patas'</span>,</span><br><span class="line"> <span class="number">372</span>: <span class="string">'baboon'</span>,</span><br><span class="line"> <span class="number">373</span>: <span class="string">'macaque'</span>,</span><br><span class="line"> <span class="number">374</span>: <span class="string">'langur'</span>,</span><br><span class="line"> <span class="number">375</span>: <span class="string">'colobus\n colobus monkey'</span>,</span><br><span class="line"> <span class="number">376</span>: <span class="string">'proboscis monkey\n Nasalis larvatus'</span>,</span><br><span class="line"> <span class="number">377</span>: <span class="string">'marmoset'</span>,</span><br><span class="line"> <span class="number">378</span>: <span class="string">'capuchin\n ringtail\n Cebus capucinus'</span>,</span><br><span class="line"> <span class="number">379</span>: <span class="string">'howler monkey\n howler'</span>,</span><br><span class="line"> <span class="number">380</span>: <span class="string">'titi\n titi monkey'</span>,</span><br><span class="line"> <span class="number">381</span>: <span class="string">'spider monkey\n Ateles geoffroyi'</span>,</span><br><span class="line"> <span class="number">382</span>: <span class="string">'squirrel monkey\n Saimiri sciureus'</span>,</span><br><span class="line"> <span class="number">383</span>: <span class="string">'Madagascar cat\n ring-tailed lemur\n Lemur catta'</span>,</span><br><span class="line"> <span class="number">384</span>: <span class="string">'indri\n indris\n Indri indri\n Indri brevicaudatus'</span>,</span><br><span class="line"> <span class="number">385</span>: <span class="string">'Indian elephant\n Elephas maximus'</span>,</span><br><span class="line"> <span class="number">386</span>: <span class="string">'African elephant\n Loxodonta africana'</span>,</span><br><span class="line"> <span class="number">387</span>: <span class="string">'lesser panda\n red panda\n panda\n bear cat\n cat bear\n Ailurus fulgens'</span>,</span><br><span class="line"> <span class="number">388</span>: <span class="string">'giant panda\n panda\n panda bear\n coon bear\n Ailuropoda melanoleuca'</span>,</span><br><span class="line"> <span class="number">389</span>: <span class="string">'barracouta\n snoek'</span>,</span><br><span class="line"> <span class="number">390</span>: <span class="string">'eel'</span>,</span><br><span class="line"> <span class="number">391</span>: <span class="string">'coho\n cohoe\n coho salmon\n blue jack\n silver salmon\n Oncorhynchus kisutch'</span>,</span><br><span class="line"> <span class="number">392</span>: <span class="string">'rock beauty\n Holocanthus tricolor'</span>,</span><br><span class="line"> <span class="number">393</span>: <span class="string">'anemone fish'</span>,</span><br><span class="line"> <span class="number">394</span>: <span class="string">'sturgeon'</span>,</span><br><span class="line"> <span class="number">395</span>: <span class="string">'gar\n garfish\n garpike\n billfish\n Lepisosteus osseus'</span>,</span><br><span class="line"> <span class="number">396</span>: <span class="string">'lionfish'</span>,</span><br><span class="line"> <span class="number">397</span>: <span class="string">'puffer\n pufferfish\n blowfish\n globefish'</span>,</span><br><span class="line"> <span class="number">398</span>: <span class="string">'abacus'</span>,</span><br><span class="line"> <span class="number">399</span>: <span class="string">'abaya'</span>,</span><br><span class="line"> <span class="number">400</span>: <span class="string">"academic gown\n academic robe\n judge's robe"</span>,</span><br><span class="line"> <span class="number">401</span>: <span class="string">'accordion\n piano accordion\n squeeze box'</span>,</span><br><span class="line"> <span class="number">402</span>: <span class="string">'acoustic guitar'</span>,</span><br><span class="line"> <span class="number">403</span>: <span class="string">'aircraft carrier\n carrier\n flattop\n attack aircraft carrier'</span>,</span><br><span class="line"> <span class="number">404</span>: <span class="string">'airliner'</span>,</span><br><span class="line"> <span class="number">405</span>: <span class="string">'airship\n dirigible'</span>,</span><br><span class="line"> <span class="number">406</span>: <span class="string">'altar'</span>,</span><br><span class="line"> <span class="number">407</span>: <span class="string">'ambulance'</span>,</span><br><span class="line"> <span class="number">408</span>: <span class="string">'amphibian\n amphibious vehicle'</span>,</span><br><span class="line"> <span class="number">409</span>: <span class="string">'analog clock'</span>,</span><br><span class="line"> <span class="number">410</span>: <span class="string">'apiary\n bee house'</span>,</span><br><span class="line"> <span class="number">411</span>: <span class="string">'apron'</span>,</span><br><span class="line"> <span class="number">412</span>: <span class="string">'ashcan\n trash can\n garbage can\n wastebin\n ash bin\n ash-bin\n ashbin\n dustbin\n trash barrel\n trash bin'</span>,</span><br><span class="line"> <span class="number">413</span>: <span class="string">'assault rifle\n assault gun'</span>,</span><br><span class="line"> <span class="number">414</span>: <span class="string">'backpack\n back pack\n knapsack\n packsack\n rucksack\n haversack'</span>,</span><br><span class="line"> <span class="number">415</span>: <span class="string">'bakery\n bakeshop\n bakehouse'</span>,</span><br><span class="line"> <span class="number">416</span>: <span class="string">'balance beam\n beam'</span>,</span><br><span class="line"> <span class="number">417</span>: <span class="string">'balloon'</span>,</span><br><span class="line"> <span class="number">418</span>: <span class="string">'ballpoint\n ballpoint pen\n ballpen\n Biro'</span>,</span><br><span class="line"> <span class="number">419</span>: <span class="string">'Band Aid'</span>,</span><br><span class="line"> <span class="number">420</span>: <span class="string">'banjo'</span>,</span><br><span class="line"> <span class="number">421</span>: <span class="string">'bannister\n banister\n balustrade\n balusters\n handrail'</span>,</span><br><span class="line"> <span class="number">422</span>: <span class="string">'barbell'</span>,</span><br><span class="line"> <span class="number">423</span>: <span class="string">'barber chair'</span>,</span><br><span class="line"> <span class="number">424</span>: <span class="string">'barbershop'</span>,</span><br><span class="line"> <span class="number">425</span>: <span class="string">'barn'</span>,</span><br><span class="line"> <span class="number">426</span>: <span class="string">'barometer'</span>,</span><br><span class="line"> <span class="number">427</span>: <span class="string">'barrel\n cask'</span>,</span><br><span class="line"> <span class="number">428</span>: <span class="string">'barrow\n garden cart\n lawn cart\n wheelbarrow'</span>,</span><br><span class="line"> <span class="number">429</span>: <span class="string">'baseball'</span>,</span><br><span class="line"> <span class="number">430</span>: <span class="string">'basketball'</span>,</span><br><span class="line"> <span class="number">431</span>: <span class="string">'bassinet'</span>,</span><br><span class="line"> <span class="number">432</span>: <span class="string">'bassoon'</span>,</span><br><span class="line"> <span class="number">433</span>: <span class="string">'bathing cap\n swimming cap'</span>,</span><br><span class="line"> <span class="number">434</span>: <span class="string">'bath towel'</span>,</span><br><span class="line"> <span class="number">435</span>: <span class="string">'bathtub\n bathing tub\n bath\n tub'</span>,</span><br><span class="line"> <span class="number">436</span>: <span class="string">'beach wagon\n station wagon\n wagon\n estate car\n beach waggon\n station waggon\n waggon'</span>,</span><br><span class="line"> <span class="number">437</span>: <span class="string">'beacon\n lighthouse\n beacon light\n pharos'</span>,</span><br><span class="line"> <span class="number">438</span>: <span class="string">'beaker'</span>,</span><br><span class="line"> <span class="number">439</span>: <span class="string">'bearskin\n busby\n shako'</span>,</span><br><span class="line"> <span class="number">440</span>: <span class="string">'beer bottle'</span>,</span><br><span class="line"> <span class="number">441</span>: <span class="string">'beer glass'</span>,</span><br><span class="line"> <span class="number">442</span>: <span class="string">'bell cote\n bell cot'</span>,</span><br><span class="line"> <span class="number">443</span>: <span class="string">'bib'</span>,</span><br><span class="line"> <span class="number">444</span>: <span class="string">'bicycle-built-for-two\n tandem bicycle\n tandem'</span>,</span><br><span class="line"> <span class="number">445</span>: <span class="string">'bikini\n two-piece'</span>,</span><br><span class="line"> <span class="number">446</span>: <span class="string">'binder\n ring-binder'</span>,</span><br><span class="line"> <span class="number">447</span>: <span class="string">'binoculars\n field glasses\n opera glasses'</span>,</span><br><span class="line"> <span class="number">448</span>: <span class="string">'birdhouse'</span>,</span><br><span class="line"> <span class="number">449</span>: <span class="string">'boathouse'</span>,</span><br><span class="line"> <span class="number">450</span>: <span class="string">'bobsled\n bobsleigh\n bob'</span>,</span><br><span class="line"> <span class="number">451</span>: <span class="string">'bolo tie\n bolo\n bola tie\n bola'</span>,</span><br><span class="line"> <span class="number">452</span>: <span class="string">'bonnet\n poke bonnet'</span>,</span><br><span class="line"> <span class="number">453</span>: <span class="string">'bookcase'</span>,</span><br><span class="line"> <span class="number">454</span>: <span class="string">'bookshop\n bookstore\n bookstall'</span>,</span><br><span class="line"> <span class="number">455</span>: <span class="string">'bottlecap'</span>,</span><br><span class="line"> <span class="number">456</span>: <span class="string">'bow'</span>,</span><br><span class="line"> <span class="number">457</span>: <span class="string">'bow tie\n bow-tie\n bowtie'</span>,</span><br><span class="line"> <span class="number">458</span>: <span class="string">'brass\n memorial tablet\n plaque'</span>,</span><br><span class="line"> <span class="number">459</span>: <span class="string">'brassiere\n bra\n bandeau'</span>,</span><br><span class="line"> <span class="number">460</span>: <span class="string">'breakwater\n groin\n groyne\n mole\n bulwark\n seawall\n jetty'</span>,</span><br><span class="line"> <span class="number">461</span>: <span class="string">'breastplate\n aegis\n egis'</span>,</span><br><span class="line"> <span class="number">462</span>: <span class="string">'broom'</span>,</span><br><span class="line"> <span class="number">463</span>: <span class="string">'bucket\n pail'</span>,</span><br><span class="line"> <span class="number">464</span>: <span class="string">'buckle'</span>,</span><br><span class="line"> <span class="number">465</span>: <span class="string">'bulletproof vest'</span>,</span><br><span class="line"> <span class="number">466</span>: <span class="string">'bullet train\n bullet'</span>,</span><br><span class="line"> <span class="number">467</span>: <span class="string">'butcher shop\n meat market'</span>,</span><br><span class="line"> <span class="number">468</span>: <span class="string">'cab\n hack\n taxi\n taxicab'</span>,</span><br><span class="line"> <span class="number">469</span>: <span class="string">'caldron\n cauldron'</span>,</span><br><span class="line"> <span class="number">470</span>: <span class="string">'candle\n taper\n wax light'</span>,</span><br><span class="line"> <span class="number">471</span>: <span class="string">'cannon'</span>,</span><br><span class="line"> <span class="number">472</span>: <span class="string">'canoe'</span>,</span><br><span class="line"> <span class="number">473</span>: <span class="string">'can opener\n tin opener'</span>,</span><br><span class="line"> <span class="number">474</span>: <span class="string">'cardigan'</span>,</span><br><span class="line"> <span class="number">475</span>: <span class="string">'car mirror'</span>,</span><br><span class="line"> <span class="number">476</span>: <span class="string">'carousel\n carrousel\n merry-go-round\n roundabout\n whirligig'</span>,</span><br><span class="line"> <span class="number">477</span>: <span class="string">"carpenter's kit\n tool kit"</span>,</span><br><span class="line"> <span class="number">478</span>: <span class="string">'carton'</span>,</span><br><span class="line"> <span class="number">479</span>: <span class="string">'car wheel'</span>,</span><br><span class="line"> <span class="number">480</span>: <span class="string">'cash machine\n cash dispenser\n automated teller machine\n automatic teller machine\n automated teller\n automatic teller\n ATM'</span>,</span><br><span class="line"> <span class="number">481</span>: <span class="string">'cassette'</span>,</span><br><span class="line"> <span class="number">482</span>: <span class="string">'cassette player'</span>,</span><br><span class="line"> <span class="number">483</span>: <span class="string">'castle'</span>,</span><br><span class="line"> <span class="number">484</span>: <span class="string">'catamaran'</span>,</span><br><span class="line"> <span class="number">485</span>: <span class="string">'CD player'</span>,</span><br><span class="line"> <span class="number">486</span>: <span class="string">'cello\n violoncello'</span>,</span><br><span class="line"> <span class="number">487</span>: <span class="string">'cellular telephone\n cellular phone\n cellphone\n cell\n mobile phone'</span>,</span><br><span class="line"> <span class="number">488</span>: <span class="string">'chain'</span>,</span><br><span class="line"> <span class="number">489</span>: <span class="string">'chainlink fence'</span>,</span><br><span class="line"> <span class="number">490</span>: <span class="string">'chain mail\n ring mail\n mail\n chain armor\n chain armour\n ring armor\n ring armour'</span>,</span><br><span class="line"> <span class="number">491</span>: <span class="string">'chain saw\n chainsaw'</span>,</span><br><span class="line"> <span class="number">492</span>: <span class="string">'chest'</span>,</span><br><span class="line"> <span class="number">493</span>: <span class="string">'chiffonier\n commode'</span>,</span><br><span class="line"> <span class="number">494</span>: <span class="string">'chime\n bell\n gong'</span>,</span><br><span class="line"> <span class="number">495</span>: <span class="string">'china cabinet\n china closet'</span>,</span><br><span class="line"> <span class="number">496</span>: <span class="string">'Christmas stocking'</span>,</span><br><span class="line"> <span class="number">497</span>: <span class="string">'church\n church building'</span>,</span><br><span class="line"> <span class="number">498</span>: <span class="string">'cinema\n movie theater\n movie theatre\n movie house\n picture palace'</span>,</span><br><span class="line"> <span class="number">499</span>: <span class="string">'cleaver\n meat cleaver\n chopper'</span>,</span><br><span class="line"> <span class="number">500</span>: <span class="string">'cliff dwelling'</span>,</span><br><span class="line"> <span class="number">501</span>: <span class="string">'cloak'</span>,</span><br><span class="line"> <span class="number">502</span>: <span class="string">'clog\n geta\n patten\n sabot'</span>,</span><br><span class="line"> <span class="number">503</span>: <span class="string">'cocktail shaker'</span>,</span><br><span class="line"> <span class="number">504</span>: <span class="string">'coffee mug'</span>,</span><br><span class="line"> <span class="number">505</span>: <span class="string">'coffeepot'</span>,</span><br><span class="line"> <span class="number">506</span>: <span class="string">'coil\n spiral\n volute\n whorl\n helix'</span>,</span><br><span class="line"> <span class="number">507</span>: <span class="string">'combination lock'</span>,</span><br><span class="line"> <span class="number">508</span>: <span class="string">'computer keyboard\n keypad'</span>,</span><br><span class="line"> <span class="number">509</span>: <span class="string">'confectionery\n confectionary\n candy store'</span>,</span><br><span class="line"> <span class="number">510</span>: <span class="string">'container ship\n containership\n container vessel'</span>,</span><br><span class="line"> <span class="number">511</span>: <span class="string">'convertible'</span>,</span><br><span class="line"> <span class="number">512</span>: <span class="string">'corkscrew\n bottle screw'</span>,</span><br><span class="line"> <span class="number">513</span>: <span class="string">'cornet\n horn\n trumpet\n trump'</span>,</span><br><span class="line"> <span class="number">514</span>: <span class="string">'cowboy boot'</span>,</span><br><span class="line"> <span class="number">515</span>: <span class="string">'cowboy hat\n ten-gallon hat'</span>,</span><br><span class="line"> <span class="number">516</span>: <span class="string">'cradle'</span>,</span><br><span class="line"> <span class="number">517</span>: <span class="string">'crane'</span>,</span><br><span class="line"> <span class="number">518</span>: <span class="string">'crash helmet'</span>,</span><br><span class="line"> <span class="number">519</span>: <span class="string">'crate'</span>,</span><br><span class="line"> <span class="number">520</span>: <span class="string">'crib\n cot'</span>,</span><br><span class="line"> <span class="number">521</span>: <span class="string">'Crock Pot'</span>,</span><br><span class="line"> <span class="number">522</span>: <span class="string">'croquet ball'</span>,</span><br><span class="line"> <span class="number">523</span>: <span class="string">'crutch'</span>,</span><br><span class="line"> <span class="number">524</span>: <span class="string">'cuirass'</span>,</span><br><span class="line"> <span class="number">525</span>: <span class="string">'dam\n dike\n dyke'</span>,</span><br><span class="line"> <span class="number">526</span>: <span class="string">'desk'</span>,</span><br><span class="line"> <span class="number">527</span>: <span class="string">'desktop computer'</span>,</span><br><span class="line"> <span class="number">528</span>: <span class="string">'dial telephone\n dial phone'</span>,</span><br><span class="line"> <span class="number">529</span>: <span class="string">'diaper\n nappy\n napkin'</span>,</span><br><span class="line"> <span class="number">530</span>: <span class="string">'digital clock'</span>,</span><br><span class="line"> <span class="number">531</span>: <span class="string">'digital watch'</span>,</span><br><span class="line"> <span class="number">532</span>: <span class="string">'dining table\n board'</span>,</span><br><span class="line"> <span class="number">533</span>: <span class="string">'dishrag\n dishcloth'</span>,</span><br><span class="line"> <span class="number">534</span>: <span class="string">'dishwasher\n dish washer\n dishwashing machine'</span>,</span><br><span class="line"> <span class="number">535</span>: <span class="string">'disk brake\n disc brake'</span>,</span><br><span class="line"> <span class="number">536</span>: <span class="string">'dock\n dockage\n docking facility'</span>,</span><br><span class="line"> <span class="number">537</span>: <span class="string">'dogsled\n dog sled\n dog sleigh'</span>,</span><br><span class="line"> <span class="number">538</span>: <span class="string">'dome'</span>,</span><br><span class="line"> <span class="number">539</span>: <span class="string">'doormat\n welcome mat'</span>,</span><br><span class="line"> <span class="number">540</span>: <span class="string">'drilling platform\n offshore rig'</span>,</span><br><span class="line"> <span class="number">541</span>: <span class="string">'drum\n membranophone\n tympan'</span>,</span><br><span class="line"> <span class="number">542</span>: <span class="string">'drumstick'</span>,</span><br><span class="line"> <span class="number">543</span>: <span class="string">'dumbbell'</span>,</span><br><span class="line"> <span class="number">544</span>: <span class="string">'Dutch oven'</span>,</span><br><span class="line"> <span class="number">545</span>: <span class="string">'electric fan\n blower'</span>,</span><br><span class="line"> <span class="number">546</span>: <span class="string">'electric guitar'</span>,</span><br><span class="line"> <span class="number">547</span>: <span class="string">'electric locomotive'</span>,</span><br><span class="line"> <span class="number">548</span>: <span class="string">'entertainment center'</span>,</span><br><span class="line"> <span class="number">549</span>: <span class="string">'envelope'</span>,</span><br><span class="line"> <span class="number">550</span>: <span class="string">'espresso maker'</span>,</span><br><span class="line"> <span class="number">551</span>: <span class="string">'face powder'</span>,</span><br><span class="line"> <span class="number">552</span>: <span class="string">'feather boa\n boa'</span>,</span><br><span class="line"> <span class="number">553</span>: <span class="string">'file\n file cabinet\n filing cabinet'</span>,</span><br><span class="line"> <span class="number">554</span>: <span class="string">'fireboat'</span>,</span><br><span class="line"> <span class="number">555</span>: <span class="string">'fire engine\n fire truck'</span>,</span><br><span class="line"> <span class="number">556</span>: <span class="string">'fire screen\n fireguard'</span>,</span><br><span class="line"> <span class="number">557</span>: <span class="string">'flagpole\n flagstaff'</span>,</span><br><span class="line"> <span class="number">558</span>: <span class="string">'flute\n transverse flute'</span>,</span><br><span class="line"> <span class="number">559</span>: <span class="string">'folding chair'</span>,</span><br><span class="line"> <span class="number">560</span>: <span class="string">'football helmet'</span>,</span><br><span class="line"> <span class="number">561</span>: <span class="string">'forklift'</span>,</span><br><span class="line"> <span class="number">562</span>: <span class="string">'fountain'</span>,</span><br><span class="line"> <span class="number">563</span>: <span class="string">'fountain pen'</span>,</span><br><span class="line"> <span class="number">564</span>: <span class="string">'four-poster'</span>,</span><br><span class="line"> <span class="number">565</span>: <span class="string">'freight car'</span>,</span><br><span class="line"> <span class="number">566</span>: <span class="string">'French horn\n horn'</span>,</span><br><span class="line"> <span class="number">567</span>: <span class="string">'frying pan\n frypan\n skillet'</span>,</span><br><span class="line"> <span class="number">568</span>: <span class="string">'fur coat'</span>,</span><br><span class="line"> <span class="number">569</span>: <span class="string">'garbage truck\n dustcart'</span>,</span><br><span class="line"> <span class="number">570</span>: <span class="string">'gasmask\n respirator\n gas helmet'</span>,</span><br><span class="line"> <span class="number">571</span>: <span class="string">'gas pump\n gasoline pump\n petrol pump\n island dispenser'</span>,</span><br><span class="line"> <span class="number">572</span>: <span class="string">'goblet'</span>,</span><br><span class="line"> <span class="number">573</span>: <span class="string">'go-kart'</span>,</span><br><span class="line"> <span class="number">574</span>: <span class="string">'golf ball'</span>,</span><br><span class="line"> <span class="number">575</span>: <span class="string">'golfcart\n golf cart'</span>,</span><br><span class="line"> <span class="number">576</span>: <span class="string">'gondola'</span>,</span><br><span class="line"> <span class="number">577</span>: <span class="string">'gong\n tam-tam'</span>,</span><br><span class="line"> <span class="number">578</span>: <span class="string">'gown'</span>,</span><br><span class="line"> <span class="number">579</span>: <span class="string">'grand piano\n grand'</span>,</span><br><span class="line"> <span class="number">580</span>: <span class="string">'greenhouse\n nursery\n glasshouse'</span>,</span><br><span class="line"> <span class="number">581</span>: <span class="string">'grille\n radiator grille'</span>,</span><br><span class="line"> <span class="number">582</span>: <span class="string">'grocery store\n grocery\n food market\n market'</span>,</span><br><span class="line"> <span class="number">583</span>: <span class="string">'guillotine'</span>,</span><br><span class="line"> <span class="number">584</span>: <span class="string">'hair slide'</span>,</span><br><span class="line"> <span class="number">585</span>: <span class="string">'hair spray'</span>,</span><br><span class="line"> <span class="number">586</span>: <span class="string">'half track'</span>,</span><br><span class="line"> <span class="number">587</span>: <span class="string">'hammer'</span>,</span><br><span class="line"> <span class="number">588</span>: <span class="string">'hamper'</span>,</span><br><span class="line"> <span class="number">589</span>: <span class="string">'hand blower\n blow dryer\n blow drier\n hair dryer\n hair drier'</span>,</span><br><span class="line"> <span class="number">590</span>: <span class="string">'hand-held computer\n hand-held microcomputer'</span>,</span><br><span class="line"> <span class="number">591</span>: <span class="string">'handkerchief\n hankie\n hanky\n hankey'</span>,</span><br><span class="line"> <span class="number">592</span>: <span class="string">'hard disc\n hard disk\n fixed disk'</span>,</span><br><span class="line"> <span class="number">593</span>: <span class="string">'harmonica\n mouth organ\n harp\n mouth harp'</span>,</span><br><span class="line"> <span class="number">594</span>: <span class="string">'harp'</span>,</span><br><span class="line"> <span class="number">595</span>: <span class="string">'harvester\n reaper'</span>,</span><br><span class="line"> <span class="number">596</span>: <span class="string">'hatchet'</span>,</span><br><span class="line"> <span class="number">597</span>: <span class="string">'holster'</span>,</span><br><span class="line"> <span class="number">598</span>: <span class="string">'home theater\n home theatre'</span>,</span><br><span class="line"> <span class="number">599</span>: <span class="string">'honeycomb'</span>,</span><br><span class="line"> <span class="number">600</span>: <span class="string">'hook\n claw'</span>,</span><br><span class="line"> <span class="number">601</span>: <span class="string">'hoopskirt\n crinoline'</span>,</span><br><span class="line"> <span class="number">602</span>: <span class="string">'horizontal bar\n high bar'</span>,</span><br><span class="line"> <span class="number">603</span>: <span class="string">'horse cart\n horse-cart'</span>,</span><br><span class="line"> <span class="number">604</span>: <span class="string">'hourglass'</span>,</span><br><span class="line"> <span class="number">605</span>: <span class="string">'iPod'</span>,</span><br><span class="line"> <span class="number">606</span>: <span class="string">'iron\n smoothing iron'</span>,</span><br><span class="line"> <span class="number">607</span>: <span class="string">"jack-o'-lantern"</span>,</span><br><span class="line"> <span class="number">608</span>: <span class="string">'jean\n blue jean\n denim'</span>,</span><br><span class="line"> <span class="number">609</span>: <span class="string">'jeep\n landrover'</span>,</span><br><span class="line"> <span class="number">610</span>: <span class="string">'jersey\n T-shirt\n tee shirt'</span>,</span><br><span class="line"> <span class="number">611</span>: <span class="string">'jigsaw puzzle'</span>,</span><br><span class="line"> <span class="number">612</span>: <span class="string">'jinrikisha\n ricksha\n rickshaw'</span>,</span><br><span class="line"> <span class="number">613</span>: <span class="string">'joystick'</span>,</span><br><span class="line"> <span class="number">614</span>: <span class="string">'kimono'</span>,</span><br><span class="line"> <span class="number">615</span>: <span class="string">'knee pad'</span>,</span><br><span class="line"> <span class="number">616</span>: <span class="string">'knot'</span>,</span><br><span class="line"> <span class="number">617</span>: <span class="string">'lab coat\n laboratory coat'</span>,</span><br><span class="line"> <span class="number">618</span>: <span class="string">'ladle'</span>,</span><br><span class="line"> <span class="number">619</span>: <span class="string">'lampshade\n lamp shade'</span>,</span><br><span class="line"> <span class="number">620</span>: <span class="string">'laptop\n laptop computer'</span>,</span><br><span class="line"> <span class="number">621</span>: <span class="string">'lawn mower\n mower'</span>,</span><br><span class="line"> <span class="number">622</span>: <span class="string">'lens cap\n lens cover'</span>,</span><br><span class="line"> <span class="number">623</span>: <span class="string">'letter opener\n paper knife\n paperknife'</span>,</span><br><span class="line"> <span class="number">624</span>: <span class="string">'library'</span>,</span><br><span class="line"> <span class="number">625</span>: <span class="string">'lifeboat'</span>,</span><br><span class="line"> <span class="number">626</span>: <span class="string">'lighter\n light\n igniter\n ignitor'</span>,</span><br><span class="line"> <span class="number">627</span>: <span class="string">'limousine\n limo'</span>,</span><br><span class="line"> <span class="number">628</span>: <span class="string">'liner\n ocean liner'</span>,</span><br><span class="line"> <span class="number">629</span>: <span class="string">'lipstick\n lip rouge'</span>,</span><br><span class="line"> <span class="number">630</span>: <span class="string">'Loafer'</span>,</span><br><span class="line"> <span class="number">631</span>: <span class="string">'lotion'</span>,</span><br><span class="line"> <span class="number">632</span>: <span class="string">'loudspeaker\n speaker\n speaker unit\n loudspeaker system\n speaker system'</span>,</span><br><span class="line"> <span class="number">633</span>: <span class="string">"loupe\n jeweler's loupe"</span>,</span><br><span class="line"> <span class="number">634</span>: <span class="string">'lumbermill\n sawmill'</span>,</span><br><span class="line"> <span class="number">635</span>: <span class="string">'magnetic compass'</span>,</span><br><span class="line"> <span class="number">636</span>: <span class="string">'mailbag\n postbag'</span>,</span><br><span class="line"> <span class="number">637</span>: <span class="string">'mailbox\n letter box'</span>,</span><br><span class="line"> <span class="number">638</span>: <span class="string">'maillot'</span>,</span><br><span class="line"> <span class="number">639</span>: <span class="string">'maillot\n tank suit'</span>,</span><br><span class="line"> <span class="number">640</span>: <span class="string">'manhole cover'</span>,</span><br><span class="line"> <span class="number">641</span>: <span class="string">'maraca'</span>,</span><br><span class="line"> <span class="number">642</span>: <span class="string">'marimba\n xylophone'</span>,</span><br><span class="line"> <span class="number">643</span>: <span class="string">'mask'</span>,</span><br><span class="line"> <span class="number">644</span>: <span class="string">'matchstick'</span>,</span><br><span class="line"> <span class="number">645</span>: <span class="string">'maypole'</span>,</span><br><span class="line"> <span class="number">646</span>: <span class="string">'maze\n labyrinth'</span>,</span><br><span class="line"> <span class="number">647</span>: <span class="string">'measuring cup'</span>,</span><br><span class="line"> <span class="number">648</span>: <span class="string">'medicine chest\n medicine cabinet'</span>,</span><br><span class="line"> <span class="number">649</span>: <span class="string">'megalith\n megalithic structure'</span>,</span><br><span class="line"> <span class="number">650</span>: <span class="string">'microphone\n mike'</span>,</span><br><span class="line"> <span class="number">651</span>: <span class="string">'microwave\n microwave oven'</span>,</span><br><span class="line"> <span class="number">652</span>: <span class="string">'military uniform'</span>,</span><br><span class="line"> <span class="number">653</span>: <span class="string">'milk can'</span>,</span><br><span class="line"> <span class="number">654</span>: <span class="string">'minibus'</span>,</span><br><span class="line"> <span class="number">655</span>: <span class="string">'miniskirt\n mini'</span>,</span><br><span class="line"> <span class="number">656</span>: <span class="string">'minivan'</span>,</span><br><span class="line"> <span class="number">657</span>: <span class="string">'missile'</span>,</span><br><span class="line"> <span class="number">658</span>: <span class="string">'mitten'</span>,</span><br><span class="line"> <span class="number">659</span>: <span class="string">'mixing bowl'</span>,</span><br><span class="line"> <span class="number">660</span>: <span class="string">'mobile home\n manufactured home'</span>,</span><br><span class="line"> <span class="number">661</span>: <span class="string">'Model T'</span>,</span><br><span class="line"> <span class="number">662</span>: <span class="string">'modem'</span>,</span><br><span class="line"> <span class="number">663</span>: <span class="string">'monastery'</span>,</span><br><span class="line"> <span class="number">664</span>: <span class="string">'monitor'</span>,</span><br><span class="line"> <span class="number">665</span>: <span class="string">'moped'</span>,</span><br><span class="line"> <span class="number">666</span>: <span class="string">'mortar'</span>,</span><br><span class="line"> <span class="number">667</span>: <span class="string">'mortarboard'</span>,</span><br><span class="line"> <span class="number">668</span>: <span class="string">'mosque'</span>,</span><br><span class="line"> <span class="number">669</span>: <span class="string">'mosquito net'</span>,</span><br><span class="line"> <span class="number">670</span>: <span class="string">'motor scooter\n scooter'</span>,</span><br><span class="line"> <span class="number">671</span>: <span class="string">'mountain bike\n all-terrain bike\n off-roader'</span>,</span><br><span class="line"> <span class="number">672</span>: <span class="string">'mountain tent'</span>,</span><br><span class="line"> <span class="number">673</span>: <span class="string">'mouse\n computer mouse'</span>,</span><br><span class="line"> <span class="number">674</span>: <span class="string">'mousetrap'</span>,</span><br><span class="line"> <span class="number">675</span>: <span class="string">'moving van'</span>,</span><br><span class="line"> <span class="number">676</span>: <span class="string">'muzzle'</span>,</span><br><span class="line"> <span class="number">677</span>: <span class="string">'nail'</span>,</span><br><span class="line"> <span class="number">678</span>: <span class="string">'neck brace'</span>,</span><br><span class="line"> <span class="number">679</span>: <span class="string">'necklace'</span>,</span><br><span class="line"> <span class="number">680</span>: <span class="string">'nipple'</span>,</span><br><span class="line"> <span class="number">681</span>: <span class="string">'notebook\n notebook computer'</span>,</span><br><span class="line"> <span class="number">682</span>: <span class="string">'obelisk'</span>,</span><br><span class="line"> <span class="number">683</span>: <span class="string">'oboe\n hautboy\n hautbois'</span>,</span><br><span class="line"> <span class="number">684</span>: <span class="string">'ocarina\n sweet potato'</span>,</span><br><span class="line"> <span class="number">685</span>: <span class="string">'odometer\n hodometer\n mileometer\n milometer'</span>,</span><br><span class="line"> <span class="number">686</span>: <span class="string">'oil filter'</span>,</span><br><span class="line"> <span class="number">687</span>: <span class="string">'organ\n pipe organ'</span>,</span><br><span class="line"> <span class="number">688</span>: <span class="string">'oscilloscope\n scope\n cathode-ray oscilloscope\n CRO'</span>,</span><br><span class="line"> <span class="number">689</span>: <span class="string">'overskirt'</span>,</span><br><span class="line"> <span class="number">690</span>: <span class="string">'oxcart'</span>,</span><br><span class="line"> <span class="number">691</span>: <span class="string">'oxygen mask'</span>,</span><br><span class="line"> <span class="number">692</span>: <span class="string">'packet'</span>,</span><br><span class="line"> <span class="number">693</span>: <span class="string">'paddle\n boat paddle'</span>,</span><br><span class="line"> <span class="number">694</span>: <span class="string">'paddlewheel\n paddle wheel'</span>,</span><br><span class="line"> <span class="number">695</span>: <span class="string">'padlock'</span>,</span><br><span class="line"> <span class="number">696</span>: <span class="string">'paintbrush'</span>,</span><br><span class="line"> <span class="number">697</span>: <span class="string">"pajama\n pyjama\n pj's\n jammies"</span>,</span><br><span class="line"> <span class="number">698</span>: <span class="string">'palace'</span>,</span><br><span class="line"> <span class="number">699</span>: <span class="string">'panpipe\n pandean pipe\n syrinx'</span>,</span><br><span class="line"> <span class="number">700</span>: <span class="string">'paper towel'</span>,</span><br><span class="line"> <span class="number">701</span>: <span class="string">'parachute\n chute'</span>,</span><br><span class="line"> <span class="number">702</span>: <span class="string">'parallel bars\n bars'</span>,</span><br><span class="line"> <span class="number">703</span>: <span class="string">'park bench'</span>,</span><br><span class="line"> <span class="number">704</span>: <span class="string">'parking meter'</span>,</span><br><span class="line"> <span class="number">705</span>: <span class="string">'passenger car\n coach\n carriage'</span>,</span><br><span class="line"> <span class="number">706</span>: <span class="string">'patio\n terrace'</span>,</span><br><span class="line"> <span class="number">707</span>: <span class="string">'pay-phone\n pay-station'</span>,</span><br><span class="line"> <span class="number">708</span>: <span class="string">'pedestal\n plinth\n footstall'</span>,</span><br><span class="line"> <span class="number">709</span>: <span class="string">'pencil box\n pencil case'</span>,</span><br><span class="line"> <span class="number">710</span>: <span class="string">'pencil sharpener'</span>,</span><br><span class="line"> <span class="number">711</span>: <span class="string">'perfume\n essence'</span>,</span><br><span class="line"> <span class="number">712</span>: <span class="string">'Petri dish'</span>,</span><br><span class="line"> <span class="number">713</span>: <span class="string">'photocopier'</span>,</span><br><span class="line"> <span class="number">714</span>: <span class="string">'pick\n plectrum\n plectron'</span>,</span><br><span class="line"> <span class="number">715</span>: <span class="string">'pickelhaube'</span>,</span><br><span class="line"> <span class="number">716</span>: <span class="string">'picket fence\n paling'</span>,</span><br><span class="line"> <span class="number">717</span>: <span class="string">'pickup\n pickup truck'</span>,</span><br><span class="line"> <span class="number">718</span>: <span class="string">'pier'</span>,</span><br><span class="line"> <span class="number">719</span>: <span class="string">'piggy bank\n penny bank'</span>,</span><br><span class="line"> <span class="number">720</span>: <span class="string">'pill bottle'</span>,</span><br><span class="line"> <span class="number">721</span>: <span class="string">'pillow'</span>,</span><br><span class="line"> <span class="number">722</span>: <span class="string">'ping-pong ball'</span>,</span><br><span class="line"> <span class="number">723</span>: <span class="string">'pinwheel'</span>,</span><br><span class="line"> <span class="number">724</span>: <span class="string">'pirate\n pirate ship'</span>,</span><br><span class="line"> <span class="number">725</span>: <span class="string">'pitcher\n ewer'</span>,</span><br><span class="line"> <span class="number">726</span>: <span class="string">"plane\n carpenter's plane\n woodworking plane"</span>,</span><br><span class="line"> <span class="number">727</span>: <span class="string">'planetarium'</span>,</span><br><span class="line"> <span class="number">728</span>: <span class="string">'plastic bag'</span>,</span><br><span class="line"> <span class="number">729</span>: <span class="string">'plate rack'</span>,</span><br><span class="line"> <span class="number">730</span>: <span class="string">'plow\n plough'</span>,</span><br><span class="line"> <span class="number">731</span>: <span class="string">"plunger\n plumber's helper"</span>,</span><br><span class="line"> <span class="number">732</span>: <span class="string">'Polaroid camera\n Polaroid Land camera'</span>,</span><br><span class="line"> <span class="number">733</span>: <span class="string">'pole'</span>,</span><br><span class="line"> <span class="number">734</span>: <span class="string">'police van\n police wagon\n paddy wagon\n patrol wagon\n wagon\n black Maria'</span>,</span><br><span class="line"> <span class="number">735</span>: <span class="string">'poncho'</span>,</span><br><span class="line"> <span class="number">736</span>: <span class="string">'pool table\n billiard table\n snooker table'</span>,</span><br><span class="line"> <span class="number">737</span>: <span class="string">'pop bottle\n soda bottle'</span>,</span><br><span class="line"> <span class="number">738</span>: <span class="string">'pot\n flowerpot'</span>,</span><br><span class="line"> <span class="number">739</span>: <span class="string">"potter's wheel"</span>,</span><br><span class="line"> <span class="number">740</span>: <span class="string">'power drill'</span>,</span><br><span class="line"> <span class="number">741</span>: <span class="string">'prayer rug\n prayer mat'</span>,</span><br><span class="line"> <span class="number">742</span>: <span class="string">'printer'</span>,</span><br><span class="line"> <span class="number">743</span>: <span class="string">'prison\n prison house'</span>,</span><br><span class="line"> <span class="number">744</span>: <span class="string">'projectile\n missile'</span>,</span><br><span class="line"> <span class="number">745</span>: <span class="string">'projector'</span>,</span><br><span class="line"> <span class="number">746</span>: <span class="string">'puck\n hockey puck'</span>,</span><br><span class="line"> <span class="number">747</span>: <span class="string">'punching bag\n punch bag\n punching ball\n punchball'</span>,</span><br><span class="line"> <span class="number">748</span>: <span class="string">'purse'</span>,</span><br><span class="line"> <span class="number">749</span>: <span class="string">'quill\n quill pen'</span>,</span><br><span class="line"> <span class="number">750</span>: <span class="string">'quilt\n comforter\n comfort\n puff'</span>,</span><br><span class="line"> <span class="number">751</span>: <span class="string">'racer\n race car\n racing car'</span>,</span><br><span class="line"> <span class="number">752</span>: <span class="string">'racket\n racquet'</span>,</span><br><span class="line"> <span class="number">753</span>: <span class="string">'radiator'</span>,</span><br><span class="line"> <span class="number">754</span>: <span class="string">'radio\n wireless'</span>,</span><br><span class="line"> <span class="number">755</span>: <span class="string">'radio telescope\n radio reflector'</span>,</span><br><span class="line"> <span class="number">756</span>: <span class="string">'rain barrel'</span>,</span><br><span class="line"> <span class="number">757</span>: <span class="string">'recreational vehicle\n RV\n R.V.'</span>,</span><br><span class="line"> <span class="number">758</span>: <span class="string">'reel'</span>,</span><br><span class="line"> <span class="number">759</span>: <span class="string">'reflex camera'</span>,</span><br><span class="line"> <span class="number">760</span>: <span class="string">'refrigerator\n icebox'</span>,</span><br><span class="line"> <span class="number">761</span>: <span class="string">'remote control\n remote'</span>,</span><br><span class="line"> <span class="number">762</span>: <span class="string">'restaurant\n eating house\n eating place\n eatery'</span>,</span><br><span class="line"> <span class="number">763</span>: <span class="string">'revolver\n six-gun\n six-shooter'</span>,</span><br><span class="line"> <span class="number">764</span>: <span class="string">'rifle'</span>,</span><br><span class="line"> <span class="number">765</span>: <span class="string">'rocking chair\n rocker'</span>,</span><br><span class="line"> <span class="number">766</span>: <span class="string">'rotisserie'</span>,</span><br><span class="line"> <span class="number">767</span>: <span class="string">'rubber eraser\n rubber\n pencil eraser'</span>,</span><br><span class="line"> <span class="number">768</span>: <span class="string">'rugby ball'</span>,</span><br><span class="line"> <span class="number">769</span>: <span class="string">'rule\n ruler'</span>,</span><br><span class="line"> <span class="number">770</span>: <span class="string">'running shoe'</span>,</span><br><span class="line"> <span class="number">771</span>: <span class="string">'safe'</span>,</span><br><span class="line"> <span class="number">772</span>: <span class="string">'safety pin'</span>,</span><br><span class="line"> <span class="number">773</span>: <span class="string">'saltshaker\n salt shaker'</span>,</span><br><span class="line"> <span class="number">774</span>: <span class="string">'sandal'</span>,</span><br><span class="line"> <span class="number">775</span>: <span class="string">'sarong'</span>,</span><br><span class="line"> <span class="number">776</span>: <span class="string">'sax\n saxophone'</span>,</span><br><span class="line"> <span class="number">777</span>: <span class="string">'scabbard'</span>,</span><br><span class="line"> <span class="number">778</span>: <span class="string">'scale\n weighing machine'</span>,</span><br><span class="line"> <span class="number">779</span>: <span class="string">'school bus'</span>,</span><br><span class="line"> <span class="number">780</span>: <span class="string">'schooner'</span>,</span><br><span class="line"> <span class="number">781</span>: <span class="string">'scoreboard'</span>,</span><br><span class="line"> <span class="number">782</span>: <span class="string">'screen\n CRT screen'</span>,</span><br><span class="line"> <span class="number">783</span>: <span class="string">'screw'</span>,</span><br><span class="line"> <span class="number">784</span>: <span class="string">'screwdriver'</span>,</span><br><span class="line"> <span class="number">785</span>: <span class="string">'seat belt\n seatbelt'</span>,</span><br><span class="line"> <span class="number">786</span>: <span class="string">'sewing machine'</span>,</span><br><span class="line"> <span class="number">787</span>: <span class="string">'shield\n buckler'</span>,</span><br><span class="line"> <span class="number">788</span>: <span class="string">'shoe shop\n shoe-shop\n shoe store'</span>,</span><br><span class="line"> <span class="number">789</span>: <span class="string">'shoji'</span>,</span><br><span class="line"> <span class="number">790</span>: <span class="string">'shopping basket'</span>,</span><br><span class="line"> <span class="number">791</span>: <span class="string">'shopping cart'</span>,</span><br><span class="line"> <span class="number">792</span>: <span class="string">'shovel'</span>,</span><br><span class="line"> <span class="number">793</span>: <span class="string">'shower cap'</span>,</span><br><span class="line"> <span class="number">794</span>: <span class="string">'shower curtain'</span>,</span><br><span class="line"> <span class="number">795</span>: <span class="string">'ski'</span>,</span><br><span class="line"> <span class="number">796</span>: <span class="string">'ski mask'</span>,</span><br><span class="line"> <span class="number">797</span>: <span class="string">'sleeping bag'</span>,</span><br><span class="line"> <span class="number">798</span>: <span class="string">'slide rule\n slipstick'</span>,</span><br><span class="line"> <span class="number">799</span>: <span class="string">'sliding door'</span>,</span><br><span class="line"> <span class="number">800</span>: <span class="string">'slot\n one-armed bandit'</span>,</span><br><span class="line"> <span class="number">801</span>: <span class="string">'snorkel'</span>,</span><br><span class="line"> <span class="number">802</span>: <span class="string">'snowmobile'</span>,</span><br><span class="line"> <span class="number">803</span>: <span class="string">'snowplow\n snowplough'</span>,</span><br><span class="line"> <span class="number">804</span>: <span class="string">'soap dispenser'</span>,</span><br><span class="line"> <span class="number">805</span>: <span class="string">'soccer ball'</span>,</span><br><span class="line"> <span class="number">806</span>: <span class="string">'sock'</span>,</span><br><span class="line"> <span class="number">807</span>: <span class="string">'solar dish\n solar collector\n solar furnace'</span>,</span><br><span class="line"> <span class="number">808</span>: <span class="string">'sombrero'</span>,</span><br><span class="line"> <span class="number">809</span>: <span class="string">'soup bowl'</span>,</span><br><span class="line"> <span class="number">810</span>: <span class="string">'space bar'</span>,</span><br><span class="line"> <span class="number">811</span>: <span class="string">'space heater'</span>,</span><br><span class="line"> <span class="number">812</span>: <span class="string">'space shuttle'</span>,</span><br><span class="line"> <span class="number">813</span>: <span class="string">'spatula'</span>,</span><br><span class="line"> <span class="number">814</span>: <span class="string">'speedboat'</span>,</span><br><span class="line"> <span class="number">815</span>: <span class="string">"spider web\n spider's web"</span>,</span><br><span class="line"> <span class="number">816</span>: <span class="string">'spindle'</span>,</span><br><span class="line"> <span class="number">817</span>: <span class="string">'sports car\n sport car'</span>,</span><br><span class="line"> <span class="number">818</span>: <span class="string">'spotlight\n spot'</span>,</span><br><span class="line"> <span class="number">819</span>: <span class="string">'stage'</span>,</span><br><span class="line"> <span class="number">820</span>: <span class="string">'steam locomotive'</span>,</span><br><span class="line"> <span class="number">821</span>: <span class="string">'steel arch bridge'</span>,</span><br><span class="line"> <span class="number">822</span>: <span class="string">'steel drum'</span>,</span><br><span class="line"> <span class="number">823</span>: <span class="string">'stethoscope'</span>,</span><br><span class="line"> <span class="number">824</span>: <span class="string">'stole'</span>,</span><br><span class="line"> <span class="number">825</span>: <span class="string">'stone wall'</span>,</span><br><span class="line"> <span class="number">826</span>: <span class="string">'stopwatch\n stop watch'</span>,</span><br><span class="line"> <span class="number">827</span>: <span class="string">'stove'</span>,</span><br><span class="line"> <span class="number">828</span>: <span class="string">'strainer'</span>,</span><br><span class="line"> <span class="number">829</span>: <span class="string">'streetcar\n tram\n tramcar\n trolley\n trolley car'</span>,</span><br><span class="line"> <span class="number">830</span>: <span class="string">'stretcher'</span>,</span><br><span class="line"> <span class="number">831</span>: <span class="string">'studio couch\n day bed'</span>,</span><br><span class="line"> <span class="number">832</span>: <span class="string">'stupa\n tope'</span>,</span><br><span class="line"> <span class="number">833</span>: <span class="string">'submarine\n pigboat\n sub\n U-boat'</span>,</span><br><span class="line"> <span class="number">834</span>: <span class="string">'suit\n suit of clothes'</span>,</span><br><span class="line"> <span class="number">835</span>: <span class="string">'sundial'</span>,</span><br><span class="line"> <span class="number">836</span>: <span class="string">'sunglass'</span>,</span><br><span class="line"> <span class="number">837</span>: <span class="string">'sunglasses\n dark glasses\n shades'</span>,</span><br><span class="line"> <span class="number">838</span>: <span class="string">'sunscreen\n sunblock\n sun blocker'</span>,</span><br><span class="line"> <span class="number">839</span>: <span class="string">'suspension bridge'</span>,</span><br><span class="line"> <span class="number">840</span>: <span class="string">'swab\n swob\n mop'</span>,</span><br><span class="line"> <span class="number">841</span>: <span class="string">'sweatshirt'</span>,</span><br><span class="line"> <span class="number">842</span>: <span class="string">'swimming trunks\n bathing trunks'</span>,</span><br><span class="line"> <span class="number">843</span>: <span class="string">'swing'</span>,</span><br><span class="line"> <span class="number">844</span>: <span class="string">'switch\n electric switch\n electrical switch'</span>,</span><br><span class="line"> <span class="number">845</span>: <span class="string">'syringe'</span>,</span><br><span class="line"> <span class="number">846</span>: <span class="string">'table lamp'</span>,</span><br><span class="line"> <span class="number">847</span>: <span class="string">'tank\n army tank\n armored combat vehicle\n armoured combat vehicle'</span>,</span><br><span class="line"> <span class="number">848</span>: <span class="string">'tape player'</span>,</span><br><span class="line"> <span class="number">849</span>: <span class="string">'teapot'</span>,</span><br><span class="line"> <span class="number">850</span>: <span class="string">'teddy\n teddy bear'</span>,</span><br><span class="line"> <span class="number">851</span>: <span class="string">'television\n television system'</span>,</span><br><span class="line"> <span class="number">852</span>: <span class="string">'tennis ball'</span>,</span><br><span class="line"> <span class="number">853</span>: <span class="string">'thatch\n thatched roof'</span>,</span><br><span class="line"> <span class="number">854</span>: <span class="string">'theater curtain\n theatre curtain'</span>,</span><br><span class="line"> <span class="number">855</span>: <span class="string">'thimble'</span>,</span><br><span class="line"> <span class="number">856</span>: <span class="string">'thresher\n thrasher\n threshing machine'</span>,</span><br><span class="line"> <span class="number">857</span>: <span class="string">'throne'</span>,</span><br><span class="line"> <span class="number">858</span>: <span class="string">'tile roof'</span>,</span><br><span class="line"> <span class="number">859</span>: <span class="string">'toaster'</span>,</span><br><span class="line"> <span class="number">860</span>: <span class="string">'tobacco shop\n tobacconist shop\n tobacconist'</span>,</span><br><span class="line"> <span class="number">861</span>: <span class="string">'toilet seat'</span>,</span><br><span class="line"> <span class="number">862</span>: <span class="string">'torch'</span>,</span><br><span class="line"> <span class="number">863</span>: <span class="string">'totem pole'</span>,</span><br><span class="line"> <span class="number">864</span>: <span class="string">'tow truck\n tow car\n wrecker'</span>,</span><br><span class="line"> <span class="number">865</span>: <span class="string">'toyshop'</span>,</span><br><span class="line"> <span class="number">866</span>: <span class="string">'tractor'</span>,</span><br><span class="line"> <span class="number">867</span>: <span class="string">'trailer truck\n tractor trailer\n trucking rig\n rig\n articulated lorry\n semi'</span>,</span><br><span class="line"> <span class="number">868</span>: <span class="string">'tray'</span>,</span><br><span class="line"> <span class="number">869</span>: <span class="string">'trench coat'</span>,</span><br><span class="line"> <span class="number">870</span>: <span class="string">'tricycle\n trike\n velocipede'</span>,</span><br><span class="line"> <span class="number">871</span>: <span class="string">'trimaran'</span>,</span><br><span class="line"> <span class="number">872</span>: <span class="string">'tripod'</span>,</span><br><span class="line"> <span class="number">873</span>: <span class="string">'triumphal arch'</span>,</span><br><span class="line"> <span class="number">874</span>: <span class="string">'trolleybus\n trolley coach\n trackless trolley'</span>,</span><br><span class="line"> <span class="number">875</span>: <span class="string">'trombone'</span>,</span><br><span class="line"> <span class="number">876</span>: <span class="string">'tub\n vat'</span>,</span><br><span class="line"> <span class="number">877</span>: <span class="string">'turnstile'</span>,</span><br><span class="line"> <span class="number">878</span>: <span class="string">'typewriter keyboard'</span>,</span><br><span class="line"> <span class="number">879</span>: <span class="string">'umbrella'</span>,</span><br><span class="line"> <span class="number">880</span>: <span class="string">'unicycle\n monocycle'</span>,</span><br><span class="line"> <span class="number">881</span>: <span class="string">'upright\n upright piano'</span>,</span><br><span class="line"> <span class="number">882</span>: <span class="string">'vacuum\n vacuum cleaner'</span>,</span><br><span class="line"> <span class="number">883</span>: <span class="string">'vase'</span>,</span><br><span class="line"> <span class="number">884</span>: <span class="string">'vault'</span>,</span><br><span class="line"> <span class="number">885</span>: <span class="string">'velvet'</span>,</span><br><span class="line"> <span class="number">886</span>: <span class="string">'vending machine'</span>,</span><br><span class="line"> <span class="number">887</span>: <span class="string">'vestment'</span>,</span><br><span class="line"> <span class="number">888</span>: <span class="string">'viaduct'</span>,</span><br><span class="line"> <span class="number">889</span>: <span class="string">'violin\n fiddle'</span>,</span><br><span class="line"> <span class="number">890</span>: <span class="string">'volleyball'</span>,</span><br><span class="line"> <span class="number">891</span>: <span class="string">'waffle iron'</span>,</span><br><span class="line"> <span class="number">892</span>: <span class="string">'wall clock'</span>,</span><br><span class="line"> <span class="number">893</span>: <span class="string">'wallet\n billfold\n notecase\n pocketbook'</span>,</span><br><span class="line"> <span class="number">894</span>: <span class="string">'wardrobe\n closet\n press'</span>,</span><br><span class="line"> <span class="number">895</span>: <span class="string">'warplane\n military plane'</span>,</span><br><span class="line"> <span class="number">896</span>: <span class="string">'washbasin\n handbasin\n washbowl\n lavabo\n wash-hand basin'</span>,</span><br><span class="line"> <span class="number">897</span>: <span class="string">'washer\n automatic washer\n washing machine'</span>,</span><br><span class="line"> <span class="number">898</span>: <span class="string">'water bottle'</span>,</span><br><span class="line"> <span class="number">899</span>: <span class="string">'water jug'</span>,</span><br><span class="line"> <span class="number">900</span>: <span class="string">'water tower'</span>,</span><br><span class="line"> <span class="number">901</span>: <span class="string">'whiskey jug'</span>,</span><br><span class="line"> <span class="number">902</span>: <span class="string">'whistle'</span>,</span><br><span class="line"> <span class="number">903</span>: <span class="string">'wig'</span>,</span><br><span class="line"> <span class="number">904</span>: <span class="string">'window screen'</span>,</span><br><span class="line"> <span class="number">905</span>: <span class="string">'window shade'</span>,</span><br><span class="line"> <span class="number">906</span>: <span class="string">'Windsor tie'</span>,</span><br><span class="line"> <span class="number">907</span>: <span class="string">'wine bottle'</span>,</span><br><span class="line"> <span class="number">908</span>: <span class="string">'wing'</span>,</span><br><span class="line"> <span class="number">909</span>: <span class="string">'wok'</span>,</span><br><span class="line"> <span class="number">910</span>: <span class="string">'wooden spoon'</span>,</span><br><span class="line"> <span class="number">911</span>: <span class="string">'wool\n woolen\n woollen'</span>,</span><br><span class="line"> <span class="number">912</span>: <span class="string">'worm fence\n snake fence\n snake-rail fence\n Virginia fence'</span>,</span><br><span class="line"> <span class="number">913</span>: <span class="string">'wreck'</span>,</span><br><span class="line"> <span class="number">914</span>: <span class="string">'yawl'</span>,</span><br><span class="line"> <span class="number">915</span>: <span class="string">'yurt'</span>,</span><br><span class="line"> <span class="number">916</span>: <span class="string">'web site\n website\n internet site\n site'</span>,</span><br><span class="line"> <span class="number">917</span>: <span class="string">'comic book'</span>,</span><br><span class="line"> <span class="number">918</span>: <span class="string">'crossword puzzle\n crossword'</span>,</span><br><span class="line"> <span class="number">919</span>: <span class="string">'street sign'</span>,</span><br><span class="line"> <span class="number">920</span>: <span class="string">'traffic light\n traffic signal\n stoplight'</span>,</span><br><span class="line"> <span class="number">921</span>: <span class="string">'book jacket\n dust cover\n dust jacket\n dust wrapper'</span>,</span><br><span class="line"> <span class="number">922</span>: <span class="string">'menu'</span>,</span><br><span class="line"> <span class="number">923</span>: <span class="string">'plate'</span>,</span><br><span class="line"> <span class="number">924</span>: <span class="string">'guacamole'</span>,</span><br><span class="line"> <span class="number">925</span>: <span class="string">'consomme'</span>,</span><br><span class="line"> <span class="number">926</span>: <span class="string">'hot pot\n hotpot'</span>,</span><br><span class="line"> <span class="number">927</span>: <span class="string">'trifle'</span>,</span><br><span class="line"> <span class="number">928</span>: <span class="string">'ice cream\n icecream'</span>,</span><br><span class="line"> <span class="number">929</span>: <span class="string">'ice lolly\n lolly\n lollipop\n popsicle'</span>,</span><br><span class="line"> <span class="number">930</span>: <span class="string">'French loaf'</span>,</span><br><span class="line"> <span class="number">931</span>: <span class="string">'bagel\n beigel'</span>,</span><br><span class="line"> <span class="number">932</span>: <span class="string">'pretzel'</span>,</span><br><span class="line"> <span class="number">933</span>: <span class="string">'cheeseburger'</span>,</span><br><span class="line"> <span class="number">934</span>: <span class="string">'hotdog\n hot dog\n red hot'</span>,</span><br><span class="line"> <span class="number">935</span>: <span class="string">'mashed potato'</span>,</span><br><span class="line"> <span class="number">936</span>: <span class="string">'head cabbage'</span>,</span><br><span class="line"> <span class="number">937</span>: <span class="string">'broccoli'</span>,</span><br><span class="line"> <span class="number">938</span>: <span class="string">'cauliflower'</span>,</span><br><span class="line"> <span class="number">939</span>: <span class="string">'zucchini\n courgette'</span>,</span><br><span class="line"> <span class="number">940</span>: <span class="string">'spaghetti squash'</span>,</span><br><span class="line"> <span class="number">941</span>: <span class="string">'acorn squash'</span>,</span><br><span class="line"> <span class="number">942</span>: <span class="string">'butternut squash'</span>,</span><br><span class="line"> <span class="number">943</span>: <span class="string">'cucumber\n cuke'</span>,</span><br><span class="line"> <span class="number">944</span>: <span class="string">'artichoke\n globe artichoke'</span>,</span><br><span class="line"> <span class="number">945</span>: <span class="string">'bell pepper'</span>,</span><br><span class="line"> <span class="number">946</span>: <span class="string">'cardoon'</span>,</span><br><span class="line"> <span class="number">947</span>: <span class="string">'mushroom'</span>,</span><br><span class="line"> <span class="number">948</span>: <span class="string">'Granny Smith'</span>,</span><br><span class="line"> <span class="number">949</span>: <span class="string">'strawberry'</span>,</span><br><span class="line"> <span class="number">950</span>: <span class="string">'orange'</span>,</span><br><span class="line"> <span class="number">951</span>: <span class="string">'lemon'</span>,</span><br><span class="line"> <span class="number">952</span>: <span class="string">'fig'</span>,</span><br><span class="line"> <span class="number">953</span>: <span class="string">'pineapple\n ananas'</span>,</span><br><span class="line"> <span class="number">954</span>: <span class="string">'banana'</span>,</span><br><span class="line"> <span class="number">955</span>: <span class="string">'jackfruit\n jak\n jack'</span>,</span><br><span class="line"> <span class="number">956</span>: <span class="string">'custard apple'</span>,</span><br><span class="line"> <span class="number">957</span>: <span class="string">'pomegranate'</span>,</span><br><span class="line"> <span class="number">958</span>: <span class="string">'hay'</span>,</span><br><span class="line"> <span class="number">959</span>: <span class="string">'carbonara'</span>,</span><br><span class="line"> <span class="number">960</span>: <span class="string">'chocolate sauce\n chocolate syrup'</span>,</span><br><span class="line"> <span class="number">961</span>: <span class="string">'dough'</span>,</span><br><span class="line"> <span class="number">962</span>: <span class="string">'meat loaf\n meatloaf'</span>,</span><br><span class="line"> <span class="number">963</span>: <span class="string">'pizza\n pizza pie'</span>,</span><br><span class="line"> <span class="number">964</span>: <span class="string">'potpie'</span>,</span><br><span class="line"> <span class="number">965</span>: <span class="string">'burrito'</span>,</span><br><span class="line"> <span class="number">966</span>: <span class="string">'red wine'</span>,</span><br><span class="line"> <span class="number">967</span>: <span class="string">'espresso'</span>,</span><br><span class="line"> <span class="number">968</span>: <span class="string">'cup'</span>,</span><br><span class="line"> <span class="number">969</span>: <span class="string">'eggnog'</span>,</span><br><span class="line"> <span class="number">970</span>: <span class="string">'alp'</span>,</span><br><span class="line"> <span class="number">971</span>: <span class="string">'bubble'</span>,</span><br><span class="line"> <span class="number">972</span>: <span class="string">'cliff\n drop\n drop-off'</span>,</span><br><span class="line"> <span class="number">973</span>: <span class="string">'coral reef'</span>,</span><br><span class="line"> <span class="number">974</span>: <span class="string">'geyser'</span>,</span><br><span class="line"> <span class="number">975</span>: <span class="string">'lakeside\n lakeshore'</span>,</span><br><span class="line"> <span class="number">976</span>: <span class="string">'promontory\n headland\n head\n foreland'</span>,</span><br><span class="line"> <span class="number">977</span>: <span class="string">'sandbar\n sand bar'</span>,</span><br><span class="line"> <span class="number">978</span>: <span class="string">'seashore\n coast\n seacoast\n sea-coast'</span>,</span><br><span class="line"> <span class="number">979</span>: <span class="string">'valley\n vale'</span>,</span><br><span class="line"> <span class="number">980</span>: <span class="string">'volcano'</span>,</span><br><span class="line"> <span class="number">981</span>: <span class="string">'ballplayer\n baseball player'</span>,</span><br><span class="line"> <span class="number">982</span>: <span class="string">'groom\n bridegroom'</span>,</span><br><span class="line"> <span class="number">983</span>: <span class="string">'scuba diver'</span>,</span><br><span class="line"> <span class="number">984</span>: <span class="string">'rapeseed'</span>,</span><br><span class="line"> <span class="number">985</span>: <span class="string">'daisy'</span>,</span><br><span class="line"> <span class="number">986</span>: <span class="string">"yellow lady's slipper\n yellow lady-slipper\n Cypripedium calceolus\n Cypripedium parviflorum"</span>,</span><br><span class="line"> <span class="number">987</span>: <span class="string">'corn'</span>,</span><br><span class="line"> <span class="number">988</span>: <span class="string">'acorn'</span>,</span><br><span class="line"> <span class="number">989</span>: <span class="string">'hip\n rose hip\n rosehip'</span>,</span><br><span class="line"> <span class="number">990</span>: <span class="string">'buckeye\n horse chestnut\n conker'</span>,</span><br><span class="line"> <span class="number">991</span>: <span class="string">'coral fungus'</span>,</span><br><span class="line"> <span class="number">992</span>: <span class="string">'agaric'</span>,</span><br><span class="line"> <span class="number">993</span>: <span class="string">'gyromitra'</span>,</span><br><span class="line"> <span class="number">994</span>: <span class="string">'stinkhorn\n carrion fungus'</span>,</span><br><span class="line"> <span class="number">995</span>: <span class="string">'earthstar'</span>,</span><br><span class="line"> <span class="number">996</span>: <span class="string">'hen-of-the-woods\n hen of the woods\n Polyporus frondosus\n Grifola frondosa'</span>,</span><br><span class="line"> <span class="number">997</span>: <span class="string">'bolete'</span>,</span><br><span class="line"> <span class="number">998</span>: <span class="string">'ear\n spike\n capitulum'</span>,</span><br><span class="line"> <span class="number">999</span>: <span class="string">'toilet tissue\n toilet paper\n bathroom tissue'</span>&#125;</span><br></pre></td></tr></table></figure><p>app.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># Linux 服务器没有 GUI 的情况下使用 matplotlib 绘图，必须置于 pyplot 之前</span></span><br><span class="line"><span class="comment">#import matplotlib</span></span><br><span class="line"><span class="comment">#matplotlib.use('Agg')</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面三个是引用自定义模块</span></span><br><span class="line"><span class="keyword">import</span> vgg16</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">from</span> Nclasses <span class="keyword">import</span> labels</span><br><span class="line"></span><br><span class="line">img_path = input(<span class="string">'Input the path and image name:'</span>)</span><br><span class="line">img_ready = utils.load_image(img_path) <span class="comment"># 调用 load_image()函数，对待测试的图像做一些预处理操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个 figure 画图窗口，并指定窗口的名称，也可以设置窗口修的大小</span></span><br><span class="line">fig=plt.figure(<span class="string">u"Top-5 预测结果"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 定义一个维度为[1,224,224,3],类型为 float32 的 tensor 占位符</span></span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>])</span><br><span class="line">    vgg = vgg16.Vgg16() <span class="comment"># 类 Vgg16 实例化出 vgg</span></span><br><span class="line">    <span class="comment"># 调用类的成员方法 forward()，并传入待测试图像，这也就是网络前向传播的过程</span></span><br><span class="line">    vgg.forward(x)</span><br><span class="line">    <span class="comment"># 将一个 batch 的数据喂入网络，得到网络的预测输出</span></span><br><span class="line">    probability = sess.run(vgg.prob, feed_dict=&#123;x:img_ready&#125;)</span><br><span class="line">    <span class="comment"># np.argsort 函数返回预测值（probability 的数据结构[[各预测类别的概率值]]）由小到大的索引值，</span></span><br><span class="line">    <span class="comment"># 并取出预测概率最大的五个索引值</span></span><br><span class="line">    top5 = np.argsort(probability[<span class="number">0</span>])[<span class="number">-1</span>:<span class="number">-6</span>:<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"top5:"</span>,top5)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义两个 list---对应的概率值和实际标签（zebra）</span></span><br><span class="line">    values = []</span><br><span class="line">    bar_label = []</span><br><span class="line">    <span class="keyword">for</span> n, i <span class="keyword">in</span> enumerate(top5): <span class="comment"># 枚举上面取出的五个索引值</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"n:"</span>,n)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"i:"</span>,i)</span><br><span class="line">        values.append(probability[<span class="number">0</span>][i]) <span class="comment"># 将索引值对应的预测概率值取出并放入 values</span></span><br><span class="line">        bar_label.append(labels[i]) <span class="comment"># 根据索引值取出对应的实际标签并放入 bar_label</span></span><br><span class="line">        <span class="keyword">print</span> (i, <span class="string">":"</span>, labels[i], <span class="string">"----"</span>, utils.percent(probability[<span class="number">0</span>][i])) <span class="comment"># 打印属于某个类别的概率</span></span><br><span class="line"></span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>) <span class="comment"># 将画布划分为一行一列，并把下图放入其中</span></span><br><span class="line">    <span class="comment"># bar()函数绘制柱状图，参数 range(len(values)是柱子下标， values 表示柱高的列表（也就是五个预测概率值，</span></span><br><span class="line">    <span class="comment"># tick_label 是每个柱子上显示的标签（实际对应的标签）， width 是柱子的宽度， fc 是柱子的颜色）</span></span><br><span class="line">    ax.bar(range(len(values)), values, tick_label=bar_label, width=<span class="number">0.5</span>, fc=<span class="string">'g'</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">u'probability'</span>) <span class="comment"># 设置横轴标签</span></span><br><span class="line">    ax.set_title(<span class="string">u'Top-5'</span>) <span class="comment"># 添加标题</span></span><br><span class="line">    <span class="keyword">for</span> a,b <span class="keyword">in</span> zip(range(len(values)), values):</span><br><span class="line">      <span class="comment"># 在每个柱子的顶端添加对应的预测概率值， a， b 表示坐标， b+0.0005 表示要把文本信息放置在高于每个柱子顶端</span></span><br><span class="line">        <span class="comment">#0.0005 的位置，</span></span><br><span class="line">      <span class="comment"># center 是表示文本位于柱子顶端水平方向上的的中间位置， bottom 是将文本水平放置在柱子顶端垂直方向上的底端</span></span><br><span class="line">        <span class="comment">#位置， fontsize 是字号</span></span><br><span class="line">        ax.text(a, b+<span class="number">0.0005</span>, utils.percent(b), ha=<span class="string">'center'</span>, va = <span class="string">'bottom'</span>, fontsize=<span class="number">7</span>)</span><br><span class="line">    plt.savefig(<span class="string">'./result.jpg'</span>) <span class="comment"># 保存图片</span></span><br><span class="line">    plt.show() <span class="comment"># 弹窗展示图像（linux 服务器上将该句注释掉）</span></span><br></pre></td></tr></table></figure><p>项目里的vgg16.npy是从网上下的，读者可以自行下载</p><p>链接：<a href="https://pan.baidu.com/s/1ubSMbT4ZmhyaaV9lgNnKaw" target="_blank" rel="noopener">https://pan.baidu.com/s/1ubSMbT4ZmhyaaV9lgNnKaw</a>      提取码：3e42 </p><p>运行app.py，测试pic文件夹中的图片，图片也是自行下载</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文参考： &lt;a href=&quot;https://www.icourse163.org/learn/PKU-1002536002?tid=1206591210#/learn/content&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>检查点</title>
    <link href="http://yoursite.com/2020/02/23/%E6%A3%80%E6%9F%A5%E7%82%B9/"/>
    <id>http://yoursite.com/2020/02/23/检查点/</id>
    <published>2020-02-23T11:26:06.000Z</published>
    <updated>2020-02-24T08:13:29.577Z</updated>
    
    <content type="html"><![CDATA[<p>保存模型并不限于训练模型后，在训练模型之中也需要保存，因为Tensorflow训练模型时难免会出现中断的情况，我们自然希望能够将训练得到的参数保存下来，否则下次又要重新训练。这种在训练中保存模型，习惯上称之为保存检查点。</p><p>tf.train.get_checkpoint_state(checkpoint_dir,latest_filename=None)：该函数表示如果断点文件夹中包含有效断点状态文件，则返回该文件。参数说明：</p><p>​                checkpoint_dir：表示存储断点文件的目录</p><p>​                latest_filename=None：断点文件的可选名称，默认为”checkpoint”</p><p>通过添加检查点，可以生成载入检查点文件，并能够指定生成检查文件的个数。saver中的max_to_keep=1，表面最多只保存一个检查点文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver=tf.train.Saver(max_to_keep=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>对checkpoint文件进行加载的第一种方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cpkt = tf.train.get_checkpoint_state(savedir)</span><br><span class="line"><span class="keyword">if</span> cpkt <span class="keyword">and</span> cpkt.model_checkpoint_path:</span><br><span class="line">　　saver.restore(sess2, cpkt.model_checkpoint_path)</span><br></pre></td></tr></table></figure><p>上面代码位置：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/image-bed3/master/20200224160752.png" alt=""></p><p>第二种方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kpt = tf.train.latest_checkpoint(savedir)</span><br><span class="line">saver.restore(sess2, kpt)</span><br></pre></td></tr></table></figure><p>我们还可以用更加简便的方法进行检查点的保存，tf.train.MonitoredTrainingSession()函数，该函数可以直接实现保存载入检查点模型的文件，与前面的方法不同的是，它是按照训练时间来保存检查点的，可以通过指定save_checkpoint_secs参数的具体秒数，设置多久保存一次检查点</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#每5秒后，保存一次检查点。默认的保存时间间隔是10分钟</span></span><br><span class="line"><span class="keyword">with</span> tf.train.MonitoredTrainingSession(checkpoint_dir=savedir+<span class="string">"linear.cpkt"</span>,save_checkpoint_secs=<span class="number">5</span>) <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br></pre></td></tr></table></figure><p>这种按照时间保存的模式更适合用于使用大型数据集来训练复杂模型的情况。</p><p><strong>使用该方法前，必须要定义global_step变量</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">global_step=tf.train.get_or_create_global_step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">train_x = np.linspace(<span class="number">-5</span>, <span class="number">3</span>, <span class="number">50</span>)</span><br><span class="line">train_y = train_x * <span class="number">5</span> + <span class="number">10</span> + np.random.random(<span class="number">50</span>) * <span class="number">10</span> - <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.plot(train_x, train_y, 'r.')</span></span><br><span class="line"><span class="comment"># plt.grid(True)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(dtype=tf.float32)</span><br><span class="line">Y = tf.placeholder(dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">w = tf.Variable(tf.random.truncated_normal([<span class="number">1</span>]), name=<span class="string">'Weight'</span>)</span><br><span class="line">b = tf.Variable(tf.random.truncated_normal([<span class="number">1</span>]), name=<span class="string">'bias'</span>)</span><br><span class="line"></span><br><span class="line">z = tf.multiply(X, w) + b</span><br><span class="line"></span><br><span class="line">cost = tf.reduce_mean(tf.square(Y - z))</span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">training_epochs = <span class="number">30</span></span><br><span class="line">display_step = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">global_step = tf.train.get_or_create_global_step()</span><br><span class="line"></span><br><span class="line">step = tf.assign_add(global_step, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">savedir = <span class="string">"check-point/"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">with</span> tf.train.MonitoredTrainingSession(checkpoint_dir=savedir + <span class="string">'linear.cpkt'</span>, save_checkpoint_secs=<span class="number">5</span>) <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        loss_list = []</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">            sess.run(global_step)</span><br><span class="line">            <span class="keyword">for</span> (x, y) <span class="keyword">in</span> zip(train_x, train_y):</span><br><span class="line">                sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</span><br><span class="line">                loss = sess.run(cost, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line">                loss_list.append(loss)</span><br><span class="line">                print(<span class="string">'Iter: '</span>, epoch, <span class="string">' Loss: '</span>, loss)</span><br><span class="line"></span><br><span class="line">            w_, b_ = sess.run([w, b], feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line">            sess.run(step)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">" Finished "</span>)</span><br><span class="line">        print(<span class="string">"W: "</span>, w_, <span class="string">" b: "</span>, b_, <span class="string">" loss: "</span>, loss)</span><br><span class="line">        plt.plot(train_x, train_x * w_ + b_, <span class="string">'g-'</span>, train_x, train_y, <span class="string">'r.'</span>)</span><br><span class="line">        plt.grid(<span class="literal">True</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    load_epoch = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess2:</span><br><span class="line">        sess2.run(tf.global_variables_initializer())</span><br><span class="line">        kpt = tf.train.latest_checkpoint(savedir + <span class="string">'linear.cpkt'</span>)</span><br><span class="line">        saver.restore(sess2, kpt)</span><br><span class="line">        print(sess2.run([w, b], feed_dict=&#123;X: train_x, Y: train_y&#125;))</span><br></pre></td></tr></table></figure><p>第二个保存检查点的方法参考： <a href="https://www.cnblogs.com/baby-lily/p/10930591.html" target="_blank" rel="noopener">https://www.cnblogs.com/baby-lily/p/10930591.html</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;保存模型并不限于训练模型后，在训练模型之中也需要保存，因为Tensorflow训练模型时难免会出现中断的情况，我们自然希望能够将训练得到的参数保存下来，否则下次又要重新训练。这种在训练中保存模型，习惯上称之为保存检查点。&lt;/p&gt;
&lt;p&gt;tf.train.get_checkp
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>识别手写数字实战</title>
    <link href="http://yoursite.com/2020/02/19/%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2020/02/19/识别手写数字实战/</id>
    <published>2020-02-19T10:59:02.000Z</published>
    <updated>2020-02-23T11:21:42.620Z</updated>
    
    <content type="html"><![CDATA[<p>本次实战使用的数据集是mnist。tensorflow提供了一个库，可以直接用在下载MNIST，见下面代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist=input_data.read_data_sets(<span class="string">"./mnist_dataset/"</span>,one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>运行上面的代码，会自动下载数据集并将文件解压到当前代码所在的同级目录下。one_hot=True表示将样本标签转化为one-hot编码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回各子集样本数</span></span><br><span class="line">print(<span class="string">"train data size"</span>,mnist.train.num_examples)</span><br><span class="line"><span class="comment">#train data size  55000</span></span><br><span class="line">print(<span class="string">"validation data size"</span>,mnist.validation.num_examples)</span><br><span class="line"><span class="comment">#validation data size 5000</span></span><br><span class="line">print(<span class="string">"test data size"</span>,mnist.test.num_example)</span><br><span class="line"><span class="comment">#test data size 10000</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回标签，第1张图片的one-hot编码</span></span><br><span class="line">mnist.train.labels[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#返回数据，第1张图片的784个像素点</span></span><br><span class="line">mnist.train.images[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variables</span><span class="params">(shape)</span>:</span></span><br><span class="line">    w=tf.Variable(tf.random_normal(shape=shape,mean=<span class="number">1.0</span>,stddev=<span class="number">1.0</span>))</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variables</span><span class="params">(shape)</span>:</span></span><br><span class="line">    b=tf.Variable(tf.constant(<span class="number">0.0</span>,shape=shape))</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">()</span>:</span></span><br><span class="line">    x=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">    y_true=tf.placeholder(tf.int32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br><span class="line">    <span class="comment">#随机初始化权重,第一层卷积：5*5*1，32个，strides=1</span></span><br><span class="line">    w_conv1=weight_variables([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>])</span><br><span class="line">    b_conv1=bias_variables([<span class="number">32</span>])</span><br><span class="line">    <span class="comment">#将图片大小转为对应成4D输入 [None,784]-----&gt;[None,28,28,1]</span></span><br><span class="line">    x_reshape=tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line">    <span class="comment">#先卷积后激活函数，卷积：[None,28,28,1]-----&gt;[None,28,28,32]</span></span><br><span class="line">    x_relu1=tf.nn.relu(tf.nn.conv2d(x_reshape,w_conv1,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)+b_conv1)</span><br><span class="line">    <span class="comment">#池化 2*2 strides=2  [None,28,28,32]-----&gt;[None,14,14,32]</span></span><br><span class="line">    x_pool1=tf.nn.max_pool(x_relu1,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    <span class="comment">#第二个卷积层：[5,5,32,64] 偏置 64</span></span><br><span class="line">    w_conv2=weight_variables([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>])</span><br><span class="line">    b_conv2=bias_variables([<span class="number">64</span>])</span><br><span class="line">    <span class="comment">#卷积 [None,14,14,32]-----&gt;[None,14,14,64]</span></span><br><span class="line">    x_relu2 = tf.nn.relu(tf.nn.conv2d(x_pool1, w_conv2, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"SAME"</span>) + b_conv2)</span><br><span class="line">    <span class="comment">#池化 2*2 stride2 [None,14,14,64]------&gt;[None,7,7,64]</span></span><br><span class="line">    x_pool2=tf.nn.max_pool(x_relu2,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">    <span class="comment">#全连接层</span></span><br><span class="line">    w_fc=weight_variables([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">10</span>])</span><br><span class="line">    b_fc=bias_variables([<span class="number">10</span>])</span><br><span class="line">    x_fc_reshape=tf.reshape(x_pool2,[<span class="number">-1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">    <span class="comment">#矩阵运算</span></span><br><span class="line">    y_predict=tf.matmul(x_fc_reshape,w_fc)+b_fc</span><br><span class="line">    <span class="keyword">return</span> x,y_true,y_predict</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_fc</span><span class="params">()</span>:</span></span><br><span class="line">    mnist=input_data.read_data_sets(<span class="string">"./mnist_dataset/"</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line">    x,y_true,y_predict=model()</span><br><span class="line">    <span class="comment"># 求平均交叉熵损失</span></span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_predict))</span><br><span class="line">    <span class="comment"># 梯度下降求出损失</span></span><br><span class="line">    train_op = tf.train.GradientDescentOptimizer(<span class="number">0.0001</span>).minimize(loss)</span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    equal_list = tf.equal(tf.argmax(y_true, <span class="number">1</span>), tf.argmax(y_predict, <span class="number">1</span>))</span><br><span class="line">    <span class="comment">#cast转换数据类型</span></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(equal_list, tf.float32))</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init_op)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">            mnist_x,mnist_y=mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">            sess.run(train_op,feed_dict=&#123;x:mnist_x,y_true:mnist_y&#125;)</span><br><span class="line">            print(<span class="string">"训练第%d步，准确率为：%f"</span> % (i,sess.run(accuracy,feed_dict=&#123;x:mnist_x,y_true:mnist_y&#125;)))</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    conv_fc()</span><br></pre></td></tr></table></figure><p>上面的代码训练效果实在惨不忍睹，训练了半天还是连20%都没过。所以，又去抄了大佬的代码学习，他分成三个文件：mnist_forward、mnist_backward、mnist_test。</p><p>mnist_forward</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#输入节点</span></span><br><span class="line">INPUT_NODE = <span class="number">784</span></span><br><span class="line"><span class="comment">#输出十个数，每个数代表每个数字的概率</span></span><br><span class="line">OUTPUT_NODE = <span class="number">10</span></span><br><span class="line"><span class="comment">#隐藏节点个数</span></span><br><span class="line">LAYER1_NODE = <span class="number">500</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape, regularizer)</span>:</span></span><br><span class="line">    <span class="comment">#随机生成w</span></span><br><span class="line">    w = tf.Variable(tf.truncated_normal(shape,stddev=<span class="number">0.1</span>))</span><br><span class="line">    <span class="comment">#正则化</span></span><br><span class="line">    <span class="keyword">if</span> regularizer != <span class="literal">None</span>: tf.add_to_collection(<span class="string">'losses'</span>, tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(shape)</span>:</span>  </span><br><span class="line">    b = tf.Variable(tf.zeros(shape))  </span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x, regularizer)</span>:</span></span><br><span class="line">    w1 = get_weight([INPUT_NODE, LAYER1_NODE], regularizer)</span><br><span class="line">    b1 = get_bias([LAYER1_NODE])</span><br><span class="line">    y1 = tf.nn.relu(tf.matmul(x, w1) + b1)</span><br><span class="line"></span><br><span class="line">    w2 = get_weight([LAYER1_NODE, OUTPUT_NODE], regularizer)</span><br><span class="line">    b2 = get_bias([OUTPUT_NODE])</span><br><span class="line">    y = tf.matmul(y1, w2) + b2</span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><p>mnist_backward</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> mnist_forward</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#每轮训练200张图片</span></span><br><span class="line">BATCH_SIZE = <span class="number">200</span></span><br><span class="line"><span class="comment">#初始学习率</span></span><br><span class="line">LEARNING_RATE_BASE = <span class="number">0.1</span></span><br><span class="line"><span class="comment">#学习率衰减率</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span></span><br><span class="line"><span class="comment">#正则化系数</span></span><br><span class="line">REGULARIZER = <span class="number">0.0001</span></span><br><span class="line"><span class="comment">#共训练50000</span></span><br><span class="line">STEPS = <span class="number">50000</span></span><br><span class="line"><span class="comment">#滑动平均衰减率</span></span><br><span class="line">MOVING_AVERAGE_DECAY = <span class="number">0.99</span></span><br><span class="line"><span class="comment">#模型存放的路径</span></span><br><span class="line">MODEL_SAVE_PATH=<span class="string">"./model/"</span></span><br><span class="line"><span class="comment">#模型保存文件名</span></span><br><span class="line">MODEL_NAME=<span class="string">"mnist_model"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(mnist)</span>:</span></span><br><span class="line"></span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line">    y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.OUTPUT_NODE])</span><br><span class="line">    y = mnist_forward.forward(x, REGULARIZER)</span><br><span class="line">    <span class="comment">#设定global_step初值为0，设定为不可训练</span></span><br><span class="line">    global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">    cem = tf.reduce_mean(ce)</span><br><span class="line">    <span class="comment">#加上正则化</span></span><br><span class="line">    loss = cem + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br><span class="line">    <span class="comment">#学习率衰减</span></span><br><span class="line">    learning_rate = tf.train.exponential_decay(</span><br><span class="line">        LEARNING_RATE_BASE,</span><br><span class="line">        global_step,</span><br><span class="line">        mnist.train.num_examples / BATCH_SIZE, </span><br><span class="line">        LEARNING_RATE_DECAY,</span><br><span class="line">        staircase=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#梯度下降</span></span><br><span class="line">    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</span><br><span class="line"><span class="comment">#滑动平均</span></span><br><span class="line">    ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)</span><br><span class="line">    ema_op = ema.apply(tf.trainable_variables())</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([train_step, ema_op]):</span><br><span class="line">        train_op = tf.no_op(name=<span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init_op = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init_op)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">            xs, ys = mnist.train.next_batch(BATCH_SIZE)</span><br><span class="line">            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict=&#123;x: xs, y_: ys&#125;)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"After %d training step(s), loss on training batch is %g."</span> % (step, loss_value))</span><br><span class="line">                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">"./data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">    backward(mnist)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>mnist_test</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> mnist_forward</span><br><span class="line"><span class="keyword">import</span> mnist_backward</span><br><span class="line">TEST_INTERVAL_SECS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(mnist)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> g:</span><br><span class="line">        x = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line">        y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.OUTPUT_NODE])</span><br><span class="line">        y = mnist_forward.forward(x, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        ema = tf.train.ExponentialMovingAverage(mnist_backward.MOVING_AVERAGE_DECAY)</span><br><span class="line">        ema_restore = ema.variables_to_restore()</span><br><span class="line">        saver = tf.train.Saver(ema_restore)</span><br><span class="line"></span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">                <span class="comment">#保存节点状态</span></span><br><span class="line">                <span class="comment">#26、27行代码用于访问到最新保存的节点文件</span></span><br><span class="line">                ckpt = tf.train.get_checkpoint_state(mnist_backward.MODEL_SAVE_PATH)</span><br><span class="line">                <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">                    saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">                    global_step = ckpt.model_checkpoint_path.split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'-'</span>)[<span class="number">-1</span>]</span><br><span class="line">                    accuracy_score = sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)</span><br><span class="line">                    print(<span class="string">"After %s training step(s), test accuracy = %g"</span> % (global_step, accuracy_score))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">'No checkpoint file found'</span>)</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">            time.sleep(TEST_INTERVAL_SECS)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">"./data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">    test(mnist)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本次实战使用的数据集是mnist。tensorflow提供了一个库，可以直接用在下载MNIST，见下面代码。&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span clas
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>房价预测实战</title>
    <link href="http://yoursite.com/2020/02/19/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2020/02/19/房价预测实战/</id>
    <published>2020-02-19T08:38:48.000Z</published>
    <updated>2020-02-19T10:57:42.860Z</updated>
    
    <content type="html"><![CDATA[<p>用到的模块也是pandas、numpy、tensorflow。</p><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#归一化处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_feature</span><span class="params">(df)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> df.apply(<span class="keyword">lambda</span> column:(column-column.mean())/column.std())</span><br><span class="line">df=pd.read_csv(<span class="string">"data1.csv"</span>,names=[<span class="string">"square"</span>,<span class="string">"bedrooms"</span>,<span class="string">"price"</span>])</span><br><span class="line">df=normalize_feature(df)</span><br><span class="line">print(df.head())</span><br><span class="line">X_data=np.array(df[df.columns[<span class="number">0</span>:<span class="number">2</span>]])</span><br><span class="line">y_data=np.array(df[df.columns[<span class="number">-1</span>]]).reshape(len(df),<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>为什么归一化？</p><p> 最优解的寻优过程明显会变得平缓，更容易正确的收敛到最优解。 </p><h2 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">alpha = <span class="number">0.01</span> <span class="comment"># 学习率 alpha</span></span><br><span class="line">epoch = <span class="number">500</span> <span class="comment"># 轮数</span></span><br><span class="line">X = tf.placeholder(tf.float32, X_data.shape, name=<span class="string">'X'</span>)</span><br><span class="line">    <span class="comment"># 输出 y，形状[47, 1]</span></span><br><span class="line">y = tf.placeholder(tf.float32, y_data.shape, name=<span class="string">'y'</span>)</span><br><span class="line"><span class="comment">#W = tf.get_variable("weights",(X_data.shape[1], 1),initializer=tf.constant_initializer())</span></span><br><span class="line">W=tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">1</span>]))</span><br><span class="line">b=tf.Variable(tf.random_normal([<span class="number">1</span>]))</span><br><span class="line">    <span class="comment">#  y_pred  形状[47,1]</span></span><br><span class="line">y_pred = tf.matmul(X, W, name=<span class="string">'y_pred'</span>)+b</span><br><span class="line">  <span class="comment"># tf.matmul(a,b,transpose_a=True) 表示：矩阵a的转置乘矩阵b，即 [1,47] X [47,1]</span></span><br><span class="line">loss_op = <span class="number">1</span> / (<span class="number">2</span> * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=<span class="literal">True</span>)</span><br><span class="line">train_op = tf.train.GradientDescentOptimizer(learning_rate=alpha).minimize(loss_op)</span><br></pre></td></tr></table></figure><h2 id="全部代码"><a href="#全部代码" class="headerlink" title="全部代码"></a>全部代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#归一化处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_feature</span><span class="params">(df)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> df.apply(<span class="keyword">lambda</span> column:(column-column.mean())/column.std())</span><br><span class="line">df=pd.read_csv(<span class="string">"data1.csv"</span>,names=[<span class="string">"square"</span>,<span class="string">"bedrooms"</span>,<span class="string">"price"</span>])</span><br><span class="line">df=normalize_feature(df)</span><br><span class="line">print(df.head())</span><br><span class="line">X_data=np.array(df[df.columns[<span class="number">0</span>:<span class="number">2</span>]])</span><br><span class="line">y_data=np.array(df[df.columns[<span class="number">-1</span>]]).reshape(len(df),<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">alpha = <span class="number">0.01</span> <span class="comment"># 学习率 alpha</span></span><br><span class="line">epoch = <span class="number">500</span> <span class="comment"># 轮数</span></span><br><span class="line">X = tf.placeholder(tf.float32, X_data.shape, name=<span class="string">'X'</span>)</span><br><span class="line">    <span class="comment"># 输出 y，形状[47, 1]</span></span><br><span class="line">y = tf.placeholder(tf.float32, y_data.shape, name=<span class="string">'y'</span>)</span><br><span class="line"><span class="comment">#W = tf.get_variable("weights",(X_data.shape[1], 1),initializer=tf.constant_initializer())</span></span><br><span class="line">W=tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">1</span>]))</span><br><span class="line">b=tf.Variable(tf.random_normal([<span class="number">1</span>]))</span><br><span class="line">    <span class="comment">#  y_pred  形状[47,1]</span></span><br><span class="line">y_pred = tf.matmul(X, W, name=<span class="string">'y_pred'</span>)+b</span><br><span class="line">  <span class="comment"># tf.matmul(a,b,transpose_a=True) 表示：矩阵a的转置乘矩阵b，即 [1,47] X [47,1]</span></span><br><span class="line">loss_op = <span class="number">1</span> / (<span class="number">2</span> * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=<span class="literal">True</span>)</span><br><span class="line">train_op = tf.train.GradientDescentOptimizer(learning_rate=alpha).minimize(loss_op)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 初始化全局变量</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># 记录所有损失值</span></span><br><span class="line">    loss_data = []</span><br><span class="line">    <span class="comment"># 开始训练模型</span></span><br><span class="line">    <span class="comment"># 因为训练集较小，所以采用批梯度下降优化算法，每次都使用全量数据训练</span></span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(<span class="number">1</span>, epoch + <span class="number">1</span>):</span><br><span class="line">        _, loss, w = sess.run([train_op, loss_op, W], feed_dict=&#123;X: X_data, y: y_data&#125;)</span><br><span class="line">        <span class="comment"># 记录每一轮损失值变化情况</span></span><br><span class="line">        loss_data.append(float(loss))</span><br><span class="line">        <span class="keyword">if</span> e % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            log_str = <span class="string">"Epoch %d \t Loss=%.4g \t"</span></span><br><span class="line">            print(log_str % (e, loss))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;用到的模块也是pandas、numpy、tensorflow。&lt;/p&gt;
&lt;h2 id=&quot;数据处理&quot;&gt;&lt;a href=&quot;#数据处理&quot; class=&quot;headerlink&quot; title=&quot;数据处理&quot;&gt;&lt;/a&gt;数据处理&lt;/h2&gt;&lt;figure class=&quot;highlight p
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>TCP的长连接和短连接</title>
    <link href="http://yoursite.com/2020/02/17/TCP%E7%9A%84%E9%95%BF%E8%BF%9E%E6%8E%A5%E5%92%8C%E7%9F%AD%E8%BF%9E%E6%8E%A5/"/>
    <id>http://yoursite.com/2020/02/17/TCP的长连接和短连接/</id>
    <published>2020-02-17T07:30:43.000Z</published>
    <updated>2020-02-17T07:45:40.141Z</updated>
    
    <content type="html"><![CDATA[<p>本文参考： <a href="https://www.cnblogs.com/georgexu/p/10909814.html" target="_blank" rel="noopener">https://www.cnblogs.com/georgexu/p/10909814.html</a> </p><p>在TCP真正的读写之前，server和client之间必须建立一个连接，当读写操作完成后，双方不再需要这个连接时它们可以释放这个连接，连接的建立通过三次握手，释放时需要四次握手，每个连接的建立都是需要资源消耗和时间消耗。</p><h2 id="TCP短连接"><a href="#TCP短连接" class="headerlink" title="TCP短连接"></a>TCP短连接</h2><p>模拟一种TCP短连接的情况:</p><ol><li>client 向 server 发起连接请求</li><li>server 接到请求，双方建立连接</li><li>client 向 server 发送消息</li><li>server 回应 client</li><li>一次读写完成，此时双方任何一个都可以发起 close 操作</li></ol><p>在步骤5中，一般都是 client 先发起 close 操作。当然也不排除有特殊的情况。</p><p>从上面的描述看，短连接一般只会在 client/server 间传递一次读写操作！</p><h2 id="TCP长连接"><a href="#TCP长连接" class="headerlink" title="TCP长连接"></a>TCP长连接</h2><p>再模拟一种长连接的情况:</p><ol><li>client 向 server 发起连接</li><li>server 接到请求，双方建立连接</li><li>client 向 server 发送消息</li><li>server 回应 client</li><li>一次读写完成，连接不关闭</li><li>后续读写操作…</li><li>长时间操作之后client发起关闭请求</li></ol><h2 id="TCP长-短连接操作过程"><a href="#TCP长-短连接操作过程" class="headerlink" title="TCP长/短连接操作过程"></a>TCP长/短连接操作过程</h2><h3 id="短连接的操作步骤是："><a href="#短连接的操作步骤是：" class="headerlink" title="短连接的操作步骤是："></a>短连接的操作步骤是：</h3><p>建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接</p><h3 id="长连接的操作步骤是："><a href="#长连接的操作步骤是：" class="headerlink" title="长连接的操作步骤是："></a>长连接的操作步骤是：</h3><p>建立连接——数据传输…（保持连接）…数据传输——关闭连接</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，较适用长连接。</p><p>client与server之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server早晚有扛不住的时候，这时候server端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致server端服务受损；如果条件再允许就可以以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务。</p><p>短连接对于服务器来说管理较为简单，存在的连接都是有用的连接，不需要额外的控制手段。但如果客户请求频繁，将在TCP的建立和关闭操作上浪费时间和带宽。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文参考： &lt;a href=&quot;https://www.cnblogs.com/georgexu/p/10909814.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/georgexu/p/109098
      
    
    </summary>
    
      <category term="网络知识" scheme="http://yoursite.com/categories/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="网络知识" scheme="http://yoursite.com/tags/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>泰坦尼克号获救预测实战</title>
    <link href="http://yoursite.com/2020/02/14/%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E8%8E%B7%E6%95%91%E9%A2%84%E6%B5%8B%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2020/02/14/泰坦尼克号获救预测实战/</id>
    <published>2020-02-14T07:59:46.000Z</published>
    <updated>2020-02-15T08:24:20.726Z</updated>
    
    <content type="html"><![CDATA[<p>在本次实战，会用到numpy和pandas等模块，不会的话，请补完自己的知识空区。</p><p><a href="https://www.kaggle.com/c/titanic/data" target="_blank" rel="noopener">本次数据集的下载网址</a></p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=pd.read_csv(<span class="string">"train.csv"</span>)</span><br><span class="line"><span class="comment">#查看数据集的字段</span></span><br><span class="line">print(data.columns)</span><br></pre></td></tr></table></figure><p>数据字段含义如下：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200214190725.png" alt=""></p><p>接着我们把一些没有什么用的字段删掉，比如Name、Ticket</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data=data[[<span class="string">"Survived"</span>,<span class="string">"Pclass"</span>,<span class="string">"Sex"</span>,<span class="string">"Age"</span>,<span class="string">"SibSp"</span>,<span class="string">"Parch"</span>,<span class="string">"Fare"</span>,<span class="string">"Cabin"</span>,<span class="string">"Embarked"</span>]]</span><br></pre></td></tr></table></figure><p>接着，我们发现有一些NAN的数据，我们用年龄的平均填充一下，即使使用平均年龄填充并不是很好</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">"Age"</span>]=data[<span class="string">"Age"</span>].fillna(data[<span class="string">"Age"</span>].mean())</span><br></pre></td></tr></table></figure><p>对Cabin字段数值化，数值化返回的是一个元祖，元祖后的第一项就是数值化后的值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">"Cabin"</span>]=pd.factorize(data.Cabin)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>对其它的NAN数据都填充为0</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.fillna(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>对Sex特征进行数值化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">"Sex"</span>]=[<span class="number">1</span> <span class="keyword">if</span> x==<span class="string">"male"</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> data.Sex]</span><br></pre></td></tr></table></figure><p>对Pclass进行one-hot编码，添加三个特征，将Pclass特征删除</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">"p1"</span>]=np.array(data[<span class="string">"Pclass"</span>]==<span class="number">1</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">"p2"</span>]=np.array(data[<span class="string">"Pclass"</span>]==<span class="number">2</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">"p3"</span>]=np.array(data[<span class="string">"Pclass"</span>]==<span class="number">3</span>).astype(np.int32)</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">"Pclass"</span>]</span><br></pre></td></tr></table></figure><p>对Embarked，首先知道它有三个港口，0是我们刚刚填充NAN的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(data.Embarked.unique())</span><br><span class="line"><span class="comment">#['S' 'C' 'Q' 0]</span></span><br></pre></td></tr></table></figure><p>接着对Embarked进行one-hot编码，再删除Embarked特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">"e1"</span>]=np.array(data[<span class="string">"Embarked"</span>]==<span class="string">"S"</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">"e2"</span>]=np.array(data[<span class="string">"Embarked"</span>]==<span class="string">"C"</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">"e3"</span>]=np.array(data[<span class="string">"Embarked"</span>]==<span class="string">"Q"</span>).astype(np.int32)</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">"Embarked"</span>]</span><br></pre></td></tr></table></figure><p>数据的预处理就结束了</p><h3 id="提取训练数据"><a href="#提取训练数据" class="headerlink" title="提取训练数据"></a>提取训练数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_train=data[[<span class="string">"Sex"</span>,<span class="string">"Age"</span>,<span class="string">"SibSp"</span>,<span class="string">"Parch"</span>,<span class="string">"Fare"</span>,<span class="string">"Cabin"</span>,<span class="string">"p1"</span>,<span class="string">"p2"</span>,<span class="string">"p3"</span>,<span class="string">"e1"</span>,<span class="string">"e2"</span>,<span class="string">"e3"</span>]]</span><br></pre></td></tr></table></figure><h3 id="数据标签"><a href="#数据标签" class="headerlink" title="数据标签"></a>数据标签</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_target=data[<span class="string">"Survived"</span>].values.reshape(len(data),<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = tf.placeholder(<span class="string">"float"</span>, shape=[<span class="literal">None</span>, <span class="number">12</span>])</span><br><span class="line">y = tf.placeholder(<span class="string">"float"</span>, shape=[<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">weight = tf.Variable(tf.random_normal([<span class="number">12</span>, <span class="number">1</span>]))</span><br><span class="line">bias = tf.Variable(tf.random_normal([<span class="number">1</span>]))</span><br><span class="line">output = tf.matmul(x, weight) + bias</span><br><span class="line">pred = tf.cast(tf.sigmoid(output) &gt; <span class="number">0.5</span>, tf.float32)</span><br><span class="line">loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss)</span><br><span class="line">accurary = tf.reduce_mean(tf.cast(tf.equal(pred, y), tf.float32))</span><br></pre></td></tr></table></figure><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(loss_train, <span class="string">'k-'</span>)</span><br><span class="line">plt.title(<span class="string">'train loss'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(train_acc, <span class="string">'b-'</span>, label=<span class="string">'train_acc'</span>)</span><br><span class="line">plt.plot(test_acc, <span class="string">'r--'</span>, label=<span class="string">'test_acc'</span>)</span><br><span class="line">plt.title(<span class="string">'train and test accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="全部代码"><a href="#全部代码" class="headerlink" title="全部代码"></a>全部代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = pd.read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">data = data[[<span class="string">'Survived'</span>, <span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Cabin'</span>, <span class="string">'Embarked'</span>]]</span><br><span class="line">data[<span class="string">'Age'</span>] = data[<span class="string">'Age'</span>].fillna(data[<span class="string">'Age'</span>].mean())</span><br><span class="line">data[<span class="string">'Cabin'</span>] = pd.factorize(data[<span class="string">'Cabin'</span>])[<span class="number">0</span>]</span><br><span class="line">data.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">data[<span class="string">'Sex'</span>] = [<span class="number">1</span> <span class="keyword">if</span> x==<span class="string">'male'</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> data[<span class="string">'Sex'</span>]]</span><br><span class="line">data[<span class="string">'p1'</span>] = np.array(data[<span class="string">'Pclass'</span>]==<span class="number">1</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">'p2'</span>] = np.array(data[<span class="string">'Pclass'</span>]==<span class="number">2</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">'p3'</span>] = np.array(data[<span class="string">'Pclass'</span>]==<span class="number">3</span>).astype(np.int32)</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">'Pclass'</span>]</span><br><span class="line">data[<span class="string">'e1'</span>] = np.array(data[<span class="string">'Embarked'</span>]==<span class="string">'S'</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">'e2'</span>] = np.array(data[<span class="string">'Embarked'</span>]==<span class="string">'C'</span>).astype(np.int32)</span><br><span class="line">data[<span class="string">'e3'</span>] = np.array(data[<span class="string">'Embarked'</span>]==<span class="string">'Q'</span>).astype(np.int32)</span><br><span class="line"><span class="keyword">del</span> data[<span class="string">'Embarked'</span>]</span><br><span class="line"></span><br><span class="line">data_train = data[[ <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Cabin'</span>, <span class="string">'p1'</span>, <span class="string">'p2'</span>, <span class="string">'p3'</span>, <span class="string">'e1'</span>, <span class="string">'e2'</span>, <span class="string">'e3'</span>]]</span><br><span class="line">data_target = data[<span class="string">'Survived'</span>].values.reshape(len(data), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, shape=[<span class="literal">None</span>, <span class="number">12</span>])</span><br><span class="line">y = tf.placeholder(<span class="string">"float"</span>, shape=[<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">weight = tf.Variable(tf.random_normal([<span class="number">12</span>, <span class="number">1</span>]))</span><br><span class="line">bias = tf.Variable(tf.random_normal([<span class="number">1</span>]))</span><br><span class="line">output = tf.matmul(x, weight) + bias</span><br><span class="line">pred = tf.cast(tf.sigmoid(output) &gt; <span class="number">0.5</span>, tf.float32)</span><br><span class="line">loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss)</span><br><span class="line">accurary = tf.reduce_mean(tf.cast(tf.equal(pred, y), tf.float32))</span><br><span class="line"> </span><br><span class="line">data_test = pd.read_csv(<span class="string">'test.csv'</span>)</span><br><span class="line">data_test = data_test[[<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Cabin'</span>, <span class="string">'Embarked'</span>]]</span><br><span class="line">data_test[<span class="string">'Age'</span>] = data_test[<span class="string">'Age'</span>].fillna(data_test[<span class="string">'Age'</span>].mean())</span><br><span class="line">data_test[<span class="string">'Cabin'</span>] = pd.factorize(data_test[<span class="string">'Cabin'</span>])[<span class="number">0</span>]</span><br><span class="line">data_test.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">data_test[<span class="string">'Sex'</span>] = [<span class="number">1</span> <span class="keyword">if</span> x==<span class="string">'male'</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> data_test[<span class="string">'Sex'</span>]]</span><br><span class="line">data_test[<span class="string">'p1'</span>] = np.array(data_test[<span class="string">'Pclass'</span>]==<span class="number">1</span>).astype(np.int32)</span><br><span class="line">data_test[<span class="string">'p2'</span>] = np.array(data_test[<span class="string">'Pclass'</span>]==<span class="number">2</span>).astype(np.int32)</span><br><span class="line">data_test[<span class="string">'p3'</span>] = np.array(data_test[<span class="string">'Pclass'</span>]==<span class="number">3</span>).astype(np.int32)</span><br><span class="line"><span class="keyword">del</span> data_test[<span class="string">'Pclass'</span>]</span><br><span class="line">data_test[<span class="string">'e1'</span>] = np.array(data_test[<span class="string">'Embarked'</span>]==<span class="string">'S'</span>).astype(np.int32)</span><br><span class="line">data_test[<span class="string">'e2'</span>] = np.array(data_test[<span class="string">'Embarked'</span>]==<span class="string">'C'</span>).astype(np.int32)</span><br><span class="line">data_test[<span class="string">'e3'</span>] = np.array(data_test[<span class="string">'Embarked'</span>]==<span class="string">'Q'</span>).astype(np.int32)</span><br><span class="line"><span class="keyword">del</span> data_test[<span class="string">'Embarked'</span>]</span><br><span class="line"></span><br><span class="line">test_label = pd.read_csv(<span class="string">'gender_submission.csv'</span>)</span><br><span class="line">test_label = np.reshape(test_label[<span class="string">'Survived'</span>].values.astype(np.float32), (<span class="number">418</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">loss_train=[]</span><br><span class="line">train_acc = []</span><br><span class="line">test_acc = []</span><br><span class="line"><span class="comment">#这句代码不可缺</span></span><br><span class="line">data_train = data_train.values</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25000</span>):</span><br><span class="line">    index = np.random.permutation(len(data_target))</span><br><span class="line">    data_train = data_train[index]</span><br><span class="line">    data_target = data_target[index]</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(len(data_target)//<span class="number">100</span> + <span class="number">1</span>):</span><br><span class="line">      batch_xs = data_train[n*<span class="number">100</span>:n*<span class="number">100</span>+<span class="number">100</span>]</span><br><span class="line">      batch_ys = data_target[n*<span class="number">100</span>:n*<span class="number">100</span>+<span class="number">100</span>]</span><br><span class="line">      sess.run(train_step, feed_dict=&#123;x:batch_xs, y:batch_ys&#125;)</span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">      loss_temp = sess.run(loss, feed_dict=&#123;x:batch_xs, y:batch_ys&#125;)</span><br><span class="line">      loss_train.append(loss_temp)</span><br><span class="line">      train_acc_temp = sess.run(accurary, feed_dict=&#123;x:batch_xs, y:batch_ys&#125;)</span><br><span class="line">      train_acc.append(train_acc_temp)</span><br><span class="line">      test_acc_temp = sess.run(accurary, feed_dict=&#123;x:data_test, y:test_label&#125;)</span><br><span class="line">      test_acc.append(test_acc_temp)</span><br><span class="line">      print(loss_temp,train_acc_temp,test_acc_temp)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(loss_train, <span class="string">'k-'</span>)</span><br><span class="line">plt.title(<span class="string">'train loss'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(train_acc, <span class="string">'b-'</span>, label=<span class="string">'train_acc'</span>)</span><br><span class="line">plt.plot(test_acc, <span class="string">'r--'</span>, label=<span class="string">'test_acc'</span>)</span><br><span class="line">plt.title(<span class="string">'train and test accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在本次实战，会用到numpy和pandas等模块，不会的话，请补完自己的知识空区。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.kaggle.com/c/titanic/data&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;本次数据集的下载网
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>何为端到端？</title>
    <link href="http://yoursite.com/2020/02/11/%E4%BD%95%E4%B8%BA%E7%AB%AF%E5%88%B0%E7%AB%AF%EF%BC%9F/"/>
    <id>http://yoursite.com/2020/02/11/何为端到端？/</id>
    <published>2020-02-11T03:36:08.000Z</published>
    <updated>2020-02-11T07:11:17.181Z</updated>
    
    <content type="html"><![CDATA[<p>传统机器学习的流程往往由多个独立的模块组成。比如在自然语言处理问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，每个任务结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端。</p><p>端到端学习到底是什么呢？上面说了，在一些问题需要多个阶段的处理，那么端到端学习就是忽略所有不同的阶段，用单个神经网络代替它。从输入端到输出端会得到一个预测结果，与真实结果相比较会得到一个误差，这个误差会在模型中的每一层反向传播，每一层的表示都会根据这个误差再做调整，直到模型收敛或达到模型预期效果才结束，中间所有的操作都包含在神经网络内部，不再分成多个模块处理。由原始数据输入，到结果输出，从输入端到输出端，中间的神经网络自成一体，这就是端到端学习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;传统机器学习的流程往往由多个独立的模块组成。比如在自然语言处理问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，每个任务结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端。&lt;/p&gt;
&lt;p&gt;端到端学习到底是什么呢？上面说了，
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow中的模型训练技巧</title>
    <link href="http://yoursite.com/2020/01/15/Tensorflow%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/"/>
    <id>http://yoursite.com/2020/01/15/Tensorflow中的模型训练技巧/</id>
    <published>2020-01-15T07:07:04.000Z</published>
    <updated>2020-01-16T02:17:34.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="优化卷积核"><a href="#优化卷积核" class="headerlink" title="优化卷积核"></a>优化卷积核</h2><p>在实际的卷积训练中，为了加快速度，常常把卷积层裁开。比如一个3x3的过滤器，可以裁成3x1和1x3两个过滤器，分别对原有输入做卷积操作，这样可以大大提升运算速度</p><p>原理：在浮点运算中乘法消耗的资源较多，我们的目的就是尽量减小乘法运算</p><p>比如：对一个5x2的原始图片进行一次3x3的同卷积，相当于生成的5x2像素中每一个都要经历3x3次乘法，一共90次。同样一张图片，如果先进行一次3x1的同卷积需要30次运算，再进行一次1x3的同卷积还是30次，一共60次。</p><p>看下面例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv2=tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)</span><br></pre></td></tr></table></figure><p>修改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">W_conv21 = weight_variable([<span class="number">5</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">64</span>])</span><br><span class="line">b_conv21 = bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv21 = tf.nn.relu(conv2d(h_pool1, W_conv21) + b_conv21)</span><br><span class="line">W_conv2 = weight_variable([<span class="number">1</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv2=tf.nn.relu(conv2d(h_conv21,W_conv2)+b_conv2)</span><br></pre></td></tr></table></figure><h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><p>批量归一化，简称BN算法。一般用在全连接层或卷积神经网络。它的作用是要最大限度地保证每次的正向传播输出在同一分布上， 这样反向计算时参照的数据样本分布就会与正向计算时的数据分布一样了。 保证了分布统一， 对权重的调整才会更有意义。  </p><p>批量归一化的做法很简单，即将每一层运算出来的数据都归一化成均值为0、方差为1的标准高斯分布。这样就会在保留样本分布特征的同时，又消除了层与层之间的分布差异</p><p>Tensorflow中自带的BN函数定义：</p><p>tf.nn.batch_normalization(x,mean,variance,offset,scale,variance_epsion,name=None)，参数说明如下：</p><p>x：代表输入</p><p>mean：代表样本的均值</p><p>variance：代表方差</p><p>offset：代表偏移，即相加一个转化值，后面我们会用激活函数来转换，所以直接使用0</p><p>scale：代表缩放，即乘以一个转化值。一般用1</p><p>variance_epsilon：为了避免分布为0的情况，给分母加一个极小值</p><p>要想使用上面这个BN函数，必须由另一个函数配合使用——tf.nn.moments，由他来计算均值和方差，然后就可以使用BN。tf.nn.moments定义如下：</p><p>tf.nn.moments(x,axes,name=None,keep_dims=False)</p><p>axes主要是指定哪个轴来求均值与方差</p><p>有了上面的两个函数还不够，为了有更好的效果，我们希望使用平滑指数衰减的方法来优化每次的均值与方差，于是就用到了tf.train.ExponentialMovingAverage函数。它的左右是上一次的值对本次的值有个衰减后的影响，从而使每次的值连起来后会相对平滑一些。展开后可以用下列等式表示：</p><p>shadow_variable = decay * shadow_variable + (1- decay) * variable，各参数说明如下：</p><p>decay：代表衰减指数，直接指定的。比如0.9</p><p>variable：代表本批次样本中的值</p><p>等式右边的shadow_variable：代表上次总样本的值</p><p>等式左边的shadow_variable：代表计算出来的本次总样本的值</p><p>上面的函数需要联合使用，于是在Tensorflow中的layers模块又实现了一次BN函数，相当于把上面几个函数结合在一起。使用时，首先将头文件引入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.contrib.layers.python.layers <span class="keyword">import</span> barch_norm</span><br></pre></td></tr></table></figure><p>batch_norm(inputs,decay=0.999,center=True,scale=False,epsilon=0.001,activation_fn=None,param_initializers=None,param_regularizers=None,updates_collections=ops.GraphKeys.UPDATE_OPS,is_training=True,reuse=None,variables_collections=None,outputs_collections=None,trainable=True,batch_weights=None,fused=False,data_format=DATA_FORMAT_NHWC,zero_debias_moving_mean=False,scope=None,renorm=False,renorm_clipping=None,renorm_decay=0.9)，参数看得眼都花了，参数说明如下：</p><p>inputs：代表输入</p><p>decay：代表移动平均值的衰败速度，是使用了一种叫做平滑指数衰减的方法更新均值方差，一般设为0.9；值太小会导致均值和方差更新太快，而值太大又会导致几乎没有衰减，容易出现过拟合。</p><p>scale：是否进行变化（通过乘一个gamma值进行缩放），一般设为False。</p><p>epsilon：是为了避免分母为0的情况，给分母加一个极小值，默认即可。</p><p>is_training：当它为True，代表是训练过程，这时会不断更新样本集的均值与方差。测试时，设为False，就会使用测试样本集的均值与方差</p><p>updatas_collections：默认为tf.GraphKeys.UPDARE_OPS，在训练时提供一种内置的均值方差更新机制，即通过图中的tf.GraphKeys.UPDATE_OPS变量来更新。但它是在每次当前批次训练完成后才更新均值和方差，这样导致当前数据总是使用前一次的均值和方差，没有得到最新的更新。所以都会将其设为None，让均值和方差即时更新。</p><p>reuse：支持共享变量，与下面的scope参数联合使用</p><p>scope：指定变量的作用域variable_scope</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;优化卷积核&quot;&gt;&lt;a href=&quot;#优化卷积核&quot; class=&quot;headerlink&quot; title=&quot;优化卷积核&quot;&gt;&lt;/a&gt;优化卷积核&lt;/h2&gt;&lt;p&gt;在实际的卷积训练中，为了加快速度，常常把卷积层裁开。比如一个3x3的过滤器，可以裁成3x1和1x3两个过滤器，分别对
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>梯度</title>
    <link href="http://yoursite.com/2020/01/15/%E6%A2%AF%E5%BA%A6/"/>
    <id>http://yoursite.com/2020/01/15/梯度/</id>
    <published>2020-01-15T01:15:11.000Z</published>
    <updated>2020-01-16T02:06:24.435Z</updated>
    
    <content type="html"><![CDATA[<p>在反向传播过程中，神经网络需要对每一个loss对应的学习参数求偏导，算出的这个值叫做梯度，用来乘以学习率然后更新学习参数使用的</p><h2 id="求单变量偏导"><a href="#求单变量偏导" class="headerlink" title="求单变量偏导"></a>求单变量偏导</h2><p>它是通过tf.gradients函数来实现的。<br>tf.gradients(ys,xs,grad_ys=None,name=’gradients’,colocate_gradients_with_ops=False,gate_gradients=False,  aggregation_method=None,stop_gradients=None)</p><p>第一个参数为求导公式的结果，第二个参数为指定公式中的哪个变量来求偏导。实现第一个参数对第二个参数求导。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w1=tf.Variable([[<span class="number">1</span>,<span class="number">2</span>]],dtype=tf.float32)</span><br><span class="line">w2=tf.Variable([[<span class="number">3</span>,<span class="number">4</span>]],dtype=tf.float32)</span><br><span class="line">y=tf.matmul(w1,tf.convert_to_tensor([[<span class="number">9</span>],[<span class="number">10</span>]],dtype=tf.float32))</span><br><span class="line">grads=tf.gradients(y,[w1])</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  print(<span class="string">"梯度为："</span>,sess.run(grads))</span><br><span class="line"></span><br><span class="line"> <span class="comment">#梯度为： [array([[ 9., 10.]], dtype=float32)]</span></span><br></pre></td></tr></table></figure><p>上面例子中，由于y是由w1与[[9],[10]]相乘而来，所以导数就是[[9],[10]]，也就是斜率</p><h2 id="求多变量偏导"><a href="#求多变量偏导" class="headerlink" title="求多变量偏导"></a>求多变量偏导</h2><p>这就需要用到tf.gradients的第三个参数，grad_ys。grad_ys也是一个list，其长度等于len(ys)。这个参数的意义在于对第一个参数中的每个元素的求导加权重</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"><span class="comment">#随机生成一个形状为2的变量</span></span><br><span class="line">w1 = tf.get_variable(<span class="string">'w1'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w2 = tf.get_variable(<span class="string">'w2'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">w3 = tf.get_variable(<span class="string">'w3'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w4 = tf.get_variable(<span class="string">'w4'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">y1 = w1 + w2+ w3</span><br><span class="line">y2 = w3 + w4</span><br><span class="line"><span class="comment">#不考虑参数grad_ys</span></span><br><span class="line">gradients= tf.gradients([y1, y2], [w1, w2, w3, w4])</span><br><span class="line"><span class="comment">#考虑参数grad_ys</span></span><br><span class="line">gradients1 = tf.gradients([y1, y2], [w1, w2, w3, w4], grad_ys=[tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>]),</span><br><span class="line">                                                          tf.convert_to_tensor([<span class="number">3.</span>,<span class="number">4.</span>])])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(w1))</span><br><span class="line">    print(sess.run(gradients1))</span><br><span class="line">    print(sess.run(gradients))</span><br></pre></td></tr></table></figure><h2 id="梯度停止"><a href="#梯度停止" class="headerlink" title="梯度停止"></a>梯度停止</h2><p>对于反向传播过程中某种特殊情况需要停止梯度运算时，在tensorflow中提供了一个tf.stop_gradient函数，被它定义过的节点将没有梯度运算功能</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">w1 = tf.get_variable(<span class="string">'w1'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w2 = tf.get_variable(<span class="string">'w2'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">w3 = tf.get_variable(<span class="string">'w3'</span>, shape=[<span class="number">2</span>])</span><br><span class="line">w4 = tf.get_variable(<span class="string">'w4'</span>, shape=[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">y1 = w1 + w2+ w3</span><br><span class="line">y2 = w3 + w4</span><br><span class="line"></span><br><span class="line">a = w1+w2</span><br><span class="line">a_stoped = tf.stop_gradient(a)</span><br><span class="line">y3= a_stoped+w3</span><br><span class="line"></span><br><span class="line">gradients = tf.gradients([y1, y2], [w1, w2, w3, w4], grad_ys=[tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>]),</span><br><span class="line">                                                          tf.convert_to_tensor([<span class="number">3.</span>,<span class="number">4.</span>])])                                                      </span><br><span class="line">gradients2 = tf.gradients(y3, [w1, w2, w3], grad_ys=tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>]))                                                          </span><br><span class="line">print(gradients2) </span><br><span class="line"> </span><br><span class="line">gradients3 = tf.gradients(y3, [w3], grad_ys=tf.convert_to_tensor([<span class="number">1.</span>,<span class="number">2.</span>])) </span><br><span class="line">                                                       </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(gradients))</span><br><span class="line">    <span class="comment">#print(sess.run(gradients2))#报错，因为w1和w2梯度停止了</span></span><br><span class="line">    print(sess.run(gradients3))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在反向传播过程中，神经网络需要对每一个loss对应的学习参数求偏导，算出的这个值叫做梯度，用来乘以学习率然后更新学习参数使用的&lt;/p&gt;
&lt;h2 id=&quot;求单变量偏导&quot;&gt;&lt;a href=&quot;#求单变量偏导&quot; class=&quot;headerlink&quot; title=&quot;求单变量偏导&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>反卷积和反池化</title>
    <link href="http://yoursite.com/2020/01/11/%E5%8F%8D%E5%8D%B7%E7%A7%AF%E5%92%8C%E5%8F%8D%E6%B1%A0%E5%8C%96/"/>
    <id>http://yoursite.com/2020/01/11/反卷积和反池化/</id>
    <published>2020-01-11T09:13:49.000Z</published>
    <updated>2020-01-15T07:02:58.500Z</updated>
    
    <content type="html"><![CDATA[<h2 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h2><p>反卷积是指通过测量输出已知输入重构未知输入的过程。在神经网络中，反卷积过程并不具备学习的能力，仅仅是用于可视化一个已经训练好的卷积网络模型，没有学习训练的过程。如下图：即为VGG16反卷积神经网络的结构，展示了一个卷积网络与反卷积网络结合的过程。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111184504.png" alt=""></p><p>反卷积就是将中间的数据，按照前面卷积、池化等过程，完全相反地做一遍，从而得到类似原始输入的数据。</p><h3 id="反卷积原理"><a href="#反卷积原理" class="headerlink" title="反卷积原理"></a>反卷积原理</h3><p>反卷积可以理解为卷积操作的逆操作。<strong>千万不要将反卷积操作可以复原卷积操作的输入值，</strong>反卷积并没有这个功能，它仅仅是将卷积变换过程中的步骤反向变换一次。通过将卷积核转置，与卷积后的结果再做一遍卷积，所以反卷积还有个名字叫做转置卷积。</p><p>反卷积操作：</p><p>（1） 首先是将卷积核反转（ 并不是转置，而是上下左右方向进行递序操作）。也就是对卷积核做180<sup>o</sup>翻转。<br>（2） 再将卷积结果作为输入， 做补0的扩充操作， 即往每一个元素后面补0。 这一步是根据步长来的， 对每一个元素沿着步长的方向补（ 步长-1） 个0。 例如， 步长为1就不用补0了。<br>（3） 在扩充后的输入基础上再对整体补0。以原始输入的shape作为输出， 按照前面介绍的卷积padding规则， 计算pading的补0位置及个数， 得到的补0位置要上下和左右各自颠倒一下。<br>（4） 将补0后的卷积结果作为真正的输入，反转后的卷积核为filter， 进行步长为1的卷积操作。  </p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111193249.png" alt=""></p><p>需要注意的是，通过反卷积并不能还原卷积之前的矩阵，只能从大小上进行还原，反卷积的本质还是卷积，只是在进行卷积之前，会进行一个自动的padding补0，从而使得输出的矩阵与指定输出矩阵的shape相同。框架本身，会根据我们自己设定的反卷积值来计算输入矩阵的尺寸，如果shape不符合，会出现报错。</p><h3 id="反卷积函数"><a href="#反卷积函数" class="headerlink" title="反卷积函数"></a>反卷积函数</h3><p>在Tensorflow中，反卷积是通过函数tf.nn.conv2d_transpose来实现的。</p><p>conv2d_transpose(value,filter,output_shape,strides,padding=”SAME”,data_format=”NHWC”,name=None)：</p><p>value：代表卷积操作之后的张量，需要进行反卷积的矩阵</p><p>filter：代表卷积核，参数格式[height,width,output_channels,in_channels]</p><p>output_shape：设置反卷积输出矩阵的shape</p><p>strides：反卷积步长</p><p>padding：补0方式，SAME和VALID方式</p><p>data_format：string类型的量，’NHWC’和’NCHW’其中之一，这是tensorflow新版本中新加的参数，它说明了value参数的数据格式。’NHWC’指tensorflow标准的数据格式[batch, height, width, in_channels]，‘NCHW’指Theano的数据格式,[batch, in_channels，height, width]，默认值是’NHWC’。</p><p>name：操作名称</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"></span><br><span class="line">img = tf.Variable(tf.constant(<span class="number">1.0</span>,shape = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>])) </span><br><span class="line"></span><br><span class="line">filter =  tf.Variable(tf.constant([<span class="number">1.0</span>,<span class="number">0</span>,<span class="number">-1</span>,<span class="number">-2</span>],shape = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">conv = tf.nn.conv2d(img, filter, strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>)  </span><br><span class="line">cons = tf.nn.conv2d(img, filter, strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">print(conv.shape)</span><br><span class="line">print(cons.shape)</span><br><span class="line"> </span><br><span class="line">contv= tf.nn.conv2d_transpose(conv, filter, [<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>],strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'VALID'</span>)</span><br><span class="line">conts = tf.nn.conv2d_transpose(cons, filter, [<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>],strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:  </span><br><span class="line">    sess.run(tf.global_variables_initializer() )  </span><br><span class="line">    print(<span class="string">"img"</span>,sess.run(img))</span><br><span class="line">    print(<span class="string">"conv:\n"</span>,sess.run([conv,filter])) </span><br><span class="line">    print(<span class="string">"cons:\n"</span>,sess.run([cons]))    </span><br><span class="line">    print(<span class="string">"contv:\n"</span>,sess.run([contv])) </span><br><span class="line">    print(<span class="string">"conts:\n"</span>,sess.run([conts]))</span><br></pre></td></tr></table></figure><h3 id="反卷积应用场景"><a href="#反卷积应用场景" class="headerlink" title="反卷积应用场景"></a>反卷积应用场景</h3><p>由于反卷积的特性，可以用于信道均衡、图像恢复等问题。而在神经网络的研究中， 反卷积更多的是充当可视化的作用。 对于一个复杂的深度卷积网络，通过每层若干个卷积核的变换， 我们无法知道每个卷积核关注的是什么， 变换后的特征是什么样子。 通过反卷积的还原， 可以对这些问题有个清晰的可视化， 以各层得到的特征图作为输入， 进行反卷积， 得到反卷积结果， 用以验证显示各层提取到的特征图。  </p><h2 id="反池化"><a href="#反池化" class="headerlink" title="反池化"></a>反池化</h2><p>反池化属于池化的逆操作，是无法通过池化的结果还原出全部的原始数据。因为池化的过程就是只保留主要信息，舍去部分信息。如想从池化后的这些主要信息恢复出全部信息，则存在信息缺失，这时只能通过补位来实现最大程度的信息完整</p><h3 id="反池化原理"><a href="#反池化原理" class="headerlink" title="反池化原理"></a>反池化原理</h3><p>池化有两种最大池化和平均池化，反池化与其对应。</p><p>反平均池化比较简单。首先还原成原来的大小，然后将池化结果中的每个值都填入其对应于原始数据区域中的相应未知即可。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200112123007.png" alt=""></p><p>反最大池画要求在池化过程中记录最大激活值的坐标位置，然后在反池化时，只把池化过程中最大激活值所在位置坐标的值激活，其它的值置为0。这个过程只是一种近似，因为在池化过程中，除了最大值所在的位置，其它的值是不为0的</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200112123548.png" alt=""></p><h3 id="反池化操作"><a href="#反池化操作" class="headerlink" title="反池化操作"></a>反池化操作</h3><p>Tensorflow中没有反池化操作的函数。对于最大池化，也不支持输出最大激活值的位置，但是同样有个池化的反向传播函数tf.nn.max_pool_with_argmax。该函数可以输出位置，需要我们自己封装一个反池化函数。</p><p>首先重新定义最大池化函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_with_argmax</span><span class="params">(net, stride)</span>:</span></span><br><span class="line">    _, mask = tf.nn.max_pool_with_argmax( net,ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    mask = tf.stop_gradient(mask)</span><br><span class="line">    net = tf.nn.max_pool(net, ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) </span><br><span class="line">    <span class="keyword">return</span> net, mask</span><br></pre></td></tr></table></figure><p>在上面代码里，先调用tf.nn.max_pool_with_argmax函数获得每个最大值的位置mask，再将反向传播的mask梯度停止，接着再用tf.nn.max_pool函数计算最大池化操作，然后将mask和池化结果一起返回。</p><p><strong>注意</strong>：tf.nn.max_pool_with_argmax的方法只支持GPU操作，不能在cpu机器上使用。</p><p>接下来定义一个数组，并使用最大池化函数对其进行池化操作，比较一下tensorflow自带的tf.nn.max_pool函数是否一样，看看输出的mask</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">img=tf.constant([  </span><br><span class="line">        [[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>]],  </span><br><span class="line">        [[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>]],  </span><br><span class="line">        [[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>]],  </span><br><span class="line">        [[<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>], [<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>]]</span><br><span class="line">    ]) </span><br><span class="line">img=tf.reshape(img,[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line">pooling=tf.nn.max_pool(img,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">encode,mask=max_pool_with_argmax(img,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"image:"</span>,sess.run(img))</span><br><span class="line">  print(<span class="string">"pooling:"</span>,sess.run(pooling))</span><br><span class="line">  print(<span class="string">"encode"</span>,sess.run([encode,mask]))</span><br></pre></td></tr></table></figure><p>从输出结果可以看到，定义的最大池化与原来的版本输出是一样的。mask的值是将整个数据flat(扁平化)后的索引，但却保持与池化结果一致的shape。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpool</span><span class="params">(net, mask, stride)</span>:</span></span><br><span class="line"></span><br><span class="line">    ksize = [<span class="number">1</span>, stride, stride, <span class="number">1</span>]</span><br><span class="line">    input_shape = net.get_shape().as_list()</span><br><span class="line">    <span class="comment">#计算new shape</span></span><br><span class="line">    output_shape = (input_shape[<span class="number">0</span>], input_shape[<span class="number">1</span>] * ksize[<span class="number">1</span>], input_shape[<span class="number">2</span>] * ksize[<span class="number">2</span>], input_shape[<span class="number">3</span>])</span><br><span class="line">    <span class="comment">#计算索引</span></span><br><span class="line">    one_like_mask = tf.ones_like(mask)</span><br><span class="line">    batch_range = tf.reshape(tf.range(output_shape[<span class="number">0</span>], dtype=tf.int64), shape=[input_shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    b = one_like_mask * batch_range</span><br><span class="line">    y = mask // (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>])</span><br><span class="line">    x = mask % (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>]) // output_shape[<span class="number">3</span>]</span><br><span class="line">    feature_range = tf.range(output_shape[<span class="number">3</span>], dtype=tf.int64)</span><br><span class="line">    f = one_like_mask * feature_range</span><br><span class="line">    <span class="comment">#转置索引</span></span><br><span class="line">    updates_size = tf.size(net)</span><br><span class="line">    indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [<span class="number">4</span>, updates_size]))</span><br><span class="line">    values = tf.reshape(net, [updates_size])</span><br><span class="line">    ret = tf.scatter_nd(indices, values, output_shape)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure><p>上面代码的思路是找到mask对应的索引，将max的值填到指定地方。接着直接调用上面代码的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img2=unpool(encode,mask,<span class="number">2</span>)</span><br><span class="line"> <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">   result=sess.run(img2)  </span><br><span class="line">   <span class="keyword">print</span> (<span class="string">"reslut:\n"</span>,result)</span><br></pre></td></tr></table></figure><p>反最大池化整体代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_with_argmax</span><span class="params">(net, stride)</span>:</span></span><br><span class="line">    _, mask = tf.nn.max_pool_with_argmax( net,ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line">    mask = tf.stop_gradient(mask)</span><br><span class="line">    net = tf.nn.max_pool(net, ksize=[<span class="number">1</span>, stride, stride, <span class="number">1</span>],strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) </span><br><span class="line">    <span class="keyword">return</span> net, mask</span><br><span class="line">img=tf.constant([  </span><br><span class="line">        [[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>],[<span class="number">0.0</span>,<span class="number">4.0</span>]],  </span><br><span class="line">        [[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>],[<span class="number">1.0</span>,<span class="number">5.0</span>]],  </span><br><span class="line">        [[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>],[<span class="number">2.0</span>,<span class="number">6.0</span>]],  </span><br><span class="line">        [[<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>], [<span class="number">3.0</span>,<span class="number">7.0</span>],[<span class="number">3.0</span>,<span class="number">7.0</span>]]</span><br><span class="line">    ]) </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpool</span><span class="params">(net, mask, stride)</span>:</span></span><br><span class="line"></span><br><span class="line">    ksize = [<span class="number">1</span>, stride, stride, <span class="number">1</span>]</span><br><span class="line">    input_shape = net.get_shape().as_list()</span><br><span class="line">    <span class="comment">#计算new shape</span></span><br><span class="line">    output_shape = (input_shape[<span class="number">0</span>], input_shape[<span class="number">1</span>] * ksize[<span class="number">1</span>], input_shape[<span class="number">2</span>] * ksize[<span class="number">2</span>], input_shape[<span class="number">3</span>])</span><br><span class="line">    <span class="comment">#计算索引</span></span><br><span class="line">    one_like_mask = tf.ones_like(mask)</span><br><span class="line">    batch_range = tf.reshape(tf.range(output_shape[<span class="number">0</span>], dtype=tf.int64), shape=[input_shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    b = one_like_mask * batch_range</span><br><span class="line">    y = mask // (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>])</span><br><span class="line">    x = mask % (output_shape[<span class="number">2</span>] * output_shape[<span class="number">3</span>]) // output_shape[<span class="number">3</span>]</span><br><span class="line">    feature_range = tf.range(output_shape[<span class="number">3</span>], dtype=tf.int64)</span><br><span class="line">    f = one_like_mask * feature_range</span><br><span class="line">    <span class="comment">#转置索引</span></span><br><span class="line">    updates_size = tf.size(net)</span><br><span class="line">    indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [<span class="number">4</span>, updates_size]))</span><br><span class="line">    values = tf.reshape(net, [updates_size])</span><br><span class="line">    ret = tf.scatter_nd(indices, values, output_shape)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line">img=tf.reshape(img,[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line">pooling=tf.nn.max_pool(img,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">"SAME"</span>)</span><br><span class="line">encode,mask=max_pool_with_argmax(img,<span class="number">2</span>)</span><br><span class="line">img2=unpool(encode,mask,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  print(<span class="string">"image:"</span>,sess.run(img))</span><br><span class="line">  print(<span class="string">"pooling:"</span>,sess.run(pooling))</span><br><span class="line">  print(<span class="string">"encode"</span>,sess.run([encode,mask]))</span><br><span class="line"></span><br><span class="line">  result,mask2=sess.run([encode, mask])  </span><br><span class="line">  <span class="keyword">print</span> (<span class="string">"encode:\n"</span>,result,mask2)</span><br><span class="line">  result=sess.run(img2)  </span><br><span class="line">  <span class="keyword">print</span> (<span class="string">"reslut:\n"</span>,result)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;反卷积&quot;&gt;&lt;a href=&quot;#反卷积&quot; class=&quot;headerlink&quot; title=&quot;反卷积&quot;&gt;&lt;/a&gt;反卷积&lt;/h2&gt;&lt;p&gt;反卷积是指通过测量输出已知输入重构未知输入的过程。在神经网络中，反卷积过程并不具备学习的能力，仅仅是用于可视化一个已经训练好的卷积网
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow中的队列</title>
    <link href="http://yoursite.com/2020/01/10/Tensorflow%E4%B8%AD%E7%9A%84%E9%98%9F%E5%88%97/"/>
    <id>http://yoursite.com/2020/01/10/Tensorflow中的队列/</id>
    <published>2020-01-10T10:43:32.000Z</published>
    <updated>2020-02-03T02:39:06.746Z</updated>
    
    <content type="html"><![CDATA[<p>Tensorflow提供了一个队列机制，通过多线程将读取数据与计算数据分开，因为在处理海量数据集的训练时，无法把数据集一次全部载入内存中，需要以便从硬盘中读取，一边训练计算。</p><h2 id="队列（queue）"><a href="#队列（queue）" class="headerlink" title="队列（queue）"></a>队列（queue）</h2><h3 id="启动线程"><a href="#启动线程" class="headerlink" title="启动线程"></a>启动线程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.start_queue_runners()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111144227.png" alt=""></p><p>那什么时候程序会进入挂起状态呢？</p><p>源于上面第四行代码，意思是我们要从队列中拿出指定批次的数据，但是队列里没有数据，所以程序会进入挂起状态</p><h3 id="在session内部的退出机制"><a href="#在session内部的退出机制" class="headerlink" title="在session内部的退出机制"></a>在session内部的退出机制</h3><p>如果把session部分改为with语法：</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111141238.png" alt=""></p><p>再次运行程序后，程序虽然能够正常运行，但是结束后会报错。原因是with语法的session是自动关闭的，  当运行结束后session自动关闭的同时会把里面所有的操作都关掉， 而此时的队列还在等待另一个进程往里写数据， 所以就会报错。   </p><p>解决方法：使用sess=tf.InteractiveSession()实现，或者像第一张图片一样创建</p><p><strong>tf.InteractiveSession()和tf.Session()的区别：</strong></p><p>使用InteractiveSession()来创建会话，我们要先构建Session()然后定义操作。如果使用Session来创建会话，我们需要在会话之前定义好全部的操作然后再构建会话。</p><p>上面的代码在单例程序中没什么问题， 资源会随着程序关闭而整体销毁。 但如果在复杂的代码中， 需要某个线程自动关闭， 而不是依赖进程的结束而销毁， 这种情况下需要使用tf.train.Coordinator函数来创建一个协调器， 以信号量的方式来协调线程间的关系， 完成线程间的同步。  </p><h2 id="协调器"><a href="#协调器" class="headerlink" title="协调器"></a>协调器</h2><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL19.png" alt=""></p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL20.png" alt=""></p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL@1.png" alt=""></p><p>下面这个例子是先建立一个100大小的队列，主线程使用计数器不停的加1，队列线程把主线程里的计数器放到队列中，当队列为空时，主线程会在sess.run(queue.dequeue())语句位置挂起。当队列线程写入队列中时，主线程的计数器同步开始工作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#创建一个长度为100的队列</span></span><br><span class="line">queue=tf.FIFOQueue(<span class="number">100</span>,<span class="string">"float"</span>)</span><br><span class="line">c=tf.Variable(<span class="number">0.0</span>)   <span class="comment">#计数器</span></span><br><span class="line"><span class="comment">#c+1.0</span></span><br><span class="line">op=tf.assign_add(c,tf.constant(<span class="number">1.0</span>))</span><br><span class="line"><span class="comment">#将计数器的结果加入队列</span></span><br><span class="line">enqueue_op=queue.enqueue(c)</span><br><span class="line"><span class="comment">#创建一个队列管理器queueRunner,用上面这两个操作向queue中添加元素。</span></span><br><span class="line">qr=tf.train.QueueRunner(queue,enqueue_ops=[op,enqueue_op])</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  coord=tf.train.Coordinator()</span><br><span class="line">  <span class="comment">#启动入队进程</span></span><br><span class="line">  enqueue_threads=qr.create_threads(sess,coord=coord,start=<span class="literal">True</span>)</span><br><span class="line">  <span class="comment">#主线程</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>):</span><br><span class="line">    print(sess.run(queue.dequeue()))</span><br><span class="line">  <span class="comment">#通知其它线程关闭，其它所有线程关闭后，这一函数才返回</span></span><br><span class="line">  coord.request_stop()</span><br></pre></td></tr></table></figure><p>还可以使用coord.join(enqueue_threads)指定等待某个进程结束</p><p>为session中的队列加上协调器，只需要将上例的coord放到启动队列中。</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20200111163544.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Tensorflow提供了一个队列机制，通过多线程将读取数据与计算数据分开，因为在处理海量数据集的训练时，无法把数据集一次全部载入内存中，需要以便从硬盘中读取，一边训练计算。&lt;/p&gt;
&lt;h2 id=&quot;队列（queue）&quot;&gt;&lt;a href=&quot;#队列（queue）&quot; class
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>CNN的相关函数</title>
    <link href="http://yoursite.com/2019/11/29/CNN%E7%9A%84%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2019/11/29/CNN的相关函数/</id>
    <published>2019-11-29T12:22:09.000Z</published>
    <updated>2020-01-10T07:25:13.122Z</updated>
    
    <content type="html"><![CDATA[<h2 id="卷积函数"><a href="#卷积函数" class="headerlink" title="卷积函数"></a>卷积函数</h2><p>tf.nn.conv2d(input,filter,strides,padding,use_cudnn_on_gpu=None,name=None)</p><p>除去用以指定该操作名字的name参数，与方法有关的共有5个参数。如下:</p><p>input： 指需要做卷积的输入图像， 它要求是一个Tensor， 具有[batch， in_height， in_width，in_channels]这样的形状（shape） ， 具体含义是“训练时一个batch的图片数量， 图片高度， 图片宽度， 图像通道数” ， 注意这是一个四维的<br>Tensor， 要求类型为float32和float64其中之一。</p><p>filter： 相当于CNN中的卷积核， 它要求是一个Tensor， 具有[filter_height， filter_width，in_channels， out_channels]这样的shape， 具体含义是“卷积核的高度， 滤波器的宽度， 图像通道数， 滤波器个数” ， 要求类型与参数input相同。有一个地方需要注意， 第三维in_channels， 就是参数input的第四维。</p><p>strides： 卷积时在图像每一维的步长， 这是一个一维的向量， 长度为4。</p><p>padding： 定义元素边框与元素内容之间的空间。 string类型的量， 只能是SAME和VALID其中之一， 这个值决定了不同的卷积方式， padding的值为’VALID’时， 表示边缘不填充， 当其为’SAME’时， 表示填充到滤波器可以到达图像边缘。</p><p>use_cudnn_on_gpu： bool类型， 是否使用cudnn加速， 默认为true。  </p><h2 id="池化函数"><a href="#池化函数" class="headerlink" title="池化函数"></a>池化函数</h2><p>tf.nn.max_pool(input,ksize,strides,padding,name=None)</p><p>tf.nn.avg_pool(input,ksize,strides,padding,name=None)</p><p>上面这两个函数中的四个参数和卷积参数类似，如下：</p><p>input：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch,height,width,channels]这样的shape。</p><p>ksize：池化窗口的大小，取一个四维向量，一般是[1,height,width,1]，我们不想在batch和channels上做池化，所以这两个维度设为1</p><p>strides：步长，一般也是[1,strides,strides,1]</p><p>padding：和卷积一样，VALID是不进行padding操作，SAME是padding操作</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;卷积函数&quot;&gt;&lt;a href=&quot;#卷积函数&quot; class=&quot;headerlink&quot; title=&quot;卷积函数&quot;&gt;&lt;/a&gt;卷积函数&lt;/h2&gt;&lt;p&gt;tf.nn.conv2d(input,filter,strides,padding,use_cudnn_on_gpu=Non
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow中如何预防过拟合</title>
    <link href="http://yoursite.com/2019/11/26/tensorflow%E4%B8%AD%E5%A6%82%E4%BD%95%E9%A2%84%E9%98%B2%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    <id>http://yoursite.com/2019/11/26/tensorflow中如何预防过拟合/</id>
    <published>2019-11-26T14:26:29.000Z</published>
    <updated>2020-04-29T03:13:39.901Z</updated>
    
    <content type="html"><![CDATA[<h2 id="方法概述"><a href="#方法概述" class="headerlink" title="方法概述"></a>方法概述</h2><p>避免过拟合的方法有很多，常用的方法有early stopping、数据集扩增、正则化、dropout。下面就概述一下，具体请参照优化算法(1)</p><p>early stoping：在发生过拟合之前提前结束。理论上是可以的，但是这个点不好把握。</p><p>数据集扩增：就是让模型见到更多的情况，可以最大化地满足全样本，但实际应用中对于未来事件的预测不理想。</p><p>正则化：通过映入范数，增强模型的泛化能力。包括L1、L2.</p><p>dropout：是网络模型中的一种方法。每次训练时舍去一些节点来增强泛化能力。</p><p>下面我们来具体看看如何实现后两种方法。</p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>所谓的正则化， 其实就是在神经网络计算损失值的过程中， 在损失后面再加一项。 这样损失值所代表的输出与标准结果间的误差就会受到干扰， 导致学习参数w和b无法按照目标方向来调整， 实现模型无法与样本完全拟合的结果， 从而达到防止过拟合的效果  </p><p>这个干扰项一定要有下面这样的特性：</p><p>1、当欠拟合时，希望它对模型误差的影响越小越好，以便让模型快速拟合实际</p><p>2、当过拟合时，希望他对模型误差的影响越大越好，以便让模型不要产生过拟合的情况。</p><p>由上面两个特性，引入两个范数：L1和L2</p><p>L1：所有学习参数w的绝对值的和。</p><p>L2：所有学习参数w的平方和然后求平方根</p><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191127210328.png" alt=""></p><p>上图中的第一个式子是L1范式，另一个就是L2范式。loss为等式左边的结果，less(0)代表真实的loss值，less(0)后面的那一项就代表正则化，&lambda;为一个可以调整的参数，用来控制正则化对loss的影响。对于L2，将其乘以1/2是为了反向传播时对其求导可以将数据规整。</p><h3 id="tensorflow中的正则化"><a href="#tensorflow中的正则化" class="headerlink" title="tensorflow中的正则化"></a>tensorflow中的正则化</h3><p>L1正则化：tf.contrib.layers.l1_regularizer(lambda)(w)：lambda是正则化参数</p><p>L2正则化：tf.contrib.layers.l2_regularizer(lambda)(w)：lambda是正则化参数</p><p>但是对于高版本的tensorflow的contrib不稳定，从而在高级一点的版本中删除了contrib这个库。如果想使用L2正则化就得用下面的办法：</p><p>L2的正则化函数为：tf.nn.l2_loss(t,name=None)</p><p>L1的正则化函数在tensorflow是没有自己组装的，可以自己写：tf.reduce_sum(tf.abs(w))</p><h3 id="通过正则化改善过拟合"><a href="#通过正则化改善过拟合" class="headerlink" title="通过正则化改善过拟合"></a>通过正则化改善过拟合</h3><h4 id="使用contrib里的方法："><a href="#使用contrib里的方法：" class="headerlink" title="使用contrib里的方法："></a>使用contrib里的方法：</h4><p>tf.add_to_collection(‘list1’,var)：将变量加入到列表list1中。</p><p> tf.get_collection(‘list1’)：获得列表list1里面的所有变量。</p><p> tf.add_n(list1)：将列表list1中所有的变量加起来并返回。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.add_to_collection(<span class="string">'losses'</span>, tf.constant(<span class="number">2.2</span>))</span><br><span class="line">tf.add_to_collection(<span class="string">'losses'</span>, tf.constant(<span class="number">3.</span>))</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(tf.get_collection(<span class="string">'losses'</span>)))   </span><br><span class="line">    print(sess.run(tf.add_n(tf.get_collection(<span class="string">'losses'</span>))))</span><br><span class="line"><span class="comment">#[2.2, 3.0]</span></span><br><span class="line"><span class="comment">#5.2</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape , lambda=<span class="number">0.0001</span>)</span>:</span></span><br><span class="line">    var = tf.Variable(tf.random_normal( shape ), dtype = tf.float32)</span><br><span class="line">    tf.add_to_collection(<span class="string">'losses'</span>, tf.contrib.layers.l2_regularizer(<span class="keyword">lambda</span>)(var))</span><br><span class="line">    <span class="keyword">return</span> var</span><br><span class="line"></span><br><span class="line">mse_loss = tf.reduce_mean( tf.square(y_ - y))</span><br><span class="line">tf.add_to_collection(<span class="string">'losses'</span>, mse_loss)</span><br><span class="line">loss = tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br></pre></td></tr></table></figure><h4 id="使用nn里的方法："><a href="#使用nn里的方法：" class="headerlink" title="使用nn里的方法："></a>使用nn里的方法：</h4><p>使用正则化非常简单，只需要在计算损失值时加上loss的正则化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reg=<span class="number">0.01</span></span><br><span class="line">loss=tf.reduce_mean((y_pred-y)**<span class="number">2</span>)+tf.nn.l2_loss(weights[<span class="string">'h1'</span>])*reg+tf.nn.l2_loss(weight[<span class="string">'h2'</span>])*reg</span><br></pre></td></tr></table></figure><h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><p>还有一种防止过拟合的方法是dropout。这个方法的做法是：在训练过程中，每次随机选择一部分节点不要去“学习”</p><p>因为从样本数据的分析来看，数据本身是不可能很纯净的，也就是任何一个模型不能100%把数据完全分开，在某一类中一定会有一些异常数据，过拟合的问题恰恰是把这些异常数据当初规律来学习了。我们希望把异常数据过滤掉，只关心有用的规律数据。</p><p>异常数据的特点是，它与主流样本中的规律都不同，但是量非常少，相当于在一个样本中出现的概率比主流数据出现的概率低很多。我们可以利用这一点，通过在每次模型中忽略一些节点的数据学习，将小概率的异常数据获得学习的机会降低，这样这些异常数据对模型的影响就会更小了。</p><p><strong>注意</strong>：由于dropout让一部分节点不去“学习”，所以在增加模型的泛化能力的同时，会使学习速度降低，使模型不太容易学成。所以在使用的过程中需要合理地调节到底丢弃多少节点，并不是丢弃的节点越多越好。</p><h2 id="tensorflow中的dropout"><a href="#tensorflow中的dropout" class="headerlink" title="tensorflow中的dropout"></a>tensorflow中的dropout</h2><p>tf.nn.dropout(x,keep_prob,noise_shape=None,seed=None,name=None)</p><p>x： 输入的模型节点。<br>keep_prob： 保持率。 如果为1， 则代表全部进行学习； 如果为0.8， 则代表丢弃20%的节点， 只让80%的节点参与学习。<br>noise_shape： 代表指定x中， 哪些维度可以使用dropout技术。 为None时， 表示所有维度都使用dropout技术。 也可以将某个维度标志为1， 来代表该维度使用dropout技术。 例如： x的形状为[n， len， w， ch]， 使用noise_shape为[n， 1， 1，ch]， 这表明会对x中的第二维度len和第三维度w进行dropout。<br>seed： 随机选取节点的过程中随机数的种子值。</p><h2 id="全连接网络的深浅关系"><a href="#全连接网络的深浅关系" class="headerlink" title="全连接网络的深浅关系"></a>全连接网络的深浅关系</h2><p>在实际中，如果想使用浅层神经网络拟合复杂非线性函数，就需要靠增加的神经元个数来实现。神经元过多意味着需要训练的参数过多，这会增加网络的学习难度，并影响网络的泛化能力。因此，在增加网络结构时，一般倾向于使用更多的模型，来减少网络中所需要神经元的数量，使网络有更好的泛化能力。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;方法概述&quot;&gt;&lt;a href=&quot;#方法概述&quot; class=&quot;headerlink&quot; title=&quot;方法概述&quot;&gt;&lt;/a&gt;方法概述&lt;/h2&gt;&lt;p&gt;避免过拟合的方法有很多，常用的方法有early stopping、数据集扩增、正则化、dropout。下面就概述一下，具体请
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="框架" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/"/>
    
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
</feed>
