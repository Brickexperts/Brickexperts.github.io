<!DOCTYPE html>





<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="generator" content="Hexo 4.0.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    search: {
      root: '/',
      path: 'search.xml'
    },
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="torch.nn包里的Functional包含convolution函数，pooling函数，非线性函数、激活函数等函数，torch.nn.optim包含各种优化算法，Momentum、RMSProp等。 Tensortorch.Tensor是一种包含单一数据类型元素的多维矩阵。 Torch定义了七种CPU tensor类型和八种 tensor类型：  torch.Tensor是默认的tensor">
<meta name="keywords" content="框架">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch(1)">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;10&#x2F;22&#x2F;pytorch-1&#x2F;index.html">
<meta property="og:site_name" content="DY的个人博客">
<meta property="og:description" content="torch.nn包里的Functional包含convolution函数，pooling函数，非线性函数、激活函数等函数，torch.nn.optim包含各种优化算法，Momentum、RMSProp等。 Tensortorch.Tensor是一种包含单一数据类型元素的多维矩阵。 Torch定义了七种CPU tensor类型和八种 tensor类型：  torch.Tensor是默认的tensor">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191022221728.png">
<meta property="og:updated_time" content="2019-11-20T13:24:39.796Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191022221728.png">
  <link rel="alternate" href="/atom.xml" title="DY的个人博客" type="application/atom+xml">
  <link rel="canonical" href="http://yoursite.com/2019/10/22/pytorch-1/">


<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>pytorch(1) | DY的个人博客</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DY的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
    <ul id="menu" class="menu">
        
        
        
          
          <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        <li class="menu-item menu-item-search">
          <a href="javascript:;" target="_blank" rel="noopener" class="popup-trigger">
          
            <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>


    </div>
</nav>

</div>
    </header>

    

  <a href="https://github.com/Brickexperts" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/22/pytorch-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="湛蓝星空">
      <meta itemprop="description" content="这个人贼菜">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DY的个人博客">
    </span>
      <header class="post-header">

        
          <h1 class="post-title" itemprop="name headline">pytorch(1)

              
            
          </h1>
        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-22 17:23:19" itemprop="dateCreated datePublished" datetime="2019-10-22T17:23:19+08:00">2019-10-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-11-20 21:24:39" itemprop="dateModified" datetime="2019-11-20T21:24:39+08:00">2019-11-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">框架</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a></span>

                
                
              
            </span>
          

          <br>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>torch.nn包里的Functional包含convolution函数，pooling函数，非线性函数、激活函数等函数，torch.nn.optim包含各种优化算法，Momentum、RMSProp等。</p>
<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>torch.Tensor是一种包含单一数据类型元素的多维矩阵。</p>
<p>Torch定义了七种CPU tensor类型和八种 tensor类型：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191022221728.png" alt=""></p>
<p>torch.Tensor是默认的tensor类型（torch.FloatTensor）的简称。</p>
<p>一个张量tensor可以从Python的list或序列构建：</p>
<blockquote>
<p>>&gt;&gt;torch.FloatTensor([[1,2,3],[4,5,6]])<br>tensor([[1., 2., 3.],<br>       [4., 5., 6.]])</p>
<p>>&gt;&gt;torch.Tensor([[3,2,1],[6,5,4]])<br>tensor([[3., 2., 1.],<br>[6., 5., 4.]])</p>
</blockquote>
<p>空张量tensor可以通过规定其大小来构建：</p>
<blockquote>
<p>>&gt;&gt;torch.IntTensor(2,4).zero_()<br>tensor([[0, 0, 0, 0],<br>        [0, 0, 0, 0]], dtype=torch.int32)</p>
</blockquote>
<p>可以用python的索引和切片来获取和修改一个张量tensor中的内容：</p>
<blockquote>
<p>>&gt;&gt;x=torch.FloatTensor([[1,2,3],[4,5,6]])<br>>&gt;&gt;print(x[1][2])<br>tensor(6.)<br>>&gt;&gt;print(x[0][1])<br>tensor(2.)<br>>&gt;&gt;x[0][1]=8<br>>&gt;&gt;print(x)<br>tensor([[1., 8., 3.],<br>        [4., 5., 6.]])</p>
</blockquote>
<p>每一个张量tensor都有一个相应的tourch.Storage用来保存其数据。</p>
<p><strong>注意：会改变tensor的函数操作会用一个下划线后缀来表示。</strong>比如，torch.FloatTensor.abs_()会在原地计算绝对值，并返回改变后的tensor，而torch.FloatTensor.abs()将会在一个新的tensor中计算结果。</p>
<p>创建张量时有个参数是requires_grad，如果设置 requires_grad为 True，那么将会追踪所有对于该张量的操作吗，默认False。 当完成计算后通过调用 .backward()，自动计算所有的梯度， 这个张量的所有梯度将会自动积累到 .grad属性。 </p>
<h2 id="torch-squeeze"><a href="#torch-squeeze" class="headerlink" title="torch.squeeze"></a>torch.squeeze</h2><p>torch.squeeze(input,dim=None,out=None)：将输入张量形状中的1去除并返回。当给定dim时，那么挤压操作只在给定维度上。</p>
<blockquote>
<p>>&gt;&gt;x=torch.zeros(2,1)<br>>&gt;&gt;x<br>tensor([[0.],<br>        [0.]])<br>>&gt;&gt;y=torch.squeeze(x)<br>>&gt;&gt;y<br>tensor([0., 0.])</p>
</blockquote>
<h2 id="torch-abs"><a href="#torch-abs" class="headerlink" title="torch.abs"></a>torch.abs</h2><p>torch.abs(input,out=None)：计算输入张量的每个元素的绝对值</p>
<blockquote>
<p>>&gt;&gt;torch.abs(torch.Tensor([-1,-2,-3]),out=z)<br>tensor([1., 2., 3.])<br>>&gt;&gt;z<br>tensor([1., 2., 3.])</p>
</blockquote>
<h2 id="torch-add"><a href="#torch-add" class="headerlink" title="torch.add"></a>torch.add</h2><p>torch.add(input,value,out=None)，对输入张量input逐元素加上标量值value，并返回结果得到一个新的张量out。</p>
<blockquote>
<p>>&gt;&gt;a=torch.rand(4)<br>>&gt;&gt;a<br>tensor([0.0694, 0.6366, 0.6938, 0.8872])<br>>&gt;&gt;torch.add(a,20)<br>tensor([20.0694, 20.6366, 20.6938, 20.8872])</p>
</blockquote>
<h2 id="torch-mean"><a href="#torch-mean" class="headerlink" title="torch.mean"></a>torch.mean</h2><p>torch.mean(input,dim,out=None)：返回输入张量给定维度dim上每行的均值。0是列，1是行。</p>
<blockquote>
<p>>&gt;&gt;a=torch.rand(4,4)<br>>&gt;&gt;a<br>tensor([[0.7413, 0.5828, 0.0070, 0.0146],<br>        [0.1668, 0.6566, 0.1865, 0.0700],<br>        [0.7603, 0.8017, 0.3065, 0.8772],<br>        [0.7918, 0.8798, 0.7355, 0.1142]])<br>>&gt;&gt;torch.mean(a,1)<br>tensor([0.3364, 0.2700, 0.6864, 0.6303])</p>
</blockquote>
<h2 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h2><h3 id="torch-eq"><a href="#torch-eq" class="headerlink" title="torch.eq"></a>torch.eq</h3><p>torch.eq(input,other,out=None)：比较元素相等性。第二个参数可以为一个数或与第一个参数同类型形状的张量。</p>
<blockquote>
<p>>&gt;&gt;torch.eq(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))<br>tensor([[ True, False],<br>        [False,  True]])</p>
</blockquote>
<p>如果两个张量有相同的形状和元素值，则返回True，否则返回False。</p>
<blockquote>
<p>>&gt;&gt;torch.equal(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))<br>False</p>
<p>>&gt;&gt;torch.equal(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,2],[3,4]]))<br>True</p>
</blockquote>
<h3 id="torch-ge"><a href="#torch-ge" class="headerlink" title="torch.ge"></a>torch.ge</h3><p>torch.ge(input,other,out=None)：逐元素比较input和other。即是否 input&gt;=otherinput&gt;=other。如果两个张量有相同的形状和元素值，则返回True。否则返回False。第二个参数可以为一个数或与第一个参数相同形状和类型的张量。</p>
<blockquote>
<p>>&gt;&gt;torch.ge(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))<br>tensor([[ True,  True],<br>        [False,  True]])</p>
</blockquote>
<h3 id="torch-gt"><a href="#torch-gt" class="headerlink" title="torch.gt"></a>torch.gt</h3><p>torch.gt(input,other,out=None)：逐元素比较input和other。即input&gt;otherinput&gt;other。如果两个张量有相同的形状和元素值，则返回True。否则返回False。第二个参数可以为一个数或与第一个参数相同形状和类型的张量。PS:这个和ge有什么区别？</p>
<blockquote>
<p>>&gt;&gt;torch.gt(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))<br>tensor([[False,  True],<br>        [False, False]])</p>
</blockquote>
<h3 id="torch-le"><a href="#torch-le" class="headerlink" title="torch.le"></a>torch.le</h3><p>torch.le(input, other, out=None)：逐元素比较input和other ， 即是否input&lt;=otherinput&lt;=other 第二个参数可以为一个数或与第一个参数相同形状和类型的张量</p>
<blockquote>
<p>>&gt;&gt;torch.le(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))<br>tensor([[ True, False],<br>        [ True,  True]])</p>
</blockquote>
<h3 id="torch-lt"><a href="#torch-lt" class="headerlink" title="torch.lt"></a>torch.lt</h3><p>torch.lt(input, other, out=None)：逐元素比较input和other ， 即是否 input&lt;otherinput&lt;other。第二个参数可以为一个数或与第一个参数相同形状和类型的张量</p>
<blockquote>
<p>>&gt;&gt;torch.lt(torch.Tensor([[1,2],[3,4]]),torch.Tensor([[1,1],[4,4]]))<br>tensor([[False, False],<br>        [ True, False]])</p>
</blockquote>
<h2 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h2><p>Variable和Tensor本质上没有区别，不过Variable会被放入一个计算图中，然后进行前向传播、反向传播、自动求导。</p>
<p>首先Variable是在torch.autograd.Variable中，要将tensor变成Variable，只需要Variable(a)就可以了。Variable有三个比较重要的组成属性：data、grad、grad_fn。data可以取出variable里面的tensor值，grad_fn表示的是得到这个Variable的操作(op)，grad是这个Variable的反向传播梯度。</p>
<blockquote>
<p>>&gt;&gt;from torch.autograd import Variable<br>>&gt;&gt;x=Variable(torch.Tensor([1]),requires_grad=True)<br>>&gt;&gt;w=Variable(torch.Tensor([2]),requires_grad=True)<br>>&gt;&gt;b=Variable(torch.Tensor([3]),requires_grad=True)<br>>&gt;&gt;y=w*x+b<br>>&gt;&gt;y<br>tensor([5.], grad_fn=<AddBackward0>)<br>>&gt;&gt;print(y.backward())<br>None<br>>&gt;&gt;print(x.grad)<br>tensor([2.])<br>>&gt;&gt;print(w.grad)<br>tensor([1.])<br>>&gt;&gt;print(b.grad)<br>tensor([1.])<br>>&gt;&gt;print(x.grad_fn)<br>None<br>>&gt;&gt;print(y.grad_fn)</p>
<AddBackward0 object at 0x000001C56569E2B0>

</blockquote>
<p>构建Variable，我们传入了一个参数requires_grad=True，这个参数表示是否对这个变量求梯度，默认的是False，也就是不对这个变量求梯度。</p>
<h2 id="parameters"><a href="#parameters" class="headerlink" title="parameters"></a>parameters</h2><p>paramerters(memo=None)：返回一个包含模型所有参数的迭代器。一般用来当作optimizer的参数。</p>
<h2 id="backward"><a href="#backward" class="headerlink" title="backward"></a>backward</h2><p>如果需要计算导数，可以在Tensor上调用.backward()。 如果Tensor是一个标量（即它包含一个元素数据）则不需要为backward()指定任何参数， 但是如果它有更多的元素，需要指定一个gradient参数来匹配张量的形状。 </p>
<h2 id="zero-grad"><a href="#zero-grad" class="headerlink" title="zero_grad"></a>zero_grad</h2><p>zero_grad()：清空所有被优化过的Variable的梯度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## view</span><br><span class="line"></span><br><span class="line"> 返回一个有相同数据但大小不同的tensor。 返回的tensor必须有与原tensor相同的数据和相同数目的元素，但可以有不同的大小。一个tensor必须是连续的`contiguous()`才能被查看。 </span><br><span class="line"></span><br><span class="line">&gt; \&gt;&gt;&gt;import torch</span><br><span class="line">&gt; \&gt;&gt;&gt;x=torch.randn(4,4)</span><br><span class="line">&gt; \&gt;&gt;&gt;x.size()</span><br><span class="line">&gt; torch.Size([4, 4])</span><br><span class="line">&gt; \&gt;&gt;&gt;y=x.view(16)</span><br><span class="line">&gt; \&gt;&gt;&gt;y.size()</span><br><span class="line">&gt; torch.Size([16])</span><br><span class="line">&gt; \&gt;&gt;&gt;z=x.view(-1,8)</span><br><span class="line">&gt; \&gt;&gt;&gt;z.size()</span><br><span class="line">&gt; torch.Size([2, 8])</span><br><span class="line"></span><br><span class="line">## zero_</span><br><span class="line"></span><br><span class="line">zero_(tensor)：用0填充一个tensor</span><br><span class="line"></span><br><span class="line">&gt; \&gt;&gt;&gt;torch.zero_(x)</span><br><span class="line">&gt; tensor([[0., 0., 0., 0.],</span><br><span class="line">&gt;         [0., 0., 0., 0.],</span><br><span class="line">&gt;         [0., 0., 0., 0.],</span><br><span class="line">&gt;         [0., 0., 0., 0.]])</span><br><span class="line"></span><br><span class="line">## 模型的保存和加载</span><br><span class="line"></span><br><span class="line">在pytorch里面使用torch.save来保存模型的结构和参数，有两种保存方式，当然加载模型有两种方式对应于保存模型的方式：</span><br><span class="line"></span><br><span class="line">（1）保存这个模型的结构信息和参数信息，保存的对象是模型model。加载完整的模型结构和参数信息，在网络较大的时候加载的时间比较长，同时存储空间也比较大。</span><br><span class="line"></span><br><span class="line">torch.save(the_model,path)</span><br><span class="line"></span><br><span class="line">the_model=torch.load(&quot;path&quot;)</span><br><span class="line"></span><br><span class="line">（2）保存模型的参数，保存的对象是模型的状态model.state_dict()。加载模型时加载的是参数信息。</span><br><span class="line"></span><br><span class="line">torch.save(the_model.state_dict(),path)</span><br><span class="line"></span><br><span class="line">the_model=TheModeClass(\*args,\**kwargs)</span><br><span class="line"></span><br><span class="line">the.model.load_state_dict(path)</span><br><span class="line"></span><br><span class="line">## 优化算法</span><br><span class="line"></span><br><span class="line">优化算法分两类：</span><br><span class="line"></span><br><span class="line">### 一阶优化算法</span><br><span class="line"></span><br><span class="line">这种算法使用各个参数的梯度值来更新参数，最常用的一阶优化算法是梯度下降。所谓的梯度就是导数的多变量表达式，同时也是一个方向，这个方向上方向导数最大，且等于梯度。梯度下降的功能是通过寻找最小值，控制方差，更新模型参数，最终使模型收敛。</span><br><span class="line"></span><br><span class="line">### 二阶优化算法</span><br><span class="line"></span><br><span class="line">二阶优化算法使用了二阶导数来最小化或最大化损失函数，主要基于牛顿法。但是由于二阶导数的计算成本很高，所以这种方法并没有广泛使用。torch.optim是一个实现各种优化算法的包，大多数常见的算法都能通过这个包调用。</span><br><span class="line"></span><br><span class="line">### torch.optim</span><br><span class="line"></span><br><span class="line">为了使用torch.optim，我们需要构建一个optimizer对象。这个对象能够保持当前参数状态并基于计算得到的梯度进行参数更新。</span><br><span class="line"></span><br><span class="line">#### 构建optimizer</span><br><span class="line"></span><br><span class="line">为了构建一个optimizer，我们需要给它一个包含了需要优化的参数（必须都是Variable对象）的iterable。然后，可以设置optimizer的参数选项，比如学习率，权重衰减，等等。 </span><br><span class="line"></span><br><span class="line">举个例子：</span><br><span class="line"></span><br><span class="line"> ```optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)</span><br></pre></td></tr></table></figure>
<h4 id="单独设置参数"><a href="#单独设置参数" class="headerlink" title="单独设置参数"></a>单独设置参数</h4><p>我们还可以为每个参数单独设置选项。Optimizer也支持为每个参数单独设置选项。若想这么做，不要直接传入Variable的iterable，而是传入dict的iterable。每一个dict都分别定 义了一组参数，并且包含一个param键，这个键对应参数的列表。其他的键应该optimizer所接受的其他参数的关键字相匹配，并且会被用于对这组参数的优化。</p>
<p>你仍然能够传递选项作为关键字参数。在未重写这些选项的组中，它们会被用作默认值。当你只想改动一个参数组的选项，但其他参数组的选项不变时，这是非常有用的。</p>
<p>例如，当我们想指定每一层的学习率时，这是非常有用的：</p>
<p> <code>optim.SGD([{&#39;params&#39;: model.base.parameters()}, {&#39;params&#39;: model.classifier.parameters(), &#39;lr&#39;:1e-3], lr=1e-2, momentum=0.9)</code></p>
<h4 id="单次优化"><a href="#单次优化" class="headerlink" title="单次优化"></a>单次优化</h4><p>使用optimizer.step()，这是大多数optimizer支持的版本，一旦梯度被如backward()之类的函数计算好后，我们就可以调用这个函数。</p>
<p><code>for input, target in dataset:</code> </p>
<p>​    optimizer.zero_grad()    </p>
<p>​    output = model(input)    </p>
<p>​    loss = loss_fn(output, target)   </p>
<p>​     loss.backward()   </p>
<p>​     optimizer.step()</p>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>我看到优化算法时，发现中文文档好像没有调整学习率的函数。补充一下。torch.optim.lr_scheduler提供了几种方法来根据epoches的数量调整学习速率。 两种机制：LambdaLR机制和StepLR机制；</p>
<h4 id="LambdaLR机制："><a href="#LambdaLR机制：" class="headerlink" title="LambdaLR机制："></a>LambdaLR机制：</h4><p>class torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda,last_epoch=-1)</p>
<p>将每一个参数组的学习率设置为初始学习率lr的某个函数倍.当last_epoch=-1时,设置初始学习率为lr.</p>
<p>参数:</p>
<p>​    optimizer(Optimizer对象)—优化器</p>
<p>​    lr_lambda(是一个函数,或者列表(list))— 当是一个函数时,需要给其一个整数参数,使其计算出一个乘数因子,用于调整学习率,通常该输入参数是epoch数目或者是一组上面的函数组成的列表,</p>
<p>​    last_epoch(int类型):最后一次epoch的索引,默认为-1.</p>
<h4 id="StepLR机制"><a href="#StepLR机制" class="headerlink" title="StepLR机制"></a>StepLR机制</h4><p>class torch.optim.lr_scheduler.StepLR(optimizer,step_size,gamma=0.1,last_epoch=-1)</p>
<p>设置每个参数组的学习率为 lr*&lambda;<sup>n</sup>, n=epoch/step_size。当last_epoch=-1时,令lr=lr</p>
<p>参数:</p>
<p>​    optimizer(Optimizer对象)—优化器</p>
<p>​     step_size(整数类型): 调整学习率的步长,每过step_size次,更新一次学习率</p>
<p>​    gamma(float 类型):学习率下降的乘数因子</p>
<p>​    last_epoch(int类型):最后一次epoch的索引,默认为-1.</p>
<h2 id="其它API"><a href="#其它API" class="headerlink" title="其它API"></a>其它API</h2><p>其它的API不想做搬运工了，上网址。<a href="https://www.pytorchtutorial.com/docs/" target="_blank" rel="noopener">pytorch中文文档</a></p>
<p>看文档我发现torch.nn包里面和nn.functional都有卷积等一些函数。其实nn.functional中的函数仅仅定义了一些具体的基本操作，不能构成pytorch中的一个Layer。当我们需要自定义一些非标准Layer时，可以在其中调用nn.functional中的操作。例如，relu仅仅是一个函数，参数包括输入和计算需要的参数，返回计算的结果，它不能存储任何上下文的信息。</p>
<p>torch.nn包里面只是包装好了神经网络架构的类，nn.functional 与torch.nn包相比，nn.functional是可以直接调用函数的。</p>

    </div>

    
    
    
<div>
	
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">----本文结束，感谢您的阅读。如有错，请指正。----</div>
    
</div>

	
</div>
    
      <div>
        <div id="reward-container">
  <div>大哥大嫂过年好！支持我一下呗</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.jpg" alt="湛蓝星空 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="湛蓝星空 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      </div>

    <footer class="post-footer">
          
        
        <div class="post-tags">
            <a href="/tags/%E6%A1%86%E6%9E%B6/" rel="tag"># 框架</a>
          
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/2019/10/13/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81batch%E6%AD%A3%E5%88%99%E5%8C%96/" rel="next" title="超参数调试、batch正则化">
                <i class="fa fa-chevron-left"></i> 超参数调试、batch正则化
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
              <a href="/2019/10/26/pytorch%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="prev" title="pytorch的可视化">
                pytorch的可视化 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
    </footer>
  </div>
  
  
  
  </article>

  </div>


          </div>
          


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="湛蓝星空">
  <p class="site-author-name" itemprop="name">湛蓝星空</p>
  <div class="site-description motion-element" itemprop="description">这个人贼菜</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/%20%7C%7C%20archive">
        
          <span class="site-state-item-count">105</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/%20%7C%7C%20th">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/%20%7C%7C%20tags">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/Brickexperts" title="GitHub &rarr; https://github.com/Brickexperts" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
  </div>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensor"><span class="nav-text">Tensor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#torch-squeeze"><span class="nav-text">torch.squeeze</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#torch-abs"><span class="nav-text">torch.abs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#torch-add"><span class="nav-text">torch.add</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#torch-mean"><span class="nav-text">torch.mean</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#比较运算符"><span class="nav-text">比较运算符</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#torch-eq"><span class="nav-text">torch.eq</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#torch-ge"><span class="nav-text">torch.ge</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#torch-gt"><span class="nav-text">torch.gt</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#torch-le"><span class="nav-text">torch.le</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#torch-lt"><span class="nav-text">torch.lt</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Variable"><span class="nav-text">Variable</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#parameters"><span class="nav-text">parameters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#backward"><span class="nav-text">backward</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#zero-grad"><span class="nav-text">zero_grad</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#单独设置参数"><span class="nav-text">单独设置参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#单次优化"><span class="nav-text">单次优化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#补充"><span class="nav-text">补充</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LambdaLR机制："><span class="nav-text">LambdaLR机制：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#StepLR机制"><span class="nav-text">StepLR机制</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其它API"><span class="nav-text">其它API</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">湛蓝星空</span>
</div>

        








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>

    

  </div>

  
    
    
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  <script src="/js/utils.js?v=7.3.0"></script>
  <script src="/js/motion.js?v=7.3.0"></script>

  
  <script src="/js/affix.js?v=7.3.0"></script>
  <script src="/js/schemes/pisces.js?v=7.3.0"></script>



  
  <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>



  <script src="/js/next-boot.js?v=7.3.0"></script>

  

  

  


  





  



















  <script src="/js/local-search.js?v=7.3.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->














</body>
</html>
