<!DOCTYPE html>





<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="generator" content="Hexo 4.0.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    search: {
      root: '/',
      path: 'search.xml'
    },
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="前沿在使用XGBoost之前，要先安装XGBoost库。xgboost库要求我们必须要提供适合的Scipy环境。以下为大家提供在windows中和MAC使用pip来安装xgboost的代码：  windows： pip install xgboost #安装xgboost库pip install —upgrade xgboost #更新xgboost库 我在这步遇到超时报错，查了以下，改成如下安装">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="XGBoost">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;09&#x2F;12&#x2F;XGBoost&#x2F;index.html">
<meta property="og:site_name" content="DY的个人博客">
<meta property="og:description" content="前沿在使用XGBoost之前，要先安装XGBoost库。xgboost库要求我们必须要提供适合的Scipy环境。以下为大家提供在windows中和MAC使用pip来安装xgboost的代码：  windows： pip install xgboost #安装xgboost库pip install —upgrade xgboost #更新xgboost库 我在这步遇到超时报错，查了以下，改成如下安装">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost7.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost50.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost1.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost2.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost3.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost3.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoosting6.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost6.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost8.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost11.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost12.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost13.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost14.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost15png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;forest6.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost17.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost18.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost1.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost21.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost22.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost23.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost24.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost25.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost26.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost20.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost28.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost27.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost29.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost30.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost31.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost32.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost34.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost33.png">
<meta property="og:updated_time" content="2019-09-16T15:04:21.643Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;XGBoost7.png">
  <link rel="alternate" href="/atom.xml" title="DY的个人博客" type="application/atom+xml">
  <link rel="canonical" href="http://yoursite.com/2019/09/12/XGBoost/">


<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>XGBoost | DY的个人博客</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DY的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
    <ul id="menu" class="menu">
        
        
        
          
          <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        <li class="menu-item menu-item-search">
          <a href="javascript:;" target="_blank" rel="noopener" class="popup-trigger">
          
            <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>


    </div>
</nav>

</div>
    </header>

    

  <a href="https://github.com/Brickexperts" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/12/XGBoost/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="湛蓝星空">
      <meta itemprop="description" content="这个人贼菜">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DY的个人博客">
    </span>
      <header class="post-header">

        
          <h1 class="post-title" itemprop="name headline">XGBoost

              
            
          </h1>
        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-09-12 22:19:52" itemprop="dateCreated datePublished" datetime="2019-09-12T22:19:52+08:00">2019-09-12</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-09-16 23:04:21" itemprop="dateModified" datetime="2019-09-16T23:04:21+08:00">2019-09-16</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          <br>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="前沿"><a href="#前沿" class="headerlink" title="前沿"></a>前沿</h2><p>在使用XGBoost之前，要先安装XGBoost库。xgboost库要求我们必须要提供适合的Scipy环境。以下为大家提供在windows中和MAC使用pip来安装xgboost的代码： </p>
<p>windows：</p>
<p>pip install xgboost #安装xgboost库<br>pip install —upgrade xgboost #更新xgboost库</p>
<p>我在这步遇到超时报错，查了以下，改成如下安装：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost7.png" alt=""></p>
<p>后面看到一些帖子，发现下面这个方法才是真的好用，在C:\Users\湛蓝星空 这个路径下创建一个pip文件夹，在文件夹创建一个txt，将下面内容加入文件里面，再将文件后缀名改为 .ini。</p>
<p>[global]<br> index-url = <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost50.png" alt=""></p>
<p>这其实就是将源改为清华的源，防止被墙。非常管用</p>
<p>MAC：</p>
<p>brew install gcc@7<br>pip3 install xgboost </p>
<p>安装好XGBoost库后，我们有两种方式来使用我们的XGBoost库。第一种方式。是直接使用XGBoost库自己的建模流程。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost1.png" alt=""></p>
<p>其中最核心的，是DMtarix这个读取数据的类，以及train()这个用于训练的类。与sklearn把所有的参数都写在类中的方式不同，xgboost库中必须先使用字典设定参数集，再使用train来将参数及输入，然后进行训练。params可能的取值以及xgboost.train的列表：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost2.png" alt=""></p>
<p>我们也可以选择第二种方法，使用xgboost库中的sklearn的API：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost3.png" alt=""></p>
<p>有人发现，这两种方法的参数是不同的。其实只是写法不同，功能是相同的。使用xgboost中设定的建模流程来建模，和使用sklearnAPI中的类来建模，模型效果是比较相似的，但是xgboost库本身的运算速度（尤其是交叉验证）以及调参手段比sklearn要简单。</p>
<h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>XGBoost本身的核心是基于梯度提升树实现的集成算法，整体来说可以有三个核心部分：集成算法本身，用于集成的弱评估器，以及应用中的其他过程。</p>
<h3 id="梯度提升树"><a href="#梯度提升树" class="headerlink" title="梯度提升树"></a>梯度提升树</h3><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost3.png" alt=""></p>
<h4 id="Boosting过程"><a href="#Boosting过程" class="headerlink" title="Boosting过程"></a>Boosting过程</h4><p>XGBoost的基础是梯度提升算法，因此我们必须先从了解梯度提升算法开始。梯度提升（Gradient boosting）是构建预测模型的最强大技术之一，它是集成算法中提升法（Boosting）的代表算法。集成算法通过在数据上构建多个弱评估器，汇总所有弱评估器的建模结果，以获取比单个模型更好的回归或分类表现。弱评估器被定义为是表现至少比随机猜测更好的模型，即预测准确率不低于50%的任意模型。 集成不同弱评估器的方法有很多种。有像我们曾经在随机森林的课中介绍的，一次性建立多个平行独立的弱评估器的装袋法。也有像我们今天要介绍的提升法这样，逐一构建弱评估器，经过多次迭代逐渐累积多个弱评估器的方法。提升法的中最著名的算法包括Adaboost和梯度提升树，XGBoost就是由梯度提升树发展而来的。梯度提升树中可以有回归树也可以有分类树，两者都以CART树算法作为主流，XGBoost背后也是CART树，<strong>这意味着XGBoost中所有的树都是二叉的</strong>。</p>
<p>接下来，我们来了解一些Boosting算法是上面工作：首先，梯度提升回归树是专注于回归的树模型的提升集成模型，其建模过程大致如下：最开始先建立一棵树，然后逐渐迭代，每次迭代过程中都增加一棵树，逐渐形成众多树模型集成的强评估器。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoosting6.png" alt=""></p>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost6.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor <span class="keyword">as</span> XGBR</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor <span class="keyword">as</span> RFR</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression <span class="keyword">as</span> LinearR</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score <span class="keyword">as</span> CVS, train_test_split <span class="keyword">as</span> TTS</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error <span class="keyword">as</span> MSE</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">data = load_boston()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line">Xtrain,Xtest,Ytrain,Ytest = TTS(X,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">420</span>)</span><br><span class="line">reg = XGBR(n_estimators=<span class="number">100</span>).fit(Xtrain,Ytrain)</span><br><span class="line">print(<span class="string">"预测："</span>,reg.predict(Xtest)) <span class="comment">#传统接口predict</span></span><br><span class="line">print(<span class="string">"准确率："</span>,reg.score(Xtest,Ytest))</span><br><span class="line">print(<span class="string">"均方误差："</span>,MSE(Ytest,reg.predict(Xtest)))</span><br><span class="line">print(<span class="string">"模型的重要性分数："</span>,reg.feature_importances_)</span><br></pre></td></tr></table></figure>
<p>使用参数学习曲线观察n_estimators对模型的影响</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">axisx = range(<span class="number">10</span>,<span class="number">1010</span>,<span class="number">50</span>)</span><br><span class="line">cv = KFold(n_splits=<span class="number">5</span>, shuffle = <span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rs = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=i,random_state=<span class="number">420</span>)</span><br><span class="line">    rs.append(CVS(reg,Xtrain,Ytrain,cv=cv).mean())</span><br><span class="line">print(axisx[rs.index(min(rs))],max(rs))</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">"red"</span>,label=<span class="string">"XGB"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="方差与泛化误差"><a href="#方差与泛化误差" class="headerlink" title="方差与泛化误差"></a>方差与泛化误差</h4><p>机器学习中，我们用来衡量模型在未知数据上的准确率的指标，叫做泛化误差（Genelization error）一个集成模型(f)在未知数据集(D)上的泛化误差 ，由方差(var)，偏差(bais)和噪声(ε)共同决定。其中偏差就是训练集上的拟合程度决定，方差是模型的稳定性决定，噪音是不可控的。而泛化误差越小，模型就越理想。 </p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost8.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">cv=KFold(n_splits=<span class="number">5</span>,shuffle=<span class="literal">True</span>,random_state=<span class="number">42</span>)</span><br><span class="line">axisx = range(<span class="number">100</span>,<span class="number">300</span>,<span class="number">10</span>)</span><br><span class="line">rs = []</span><br><span class="line">var = []</span><br><span class="line">ge = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=i,random_state=<span class="number">420</span>)</span><br><span class="line">    cvresult = CVS(reg,Xtrain,Ytrain,cv=cv)</span><br><span class="line">    rs.append(cvresult.mean())</span><br><span class="line">    var.append(cvresult.var())</span><br><span class="line">    ge.append((<span class="number">1</span> - cvresult.mean())**<span class="number">2</span>+cvresult.var())</span><br><span class="line"><span class="comment">#得出最好的n_estimators</span></span><br><span class="line">print(axisx[rs.index(max(rs))],max(rs),var[rs.index(max(rs))])</span><br><span class="line">print(axisx[var.index(min(var))],rs[var.index(min(var))],min(var))</span><br><span class="line">print(axisx[ge.index(min(ge))],rs[ge.index(min(ge))],var[ge.index(min(ge))],min(ge))</span><br><span class="line">rs = np.array(rs)</span><br><span class="line">var = np.array(var)*<span class="number">0.01</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">"black"</span>,label=<span class="string">"XGB"</span>)</span><br><span class="line"><span class="comment">#添加方差线</span></span><br><span class="line">plt.plot(axisx,rs+var,c=<span class="string">"red"</span>,linestyle=<span class="string">'-.'</span>)</span><br><span class="line">plt.plot(axisx,rs-var,c=<span class="string">"red"</span>,linestyle=<span class="string">'-.'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#泛化误差的可控部分</span></span><br><span class="line">plt.plot(axisx,ge,c=<span class="string">"gray"</span>,linestyle=<span class="string">'-.'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>从这个过程中观察n_estimators参数对模型的影响，我们可以得出以下结论： </p>
<p>首先，XGB中的树的数量决定了模型的学习能力，树的数量越多，模型的学习能力越强。只要XGB中树的数量足够 了，即便只有很少的数据， 模型也能够学到训练数据100%的信息，所以XGB也是天生过拟合的模型。但在这种情况 下，模型会变得非常不稳定。</p>
<p>第二，XGB中树的数量很少的时候，对模型的影响较大，当树的数量已经很多的时候，对模型的影响比较小，只能有 微弱的变化。当数据本身就处于过拟合的时候，再使用过多的树能达到的效果甚微，反而浪费计算资源。当唯一指标 或者准确率给出的n_estimators看起来不太可靠的时候，我们可以改造学习曲线来帮助我们。</p>
<p> 第三，树的数量提升对模型的影响有极限，开始，模型的表现会随着XGB的树的数量一起提升，但到达某个点之 后，树的数量越多，模型的效果会逐步下降，这也说明了暴力增加n_estimators不一定有效果。<br>这些都和随机森林中的参数n_estimators表现出一致的状态。在随机森林中我们总是先调整n_estimators，当 n_estimators的极限已达到，我们才考虑其他参数，但XGB中的状况明显更加复杂，当数据集不太寻常的时候会更加 复杂。这是我们要给出的第一个超参数，因此还是建议优先调整n_estimators，一般都不会建议一个太大的数目， 300以下为佳。</p>
<h4 id="subsample"><a href="#subsample" class="headerlink" title="subsample"></a>subsample</h4><p>我们训练模型之前，必然会有一个巨大的数据集。我们都知道树模型是天生过拟合的模型，并且如果数据量太过巨 大，树模型的计算会非常缓慢，因此，我们要对我们的原始数据集进行有放回抽样（bootstrap）。有放回的抽样每 次只能抽取一个样本，若我们需要总共N个样本，就需要抽取N次。每次抽取一个样本的过程是独立的，这一次被抽 到的样本会被放回数据集中，下一次还可能被抽到，因此抽出的数据集中，可能有一些重复的数据。在无论是装袋还是提升的集成算法中，有放回抽样都是我们防止过拟合。</p>
<p>在sklearn中，我们使用参数subsample来控制我们的随机抽样。在xgb和sklearn中，这个参数都默认为1且不能取到0，所以取值范围是(0,1]。这说明我们无法控制模型是否进行随机有放回抽样，只能控制抽样抽出来的样本量大概是多少。</p>
<h4 id="eta-or-learning-rate"><a href="#eta-or-learning-rate" class="headerlink" title="eta   or  learning_rate"></a>eta   or  learning_rate</h4><p>在逻辑回归中，我们自定义步长&alpha;来干涉我们的迭代速率，在XGB中看起来却没有这样的设置，但其实不然。在XGB<br>中，我们完整的迭代决策树的公式应该写作： </p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost11.png" alt=""></p>
<p>其中&eta;读作”eta”，是迭代决策树时的步长（shrinkage），又叫做学习率（learning rate）。和逻辑回归中的&alpha;类似，&eta;<br>越大，迭代的速度越快，算法的极限很快被达到，有可能无法收敛到真正的最佳。&eta;越小，越有可能找到更精确的最<br>佳值，更多的空间被留给了后面建立的树，但迭代速度会比较缓慢。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost12.png" alt=""></p>
<p>在sklearn中，我们使用参数learning_rate来干涉我们的学习速率：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost13.png" alt=""></p>
<p>梯度提升树是XGB的基础，本节中已经介绍了XGB中与梯度提升树的过程相关的四个参数：n_estimators，learning_rate ，silent，subsample。这四个参数的主要目的，其实并不是提升模型表现，更多是了解梯度提升树的原理。现在来看，我们的梯度提升树可是说是由三个重要的部分组成：</p>
<ol>
<li>一个能够衡量集成算法效果的，能够被最优化的损失函数</li>
<li>一个能够实现预测的弱评估器</li>
<li>一种能够让弱评估器集成的手段，包括我们讲解的迭代方法，抽样手段，样本加权等等过程 </li>
</ol>
<h4 id="booster"><a href="#booster" class="headerlink" title="booster"></a>booster</h4><p>梯度提升算法中不只有梯度提升树，XGB作为梯度提升算法的进化，自然也不只有树模型一种弱评估器。在XGB中，除了树模型，我们还可以选用线性模型，比如线性回归，来进行集成。虽然主流的XGB依然是树模型，但我们也可以使用其他的模型。基于XGB的这种性质，我们有参数“booster”来控制我们究竟使用怎样的弱评估器。 </p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost14.png" alt=""></p>
<p>两个参数都默认为”gbtree”，如果不想使用树模型，则可以自行调整。当XGB使用线性模型的时候，它的许多数学过<br>程就与使用普通的Boosting集成非常相似。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> booster <span class="keyword">in</span> [<span class="string">"gbtree"</span>,<span class="string">"gblinear"</span>,<span class="string">"dart"</span>]:</span><br><span class="line">reg = XGBR(<span class="attribute">n_estimators</span>=180,learning_rate=0.1,random_state=420,booster=booster).fit(Xtrain,Ytrain)</span><br><span class="line">	<span class="builtin-name">print</span>(booster)</span><br><span class="line">	<span class="builtin-name">print</span>(reg.score(Xtest,Ytest))</span><br></pre></td></tr></table></figure>
<h4 id="objective"><a href="#objective" class="headerlink" title="objective"></a>objective</h4><p>在众多机器学习算法中，损失函数的核心是衡量模型的泛化能力，即模型在未知数据上的预测的准确与否，我们训练模型的核心目标也是希望模型能够预测准确。在XGB中，预测准确自然是非常重要的因素，但我们之前提到过，XGB的是实现了模型表现和运算速度的平衡的算法。普通的损失函数，比如错误率，均方误差等，都只能够衡量模型的表现，无法衡量模型的运算速度。回忆一下，我们曾在许多模型中使用空间复杂度和时间复杂度来衡量模型的运算效率。XGB因此引入了模型复杂度来衡量算法的运算效率。因此XGB的目标函数被写作：传统损失函数 + 模型复杂度。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost15png" alt=""></p>
<p>其中i代表数据集中的第i个样本，m表示导入第K棵树的数据总量，K代表建立的所有树(n_estimators)。 第二项代表模型的复杂度，使用树模型的某种变换$\Omega$表示，这个变化代表了一个从树的结构来衡量树模型的复杂度的式子,可以有多种定义。我们在迭代每一颗的过程中，都最小化Obj来求最优的yi。</p>
<p>在机器学习中，我们用来衡量模型在未知数据上的准确率的指标，叫做泛化误差（Genelization error）。一个集成模型(f)<br>在未知数据集(D)上的泛化误差 ，由方差(var)，偏差(bais)和噪声(ε)共同决定，而泛化误差越小，模型就越理想。从下面的图可以看出来，方差和偏差是此消彼长的，并且模型的复杂度越高，方差越大，偏差越小。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/forest6.png" alt=""></p>
<p>方差可以被简单地解释为模型在不同数据集上表现出来地稳定性，而偏差是模型预测的准确度。那方差-偏差困境就<br>可以对应到我们的Obj中了： </p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost17.png" alt=""></p>
<p>第一项是衡量我们的偏差，模型越不准确，第一项就会越大。第二项是衡量我们的方差，模型越复杂，模型的学习就会越具体，到不同数据集上的表现就会差异巨大，方差就会越大。所以我们求解Obj的最小值，其实是在求解方差与偏差的平衡点，以求模型的泛化误差最小，运行速度最快。 </p>
<p>在应用中，我们使用参数“objective”来确定我们目标函数的第一部分，也就是衡量损失的部分。 </p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost18.png" alt=""></p>
<p>xgb自身的调用方式：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost1.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor <span class="keyword">as</span> XGBR</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error <span class="keyword">as</span> MSE</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="keyword">as</span> TTS</span><br><span class="line">data = load_boston()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line">Xtrain,Xtest,Ytrain,Ytest = TTS(X,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">420</span>)</span><br><span class="line"><span class="comment">#默认reg:linear</span></span><br><span class="line">reg = XGBR(n_estimators=<span class="number">180</span>,random_state=<span class="number">420</span>).fit(Xtrain,Ytrain)</span><br><span class="line">print(<span class="string">"sklearn中的XGboost准确率："</span>,reg.score(Xtest,Ytest))</span><br><span class="line">print(<span class="string">"sklearn中的xgb均方误差："</span>,MSE(Ytest,reg.predict(Xtest)))</span><br><span class="line"><span class="comment">#xgb实现法</span></span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="comment">#使用类Dmatrix读取数据</span></span><br><span class="line">dtrain = xgb.DMatrix(Xtrain,Ytrain)</span><br><span class="line">dtest = xgb.DMatrix(Xtest,Ytest)</span><br><span class="line"><span class="comment">#写明参数，silent默认为False，通常需要手动将它关闭</span></span><br><span class="line">param = &#123;<span class="string">'silent'</span>:<span class="literal">False</span>,<span class="string">'objective'</span>:<span class="string">'reg:linear'</span>,<span class="string">"eta"</span>:<span class="number">0.1</span>&#125;</span><br><span class="line">num_round = <span class="number">180</span></span><br><span class="line"><span class="comment">#类train，可以直接导入的参数是训练数据，树的数量，其他参数都需要通过params来导入</span></span><br><span class="line">bst = xgb.train(param, dtrain, num_round)</span><br><span class="line"><span class="comment">#接口predict</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">print(<span class="string">"xgb中的准确率："</span>,r2_score(Ytest,bst.predict(dtest)))</span><br><span class="line">print(<span class="string">"xgb中的均方误差："</span>,MSE(Ytest,bst.predict(dtest)))</span><br></pre></td></tr></table></figure>
<p>看得出来，无论是从R<sup>2</sup>还是从MSE的角度来看，都是xgb库本身表现更优秀。</p>
<h4 id="alpha-or-reg-alpha-amp-lambda-or-reg-lambda"><a href="#alpha-or-reg-alpha-amp-lambda-or-reg-lambda" class="headerlink" title="(alpha or reg_alpha)  &amp; (lambda or  reg_lambda)"></a>(alpha or reg_alpha)  &amp; (lambda or  reg_lambda)</h4><p>对于XGB来说，每个叶子节点上会有一个预测分数（prediction score），也被称为叶子权重。这个叶子权重就是所有在这个叶子节点上的样本在这一棵树上的回归取值,用f<sub>k</sub>(x<sub>i</sub>)或者&omega;来表示。</p>
<p>当有多棵树的时候，集成模型的回归结果就是所有树的预测分数之和，假设这个集成模型中总共有K棵决策树，则整<br>个模型在这个样本i上给出的预测结果为 </p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost21.png" alt=""></p>
<p>如下图：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost22.png" alt=""></p>
<p>设一棵树上总共包含了T个叶子节点，其中每个叶子节点的索引为j，则这个叶子节点上的样本权重是w<sub>j</sub>。依据这个，我们定义模型的复杂度$\Omega$(f)为（注意这不是唯一可能的定义，我们当然还可以使用其他的定义，只要满足叶子越多/深度越大，复杂度越大的理论):</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost23.png" alt=""></p>
<p>使用L2正则项：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost24.png" alt=""></p>
<p>使用L1正则项：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost25.png" alt=""></p>
<p>还可以两个一起用：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost26.png" alt=""></p>
<p>这个结构中有两部分内容，一部分是控制树结构的&gamma;，另一部分则是我们的正则项。叶子数量<em>T</em>可以代表整个树结构，这是因为在XGBoost中所有的树都是CART树（二叉树），所以我们可以根据叶子的数量<em>T</em>判断出树的深度，而&gamma;是我们自定的控制叶子数量的参数。 至于第二部分正则项，类比一下我们岭回归和Lasso的结构，参数&alpha;和&lambda;的作用其实非常容易理解，他们都是控制正则化强度的参数，我们可以二选一使用，也可以一起使用加大正则化的力度。当 和 都为0的时候，目标函数就是普通的梯度提升树的目标函数。</p>
<p>来看正则化系数分别对应的参数：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost20.png" alt=""></p>
<h4 id="gamma"><a href="#gamma" class="headerlink" title="gamma"></a>gamma</h4><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost28.png" alt=""></p>
<p>回忆一下决策树中我们是如何进行计算：我们使用基尼系数或信息熵来衡量分枝之后叶子节点的不纯度，分枝前的信息熵与分治后的信息熵之差叫做信息增益，信息增益最大的特征上的分枝就被我们选中，当信息增益低于某个阈值时，就让树停止生长。在XGB中，我们使用的方式是类似的：我们首先使用目标函数来衡量树的结构的优劣，然后让树从深度0开始生长，每进行一次分枝，我们就计算目标函数减少了多少，当目标函数的降低低于我们设定的某个阈值时，就让树停止生长。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost27.png" alt=""></p>
<p>原理还不是很明白，先贴最后的Gain函数</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost29.png" alt=""></p>
<p>从上面的Gain函数，从上面的目标函数和结构分数之差Gain的式子来看，&gamma;使我们每增加一片叶子就会被剪去的惩罚项。增加的叶子越多，结构分数之差Gain会被惩罚越重，所以&gamma;也被称为”复杂性控制“。所以&gamma;是我们用来防止过拟合的重要参数。&gamma;是对梯度提升树影响最大的参数之一，其效果不逊色与n_estimators和放过拟合神器max_depth。同时&gamma;还是我们让树停止生长的重要参数。</p>
<p>在XGB中，规定只要结构分数之差Gain大于0，即只要目标函数还能减小，我们就允许继续进行分枝。也就是说，我们对于目标函数减小量的要求是：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost30.png" alt=""></p>
<p>因此，我们可以直接通过设定&gamma;的大小让XGB的树停止生长。&gamma;因此被定义为，在树的叶节点上进行进一步分枝所需的最小目标函数减少量，在决策树和随机森林中也有类似的参数(min_split_loss，min_samples_split)。 设定越大，算法就越保守，树的叶子数量就越少，模型的复杂度就越低。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor <span class="keyword">as</span> XGBR</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="keyword">as</span> TTS</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score <span class="keyword">as</span> CVS</span><br><span class="line">data = load_boston()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line">Xtrain,Xtest,Ytrain,Ytest = TTS(X,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">420</span>)</span><br><span class="line">axisx = np.arange(<span class="number">0</span>,<span class="number">5</span>,<span class="number">0.05</span>)</span><br><span class="line">rs = []</span><br><span class="line">var = []</span><br><span class="line">ge = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axisx:</span><br><span class="line">    reg = XGBR(n_estimators=<span class="number">180</span>,random_state=<span class="number">420</span>,gamma=i)</span><br><span class="line">    result = CVS(reg,Xtrain,Ytrain,cv=<span class="number">20</span>)</span><br><span class="line">    rs.append(result.mean())</span><br><span class="line">    var.append(result.var())</span><br><span class="line">    ge.append((<span class="number">1</span> - result.mean())**<span class="number">2</span>+result.var())</span><br><span class="line">print(axisx[rs.index(max(rs))],max(rs),var[rs.index(max(rs))])</span><br><span class="line">print(axisx[var.index(min(var))],rs[var.index(min(var))],min(var))</span><br><span class="line">print(axisx[ge.index(min(ge))],rs[ge.index(min(ge))],var[ge.index(min(ge))],min(ge))</span><br><span class="line">rs = np.array(rs)</span><br><span class="line">var = np.array(var)*<span class="number">0.1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(axisx,rs,c=<span class="string">"black"</span>,label=<span class="string">"XGB"</span>)</span><br><span class="line">plt.plot(axisx,rs+var,c=<span class="string">"red"</span>,linestyle=<span class="string">'-.'</span>)</span><br><span class="line">plt.plot(axisx,rs-var,c=<span class="string">"red"</span>,linestyle=<span class="string">'-.'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>为了调整&gamma;，我们需要引入新的工具，xgboost库中的类xgboost.cv</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost31.png" alt=""></p>
<p>为了使用xgboost.cv，我们必须要熟悉xgboost自带的模型评估指标。xgboost在建库的时候本着大而全的目标，和sklearn类似，包括了大约20个模型评估指标，然而用于回归和分类的其实只有几个，大部分是用于一些更加高级的功能比如ranking。来看用于回归和分类的评估指标都有哪些：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost32.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line">data2 = load_breast_cancer()</span><br><span class="line">x2 = data2.data</span><br><span class="line">y2 = data2.target</span><br><span class="line">dfull2 = xgb.DMatrix(x2,y2)</span><br><span class="line">param1 = &#123;<span class="string">'silent'</span>:<span class="literal">True</span>,<span class="string">'obj'</span>:<span class="string">'binary:logistic'</span>,<span class="string">"gamma"</span>:<span class="number">0</span>,<span class="string">"nfold"</span>:<span class="number">5</span>&#125;</span><br><span class="line">param2 = &#123;<span class="string">'silent'</span>:<span class="literal">True</span>,<span class="string">'obj'</span>:<span class="string">'binary:logistic'</span>,<span class="string">"gamma"</span>:<span class="number">2</span>,<span class="string">"nfold"</span>:<span class="number">5</span>&#125;</span><br><span class="line">num_round = <span class="number">100</span></span><br><span class="line">cvresult1 = xgb.cv(param1, dfull2, num_round,metrics=(<span class="string">"error"</span>))</span><br><span class="line">cvresult2 = xgb.cv(param2, dfull2, num_round,metrics=(<span class="string">"error"</span>))</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">plt.grid()</span><br><span class="line">plt.plot(range(<span class="number">1</span>,<span class="number">101</span>),cvresult1.iloc[:,<span class="number">0</span>],c=<span class="string">"red"</span>,label=<span class="string">"train,gamma=0"</span>)</span><br><span class="line">plt.plot(range(<span class="number">1</span>,<span class="number">101</span>),cvresult1.iloc[:,<span class="number">2</span>],c=<span class="string">"orange"</span>,label=<span class="string">"test,gamma=0"</span>)</span><br><span class="line">plt.plot(range(<span class="number">1</span>,<span class="number">101</span>),cvresult2.iloc[:,<span class="number">0</span>],c=<span class="string">"green"</span>,label=<span class="string">"train,gamma=2"</span>)</span><br><span class="line">plt.plot(range(<span class="number">1</span>,<span class="number">101</span>),cvresult2.iloc[:,<span class="number">2</span>],c=<span class="string">"blue"</span>,label=<span class="string">"test,gamma=2"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="scale-pos-weight"><a href="#scale-pos-weight" class="headerlink" title="scale_pos_weight"></a>scale_pos_weight</h4><p>XGB中存在着调节样本不平衡的参数scale_pos_weight,这个参数非常类似于之前随机森林和支持向量机中我们都使用到过的class_weight参数。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost34.png" alt=""></p>
<h4 id="其它参数"><a href="#其它参数" class="headerlink" title="其它参数"></a>其它参数</h4><p>XGBoost应用的核心之一就是减轻过拟合带来的影响。作为树模型，减轻过拟合的方式主要是靠对决策树剪枝来降低模型的复杂度，以求降低方差。在之前的讲解中，我们已经学习了好几个可以用来防止过拟合的参数，包括上一节提到的复杂度控制&lambda;，正则化的两个参数&lambda;和&alpha;，控制迭代速度的参数 以及管理每次迭代前进行的随机有放回抽样的参数subsample。所有的这些参数都可以用来减轻过拟合。但除此之外，我们还有几个影响重大的，专用于剪枝的参数： </p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/XGBoost33.png" alt=""></p>
<h2 id="使用Pickle保存和调用模型"><a href="#使用Pickle保存和调用模型" class="headerlink" title="使用Pickle保存和调用模型"></a>使用Pickle保存和调用模型</h2><p>pickle是python编程中比较标准的一个保存和调用模型的库，我们可以使用pickle和open函数的连用，来讲我们的模型保存到本地。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#保存模型的coding</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line">data2 = load_breast_cancer()</span><br><span class="line">x2 = data2.data</span><br><span class="line">y2 = data2.target</span><br><span class="line">Xtrain,Xtest,Ytrain,Ytest=train_test_split(x2,y2,test_size=<span class="number">0.3</span>,random_state=<span class="number">420</span>)</span><br><span class="line">dtrain = xgb.DMatrix(Xtrain,Ytrain)</span><br><span class="line"><span class="comment">#设定参数，对模型进行训练</span></span><br><span class="line">param = &#123;<span class="string">'silent'</span>:<span class="literal">True</span></span><br><span class="line">,<span class="string">'obj'</span>:<span class="string">'reg:linear'</span></span><br><span class="line">,<span class="string">"subsample"</span>:<span class="number">1</span></span><br><span class="line">,<span class="string">"eta"</span>:<span class="number">0.05</span></span><br><span class="line">,<span class="string">"gamma"</span>:<span class="number">20</span></span><br><span class="line">,<span class="string">"lambda"</span>:<span class="number">3.5</span></span><br><span class="line">,<span class="string">"alpha"</span>:<span class="number">0.2</span></span><br><span class="line">,<span class="string">"max_depth"</span>:<span class="number">4</span></span><br><span class="line">,<span class="string">"colsample_bytree"</span>:<span class="number">0.4</span></span><br><span class="line">,<span class="string">"colsample_bylevel"</span>:<span class="number">0.6</span></span><br><span class="line">,<span class="string">"colsample_bynode"</span>:<span class="number">1</span>&#125;</span><br><span class="line">num_round = <span class="number">180</span></span><br><span class="line">bst = xgb.train(param, dtrain, num_round)</span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">pickle.dump(bst, open(<span class="string">"xgboostonboston.dat"</span>,<span class="string">"wb"</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用模型的coding</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="keyword">as</span> TTS</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error <span class="keyword">as</span> MSE</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">data = load_breast_cancer()</span><br><span class="line">X = data.data</span><br><span class="line">y = data.target</span><br><span class="line">Xtrain,Xtest,Ytrain,Ytest = TTS(X,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">420</span>)</span><br><span class="line"><span class="comment">#注意，如果我们保存的模型是xgboost库中建立的模型，则导入的数据类型也必须是xgboost库中的数据类型</span></span><br><span class="line">dtest = xgb.DMatrix(Xtest,Ytest)</span><br><span class="line"><span class="comment">#导入模型</span></span><br><span class="line">loaded_model = pickle.load(open(<span class="string">"xgboostonboston.dat"</span>, <span class="string">"rb"</span>))</span><br><span class="line">print(<span class="string">"Loaded model from: xgboostonboston.dat"</span>)</span><br><span class="line"><span class="comment">#做预测</span></span><br><span class="line">ypreds = loaded_model.predict(dtest)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error <span class="keyword">as</span> MSE, r2_score</span><br><span class="line">print(<span class="string">"均方误差："</span>,MSE(Ytest,ypreds))</span><br><span class="line">print(r2_score(Ytest,ypreds))</span><br></pre></td></tr></table></figure>
<h2 id="使用Joblib保存和调用模型"><a href="#使用Joblib保存和调用模型" class="headerlink" title="使用Joblib保存和调用模型"></a>使用Joblib保存和调用模型</h2><p>Joblib是SciPy生态系统中的一部分，它为Python提供保存和调用管道和对象的功能，处理NumPy结构的数据尤其高<br>效，对于很大的数据集和巨大的模型非常有用。Joblib与pickle API非常相似 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor <span class="keyword">as</span> XGBR</span><br><span class="line">bst = XGBR(n_estimators=<span class="number">200</span>,eta=<span class="number">0.05</span>,gamma=<span class="number">20</span>,reg_lambda=<span class="number">3.5</span>,reg_alpha=<span class="number">0.2</span>,max_depth=<span class="number">4</span>,colsample_bytree=<span class="number">0.4</span>,colsample_bylevel=<span class="number">0.6</span>).fit(Xtrain,Ytrain)</span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">joblib.dump(bst,<span class="string">"xgboost-boston.dat"</span>)</span><br><span class="line"><span class="comment">#调用模型</span></span><br><span class="line">loaded_model = joblib.load(<span class="string">"xgboost-boston.dat"</span>)</span><br><span class="line"><span class="comment">#这里可以直接导入Xtest</span></span><br><span class="line">ypreds = loaded_model.predict(Xtest)</span><br><span class="line"><span class="keyword">print</span>（MSE(Ytest, ypreds)）</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
<div>
	
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">----本文结束，感谢您的阅读。如有错，请指正。----</div>
    
</div>

	
</div>
    
      <div>
        <div id="reward-container">
  <div>大哥大嫂过年好！支持我一下呗</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.jpg" alt="湛蓝星空 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="湛蓝星空 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      </div>

    <footer class="post-footer">
          
        
        <div class="post-tags">
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/2019/09/12/sklearn%E4%B8%AD%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="next" title="sklearn中的神经网络">
                <i class="fa fa-chevron-left"></i> sklearn中的神经网络
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
              <a href="/2019/09/15/SVM%E8%A7%A3%E8%AF%BB(2)/" rel="prev" title="SVM解读(2)">
                SVM解读(2) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
    </footer>
  </div>
  
  
  
  </article>

  </div>


          </div>
          


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="湛蓝星空">
  <p class="site-author-name" itemprop="name">湛蓝星空</p>
  <div class="site-description motion-element" itemprop="description">这个人贼菜</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/%20%7C%7C%20archive">
        
          <span class="site-state-item-count">93</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/%20%7C%7C%20th">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/%20%7C%7C%20tags">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">45</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/Brickexperts" title="GitHub &rarr; https://github.com/Brickexperts" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
  </div>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前沿"><span class="nav-text">前沿</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#XGBoost"><span class="nav-text">XGBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度提升树"><span class="nav-text">梯度提升树</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Boosting过程"><span class="nav-text">Boosting过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#参数"><span class="nav-text">参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#方差与泛化误差"><span class="nav-text">方差与泛化误差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#subsample"><span class="nav-text">subsample</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#eta-or-learning-rate"><span class="nav-text">eta   or  learning_rate</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#booster"><span class="nav-text">booster</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#objective"><span class="nav-text">objective</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#alpha-or-reg-alpha-amp-lambda-or-reg-lambda"><span class="nav-text">(alpha or reg_alpha)  &amp; (lambda or  reg_lambda)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gamma"><span class="nav-text">gamma</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scale-pos-weight"><span class="nav-text">scale_pos_weight</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#其它参数"><span class="nav-text">其它参数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用Pickle保存和调用模型"><span class="nav-text">使用Pickle保存和调用模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用Joblib保存和调用模型"><span class="nav-text">使用Joblib保存和调用模型</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">湛蓝星空</span>
</div>

        








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>

    

  </div>

  
    
    
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  <script src="/js/utils.js?v=7.3.0"></script>
  <script src="/js/motion.js?v=7.3.0"></script>

  
  <script src="/js/affix.js?v=7.3.0"></script>
  <script src="/js/schemes/pisces.js?v=7.3.0"></script>



  
  <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>



  <script src="/js/next-boot.js?v=7.3.0"></script>

  

  

  


  





  



















  <script src="/js/local-search.js?v=7.3.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->














</body>
</html>
