<!DOCTYPE html>





<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="generator" content="Hexo 4.0.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    search: {
      root: '/',
      path: 'search.xml'
    },
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="张量张量可以说时Tensorflow的标志。因为整个框架的名称Tensorflow就是张量流的意思。 在tensorflow中把数据称为张量（tensor）。每个tensor包含了类型（type）、阶（rank）和形状（shape）。 tensor类型下面把tensor类型和python的类型放在一起比较。  tensor阶张量的阶：相当于数组的维度。    但张量的阶和矩阵的阶并不是同一个概念，">
<meta name="keywords" content="框架">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow（1）">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;08&#x2F;09&#x2F;tensorflow%EF%BC%881%EF%BC%89&#x2F;index.html">
<meta property="og:site_name" content="DY的个人博客">
<meta property="og:description" content="张量张量可以说时Tensorflow的标志。因为整个框架的名称Tensorflow就是张量流的意思。 在tensorflow中把数据称为张量（tensor）。每个tensor包含了类型（type）、阶（rank）和形状（shape）。 tensor类型下面把tensor类型和python的类型放在一起比较。  tensor阶张量的阶：相当于数组的维度。    但张量的阶和矩阵的阶并不是同一个概念，">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;3.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;4.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL2.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;IMG_20191117_124317.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117141903.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142019.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142104.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142135.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142156.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142229.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142256.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142336.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142418.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117142459.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117151643.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117152700.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117153257.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117151804.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117153718.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117153832.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117153918.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117163501.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117163537.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL12.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL13.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117164011.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191117164045.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL5.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191120172937.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL6.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL7.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL9.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;20190809123839.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL8.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL10.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL11.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;2.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL15.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed&#x2F;master&#x2F;DL17.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;20191116221508.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;1.jpg">
<meta property="og:updated_time" content="2019-11-20T13:24:54.146Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Brickexperts&#x2F;Figurebed2&#x2F;master&#x2F;3.jpg">
  <link rel="alternate" href="/atom.xml" title="DY的个人博客" type="application/atom+xml">
  <link rel="canonical" href="http://yoursite.com/2019/08/09/tensorflow%EF%BC%881%EF%BC%89/">


<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>tensorflow（1） | DY的个人博客</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DY的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
    <ul id="menu" class="menu">
        
        
        
          
          <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        <li class="menu-item menu-item-search">
          <a href="javascript:;" target="_blank" rel="noopener" class="popup-trigger">
          
            <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>


    </div>
</nav>

</div>
    </header>

    

  <a href="https://github.com/Brickexperts" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/09/tensorflow%EF%BC%881%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="湛蓝星空">
      <meta itemprop="description" content="这个人贼菜">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DY的个人博客">
    </span>
      <header class="post-header">

        
          <h1 class="post-title" itemprop="name headline">tensorflow（1）

              
            
          </h1>
        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-08-09 12:17:39" itemprop="dateCreated datePublished" datetime="2019-08-09T12:17:39+08:00">2019-08-09</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-11-20 21:24:54" itemprop="dateModified" datetime="2019-11-20T21:24:54+08:00">2019-11-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">框架</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A1%86%E6%9E%B6/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a></span>

                
                
              
            </span>
          

          <br>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><p>张量可以说时Tensorflow的标志。因为整个框架的名称Tensorflow就是张量流的意思。</p>
<p>在tensorflow中把数据称为张量（tensor）。每个tensor包含了类型（type）、阶（rank）和形状（shape）。</p>
<h3 id="tensor类型"><a href="#tensor类型" class="headerlink" title="tensor类型"></a>tensor类型</h3><p>下面把tensor类型和python的类型放在一起比较。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/3.jpg" alt=""></p>
<h3 id="tensor阶"><a href="#tensor阶" class="headerlink" title="tensor阶"></a>tensor阶</h3><p>张量的阶：相当于数组的维度。    但张量的阶和矩阵的阶并不是同一个概念，主要是看有几层中括号。例如：对于一个传统的三阶矩阵a=[[1,2,3],[4,5,6],[7,8,9]]。在张量中的阶数表示为2阶（因为它有两层中括号）</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/4.jpg" alt=""></p>
<h3 id="tensor形状"><a href="#tensor形状" class="headerlink" title="tensor形状"></a>tensor形状</h3><p>shape用于描述张量内部的组织关系。“形状”可以通过Python中的整数列表或元祖来表示，也可以Tensorflow中的相关形状函数来表示。</p>
<p>举例：一个二阶张量a=[[1,2,3],[4,5,6]]形状是两行三列，描述为(2,3)。</p>
<p>tensorflow中张量形状分为动态形状和静态形状，其在于有没有生成一个新的张量数据。静态形状的修改不能跨维度修改</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL2.png" alt=""></p>
<h3 id="相关操作"><a href="#相关操作" class="headerlink" title="相关操作"></a>相关操作</h3><p>张量的相关操作包括类型转换、数值操作、形状变换、数据操作。</p>
<h4 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h4><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/IMG_20191117_124317.jpg" alt=""></p>
<h4 id="数值操作"><a href="#数值操作" class="headerlink" title="数值操作"></a>数值操作</h4><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117141903.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142019.png" alt=""></p>
<h4 id="形状变换"><a href="#形状变换" class="headerlink" title="形状变换"></a>形状变换</h4><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142104.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142135.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142156.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142229.png" alt=""></p>
<h4 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h4><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142256.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142336.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142418.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117142459.png" alt=""></p>
<h2 id="算术运算函数"><a href="#算术运算函数" class="headerlink" title="算术运算函数"></a>算术运算函数</h2><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117151643.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117152700.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117153257.png" alt=""></p>
<h2 id="矩阵相关函数"><a href="#矩阵相关函数" class="headerlink" title="矩阵相关函数"></a>矩阵相关函数</h2><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117151804.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117153718.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117153832.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117153918.png" alt=""></p>
<h2 id="规约计算"><a href="#规约计算" class="headerlink" title="规约计算"></a>规约计算</h2><p>规约计算的操作都会有降维的功能，在所有reduce_xxx系列操作函数中，都是以xxx的手段降维，每个函数都有axis这个参数，即沿某个方向，使用xxx方法对输入的Tensor进行降维。</p>
<p>axis的默认值是None，即把input_tensor降到0维。即一个数。对于二维input_tensor而言，axis=0，则按列计算。axis=1，则按行计算。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117163501.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117163537.png" alt=""></p>
<h3 id="tf-reduce-mean"><a href="#tf-reduce-mean" class="headerlink" title="tf.reduce_mean()"></a>tf.reduce_mean()</h3><p>函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，主要用作降维或者计算tensor（图像）的平均值。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL12.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL13.png" alt=""></p>
<p>如果想设置为原来向量的维度，keep_dims=True。</p>
<h2 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h2><p>分割操作是tensorflow不常用的操作，在复杂的网络模型里偶尔才会用到。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117164011.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191117164045.png" alt=""></p>
<h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><p>整个程序的结构称为图（graph），可以把图看作一个计算任务。</p>
<p>一个Tensorflow程序默认是建立一个图的，除了系统自动建图外，还可以自主建图。</p>
<h3 id="建立图"><a href="#建立图" class="headerlink" title="建立图"></a>建立图</h3><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL5.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">c=tf.constant(<span class="number">0.0</span>)</span><br><span class="line">g=tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">  c1=tf.constant(<span class="number">0.0</span>)</span><br><span class="line">  print(c1.graph)</span><br><span class="line">  print(g)</span><br><span class="line">  print(c.graph)</span><br><span class="line">  </span><br><span class="line">g2=tf.get_default_graph()</span><br><span class="line">print(g2)</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">g3=tf.get_default_graph()</span><br><span class="line">print(g3)</span><br></pre></td></tr></table></figure>
<p>运行上面代码，得出结果如下：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191120172937.png" alt=""></p>
<p>c是刚开始的默认图中建立的，所以图的打印值就是原始的默认图的打印值。然后使用tf.Graph函数建立了一个图g，并且在新建的图里添加变量，可以通过变量的“.graph”获得所在的图。在新图g的作用域外，使用tf.get_default_graph又获得了原始的默认图，接着又使用tf.reset_default_graph函数，相当于重新建立一张图来代替原来的默认图。</p>
<p><strong>注意</strong>：在使用tf.reset_default_graph函数时必须保证当前图的资源已经全部释放，否则会报错。</p>
<h3 id="获取张量"><a href="#获取张量" class="headerlink" title="获取张量"></a>获取张量</h3><p>在图里可以通过名字得到其对应的元素，例如get_tensor_by_name可以获得图里面的张量。在上面的代码的基础上加上下面这段代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(c1.name)</span><br><span class="line">t=g.get_tensor_by_name(name=<span class="string">"Const"</span>:<span class="number">0</span>)</span><br><span class="line">print(t)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#运行结果</span></span><br><span class="line"><span class="comment">#Const:0</span></span><br><span class="line"><span class="comment">#Tensor("Const:0",shape=(),dtype=float32)</span></span><br></pre></td></tr></table></figure>
<p>常量c1是在一个子图g中建立的。with tf.Graph()、as_default()代码表示使用tf.Graph函数来创建一个图，并在其上面定义op。</p>
<h3 id="获取节点操作"><a href="#获取节点操作" class="headerlink" title="获取节点操作"></a>获取节点操作</h3><p>获取节点操作op的方法是get_operation_by_name。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a=tf.constant([[<span class="number">1.0</span>,<span class="number">2.0</span>]])</span><br><span class="line">b=tf.constant([[<span class="number">1.0</span>],[<span class="number">3.0</span>]])</span><br><span class="line">tensor1=tf.matmul(a,b,name=<span class="string">"exampleop"</span>)</span><br><span class="line">print(tensor1.name,tensor1)</span><br><span class="line">g3=tf.get_default_graph()</span><br><span class="line">test=g3.get_tensor_by_name(<span class="string">"exampleop:0"</span>)</span><br><span class="line">print(<span class="string">"test"</span>,test)</span><br><span class="line"></span><br><span class="line">print(tensor1.op.name)</span><br><span class="line">testop=g3.get_operation_by_name(<span class="string">"exampleop"</span>)</span><br><span class="line">print(<span class="string">"testop"</span>,testop)</span><br></pre></td></tr></table></figure>
<p>打印了一堆信息，看不懂。。。</p>
<h3 id="获取元素列表"><a href="#获取元素列表" class="headerlink" title="获取元素列表"></a>获取元素列表</h3><p>如果想看图中的全部元素，可以使用get_operations函数来实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tt2=g.get_operations()</span><br><span class="line">print(<span class="string">"所有的元素"</span>,tt2)</span><br></pre></td></tr></table></figure>
<p>有多少个常量，就打印多少条信息。</p>
<h3 id="获取对象"><a href="#获取对象" class="headerlink" title="获取对象"></a>获取对象</h3><p>前面是根据名字来获取信息，还可以根据对象来获取对象。使用tf.Graph.as_graph_element(obj,allow_tensor=True,allow_operation=True)函数，即传入的是一个对象，返回一个张量或是一个op。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tt3=g.as_graph_element(c1)</span><br><span class="line">print(tt3)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出内容</span></span><br><span class="line"><span class="comment">#Tensor("Const:0", shape=(), dtype=float32)</span></span><br></pre></td></tr></table></figure>
<p>看上述代码对tt3的打印来看，变量tt3所指的张量名字为Const0。而在获取张量那小节可以看到量名c1所指向的真实张量名字也为Const0。这表明：函数as_graph_element获得了c1的真实张量对象，并赋给了变量tt3。</p>
<h3 id="动态图（Eager）"><a href="#动态图（Eager）" class="headerlink" title="动态图（Eager）"></a>动态图（Eager）</h3><p>动态图是相对于静态图而言的。所谓的动态图是指在Python中代码被调用后，其操作立即被执行的计算。其与静态图最大的区别是不需要使用session来建立会话了。即：在静态图中，需要在会话中调用run方法才可以获得某个张量的具体值，而在动态图中，直接运行就可以得到具体值。</p>
<p>动态图是在Tensorflow1.3版本之后出现的。启动动态图只需要在程序的最开始处加上两行代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.contrib.eager <span class="keyword">as</span> tfe</span><br><span class="line">tfe.enable_eager_execution()</span><br></pre></td></tr></table></figure>
<p>上面这两行代码的作用就是开启动态图计算功能。例如：调用tf.matmul时，将会立即计算两个数相乘的值，而不是op。</p>
<p>在创建动态图的过程中， 默认也建立了一个session。 所有的代码都在该session中进行， 而且该session具有进程相同的生命周期。 这表明一旦使用动态图就无法实现静态图中关闭session的功能。 这便是动态图的不足之处： 无法实现多<br>session操作。 如果当前代码只需要一个session来完成的话， 建议优先选择动态图Eager来实现  </p>
<h2 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h2><p>运算程序的图称为会话（Session）。一次只能运行一个图</p>
<p>会话的作用：1、运行图的结构 2、分配资源运算 3、掌握资源</p>
<p>会话需要进行资源释放，需要run后进行close。否则可以使用with作为上下文管理器</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL6.png" alt=""></p>
<p>可以在会话当中指定图去运行</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL7.png" alt=""></p>
<p>sess.run(fetches，feed_dict=None,graph=None)启动整个图。</p>
<p>用来运行op和计算tensor</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL9.png" alt=""></p>
<p>feed_dict常与placeholder(占位符)一起使用</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/20190809123839.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL8.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL10.png" alt=""></p>
<p>变量：tensorflow中的变量也是一种op，是一种特殊的张量能够进行存储持久化，它的值就是张量，默认被训练。其中有个trainable参数默认为True，如果改为False，变量将不再变化。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL11.png" alt=""></p>
<h2 id="图的可视化（tensorboard）"><a href="#图的可视化（tensorboard）" class="headerlink" title="图的可视化（tensorboard）"></a>图的可视化（tensorboard）</h2><p>tensorflow提供了一个可视化工具TensorBoard，它可以把训练过程中的各种绘制数据展示出来，包括标量(Scalers)、图片(Images)、音频(Audio)、计算图(Graph)、数据分布、直方图(Histograms)和嵌入式向量。可以通过网页来观察模型的结构和训练过程中各个参数的变化。</p>
<p>当然，TensorBoard不会自动把代码展示出来，其实它是一个日志展示系统，需要在session中运算图时，将各种类型的数据汇总并输出到日志文件中。然后启动TensorBoard服务，TensorBoard读取这些日志文件，并开启6006端口提供web服务，让用户可以在浏览器中查看数据。</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/2.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plotdata = &#123; <span class="string">"batchsize"</span>:[], <span class="string">"loss"</span>:[] &#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">moving_average</span><span class="params">(a, w=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(a) &lt; w: </span><br><span class="line">        <span class="keyword">return</span> a[:]    </span><br><span class="line">    <span class="keyword">return</span> [val <span class="keyword">if</span> idx &lt; w <span class="keyword">else</span> sum(a[(idx-w):idx])/w <span class="keyword">for</span> idx, val <span class="keyword">in</span> enumerate(a)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成模拟数据</span></span><br><span class="line">train_X = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">train_Y = <span class="number">2</span> * train_X + np.random.randn(*train_X.shape) * <span class="number">0.3</span> <span class="comment"># y=2x，但是加入了噪声</span></span><br><span class="line"><span class="comment">#图形显示</span></span><br><span class="line">plt.plot(train_X, train_Y, <span class="string">'ro'</span>, label=<span class="string">'Original data'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line"><span class="comment"># 占位符</span></span><br><span class="line">X = tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line">Y = tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line"><span class="comment"># 模型参数</span></span><br><span class="line">W = tf.Variable(tf.random_normal([<span class="number">1</span>]), name=<span class="string">"weight"</span>)</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>]), name=<span class="string">"bias"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向结构</span></span><br><span class="line">z = tf.multiply(X, W)+ b</span><br><span class="line">tf.summary.histogram(<span class="string">'z'</span>,z)<span class="comment">#将预测值以直方图显示</span></span><br><span class="line"><span class="comment">#反向优化</span></span><br><span class="line">cost =tf.reduce_mean( tf.square(Y - z))</span><br><span class="line">tf.summary.scalar(<span class="string">'loss_function'</span>, cost)<span class="comment">#将损失以标量显示</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) <span class="comment">#Gradient descent</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="comment">#参数设置</span></span><br><span class="line">training_epochs = <span class="number">20</span></span><br><span class="line">display_step = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动session</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    </span><br><span class="line">    merged_summary_op = tf.summary.merge_all()<span class="comment">#合并所有summary</span></span><br><span class="line">    <span class="comment">#创建summary_writer，用于写文件</span></span><br><span class="line">    summary_writer = tf.summary.FileWriter(<span class="string">'log/mnist_with_summaries'</span>,sess.graph)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit all training data</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        <span class="keyword">for</span> (x, y) <span class="keyword">in</span> zip(train_X, train_Y):</span><br><span class="line">            sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#生成summary</span></span><br><span class="line">            summary_str = sess.run(merged_summary_op,feed_dict=&#123;X: x, Y: y&#125;);</span><br><span class="line">            summary_writer.add_summary(summary_str, epoch);<span class="comment">#将summary 写入文件</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#显示训练中的详细信息</span></span><br><span class="line">        <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</span><br><span class="line">            loss = sess.run(cost, feed_dict=&#123;X: train_X, Y:train_Y&#125;)</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Epoch:"</span>, epoch+<span class="number">1</span>, <span class="string">"cost="</span>, loss,<span class="string">"W="</span>, sess.run(W), <span class="string">"b="</span>, sess.run(b))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (loss == <span class="string">"NA"</span> ):</span><br><span class="line">                plotdata[<span class="string">"batchsize"</span>].append(epoch)</span><br><span class="line">                plotdata[<span class="string">"loss"</span>].append(loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">" Finished!"</span>)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"cost="</span>, sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;), <span class="string">"W="</span>, sess.run(W), <span class="string">"b="</span>, sess.run(b))</span><br><span class="line">    <span class="comment">#print ("cost:",cost.eval(&#123;X: train_X, Y: train_Y&#125;))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#图形显示</span></span><br><span class="line">    plt.plot(train_X, train_Y, <span class="string">'ro'</span>, label=<span class="string">'Original data'</span>)</span><br><span class="line">    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=<span class="string">'Fitted line'</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    plotdata[<span class="string">"avgloss"</span>] = moving_average(plotdata[<span class="string">"loss"</span>])</span><br><span class="line">    plt.figure(<span class="number">1</span>)</span><br><span class="line">    plt.subplot(<span class="number">211</span>)</span><br><span class="line">    plt.plot(plotdata[<span class="string">"batchsize"</span>], plotdata[<span class="string">"avgloss"</span>], <span class="string">'b--'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Minibatch number'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">    plt.title(<span class="string">'Minibatch run vs. Training loss'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"x=0.2，z="</span>, sess.run(z, feed_dict=&#123;X: <span class="number">0.2</span>&#125;))</span><br></pre></td></tr></table></figure>
<p>运行上面代码显示的内容和以前一样没什么变化，在代码的同级目录下多了一个文件夹，里面还有个文件夹。文件夹内有个文件。首先在命令行下pip安装tensorboard，接着在这个文件的上级路径下，输入下面命令</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL15.png" alt=""></p>
<p>双引号中间填绝对路径，注意不要出现中文和空格。</p>
<p>打开浏览器，输入<a href="http://127.0.0.6006。会跳到以下界面，点击SCALARS，会看到之前创建的loss\_function。这个loss_function也是可以点开的，点击loss\_function可以看到损失值随迭代次数的变化情况。还可以调节平滑数来改变右边标量的曲线。类似的还可以点击GRAPHS看看神经网络的内部结构，点击HISTOGRAMS看另一个显示值z。" target="_blank" rel="noopener">http://127.0.0.6006。会跳到以下界面，点击SCALARS，会看到之前创建的loss\_function。这个loss_function也是可以点开的，点击loss\_function可以看到损失值随迭代次数的变化情况。还可以调节平滑数来改变右边标量的曲线。类似的还可以点击GRAPHS看看神经网络的内部结构，点击HISTOGRAMS看另一个显示值z。</a></p>
<p><strong>注意：1、浏览器最好使用谷歌。2、在命令行里启动TensorBoard时，一定要先进入到日志所在的上级目录下，否则打开的页面找不到创建好的信息。</strong></p>
<h2 id="深度学习中的线性回归："><a href="#深度学习中的线性回归：" class="headerlink" title="深度学习中的线性回归："></a>深度学习中的线性回归：</h2><p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed/master/DL17.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">train_x=np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">train_y=<span class="number">2</span>*train_x+np.random.randn(*train_x.shape)*<span class="number">0.3</span></span><br><span class="line"><span class="comment">#plt.plot(train_x,train_y,label="original data")</span></span><br><span class="line"><span class="comment">#plt.legend()</span></span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line">X=tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line">Y=tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line">W=tf.Variable(tf.random_normal([<span class="number">1</span>]),name=<span class="string">"weight"</span>)</span><br><span class="line">b=tf.Variable(tf.zeros([<span class="number">1</span>]),name=<span class="string">"bias"</span>)</span><br><span class="line">z=tf.multiply(X,W)+b</span><br><span class="line">cost=tf.reduce_mean(tf.square(Y-z))</span><br><span class="line">learn_rate=<span class="number">0.005</span></span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)</span><br><span class="line">init=tf.global_variables_initializer()</span><br><span class="line">training_epochs=<span class="number">20</span></span><br><span class="line">display_step=<span class="number">2</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    plotdata=&#123;<span class="string">"batchsize"</span>:[],<span class="string">"loss"</span>:[]&#125;</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        <span class="keyword">for</span> (x,y) <span class="keyword">in</span> zip(train_x,train_y):</span><br><span class="line">            sess.run(optimizer,feed_dict=&#123;X:x,Y:y&#125;)</span><br><span class="line">        <span class="keyword">if</span> epoch%display_step==<span class="number">0</span>:</span><br><span class="line">            loss=sess.run(cost,feed_dict=&#123;X:train_x,Y:train_y&#125;)</span><br><span class="line">            print(<span class="string">"Epoch:"</span>,epoch+<span class="number">1</span>,<span class="string">"cost"</span>,loss,<span class="string">"W="</span>,sess.run(W),<span class="string">"b="</span>,sess.run(b))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (loss==<span class="string">"NA"</span>):</span><br><span class="line">                plotdata[<span class="string">"batchsize"</span>].append(epoch)</span><br><span class="line">                plotdata[<span class="string">"loss"</span>].append(loss)</span><br><span class="line">    print(<span class="string">"finish"</span>)</span><br><span class="line">    print(<span class="string">"cost"</span>,sess.run(cost,feed_dict=&#123;X:train_x,Y:train_y&#125;),<span class="string">"W="</span>,sess.run(W),<span class="string">"b="</span>,sess.run(b))</span><br></pre></td></tr></table></figure>
<p>如果后面的几个数据的迭代得出的结果是一样的，那么证明该模型已经梯度下降到最低点。此时应该把学习率调小。</p>
<h2 id="保存和载入模型"><a href="#保存和载入模型" class="headerlink" title="保存和载入模型"></a>保存和载入模型</h2><h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><p>首先需要建立一个saver，然后再session中通过saver的save即可将模型保存起来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#生成saver</span></span><br><span class="line">saver=tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"><span class="comment">#对模型初始化</span></span><br><span class="line">	sess.run(tf.global_variables_initializer())</span><br><span class="line"><span class="comment">#训练完后，使用saver.save进行保存</span></span><br><span class="line">	saver.save(sess,<span class="string">"save_path/file_name"</span>)</span><br></pre></td></tr></table></figure>
<p>运行以上代码后，在代码的同级目录下，生成几个文件。如图：</p>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/20191116221508.png" alt=""></p>
<h3 id="载入模型"><a href="#载入模型" class="headerlink" title="载入模型"></a>载入模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">saver=tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"><span class="comment">#参数可以进行初始化，也可以不进行初始化。即使初始化了，初始化的值也会被restore函数值覆盖。</span></span><br><span class="line">	sess.run(tf.global_variable_initializer())</span><br><span class="line"><span class="comment">#会将已经保存的变量值restore到变量中</span></span><br><span class="line">	saver.restore(sess,<span class="string">"save_path/file_name"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="保存模型的其它方法"><a href="#保存模型的其它方法" class="headerlink" title="保存模型的其它方法"></a>保存模型的其它方法</h3><p>Saver还可以指定存储变量名字与变量的对应关系</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver=tf.train.Saver(&#123;<span class="string">"weight"</span>:W,<span class="string">"bias"</span>:b&#125;)</span><br></pre></td></tr></table></figure>
<p>上面这种写法代表将W变量的值放到weight名字中，类似的写法还有以下两种：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#放到一个list里</span></span><br><span class="line">saver=tf.train.Saver([W,b])</span><br><span class="line"><span class="comment">#将op的名字当作key</span></span><br><span class="line">saver=tf.train.Saver(&#123;v.op.name:v <span class="keyword">for</span> v <span class="keyword">in</span> [W,b]&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="模型内容"><a href="#模型内容" class="headerlink" title="模型内容"></a>模型内容</h3><p>虽然模型已经保存了，但是仍然对我们不透明。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.tools.inspect_checkpoint <span class="keyword">import</span> print_tensors_in_checkpoint_file</span><br><span class="line">print_tensors_in_checkpoint_file(<span class="string">"./save_path/model"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="添加保存检查点"><a href="#添加保存检查点" class="headerlink" title="添加保存检查点"></a>添加保存检查点</h3><p>保存模型并不限于在训练之后，在训练之中也需要保存，因为tensorflow训练模型时难免会出现中断的情况。我们希望能够将幸苦得到的中间参数保留下来，否则下次又要重新开始。这种，在训练中保存模型，习惯上称为保存检查点。</p>
<p>​    PS：我感觉预训练模型和这个一样</p>
<p>此时用到saver的另一个参数，max_to_keep。表明最多只保存检查点文件的个数。</p>
<p>saver=tf.train.Saver(max_to_keep=1)，代表在迭代过程中只保存一个文件。这样，在循环训练模型中，新生成的模型就会覆盖以前的模型。</p>
<p>下面两种方法可以快速获取到检查点文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第一种</span></span><br><span class="line">ckpt=tf.train.get_checkpoint_state(ckpt_dir)</span><br><span class="line"><span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">  saver.restore(sess,ckpt.model_checkpoint_path)</span><br><span class="line"><span class="comment">#第二种</span></span><br><span class="line">kpt=tf.train.latest_checkpoint(savedir)</span><br><span class="line"><span class="keyword">if</span> kpt!=<span class="literal">None</span>:</span><br><span class="line">  saver.restore(sess,kpt)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/Brickexperts/Figurebed2/master/1.jpg" alt=""></p>

    </div>

    
    
    
<div>
	
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">----本文结束，感谢您的阅读。如有错，请指正。----</div>
    
</div>

	
</div>
    
      <div>
        <div id="reward-container">
  <div>大哥大嫂过年好！支持我一下呗</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.jpg" alt="湛蓝星空 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="湛蓝星空 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      </div>

    <footer class="post-footer">
          
        
        <div class="post-tags">
            <a href="/tags/%E6%A1%86%E6%9E%B6/" rel="tag"># 框架</a>
          
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/2019/08/09/ML%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB%E5%92%8C%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2/" rel="next" title="机器学习算法分类和数据分割">
                <i class="fa fa-chevron-left"></i> 机器学习算法分类和数据分割
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
              <a href="/2019/08/09/tensorflow%EF%BC%882%EF%BC%89/" rel="prev" title="tensorflow（2）">
                tensorflow（2） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
    </footer>
  </div>
  
  
  
  </article>

  </div>


          </div>
          


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="湛蓝星空">
  <p class="site-author-name" itemprop="name">湛蓝星空</p>
  <div class="site-description motion-element" itemprop="description">这个人贼菜</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/%20%7C%7C%20archive">
        
          <span class="site-state-item-count">98</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/%20%7C%7C%20th">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/%20%7C%7C%20tags">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/Brickexperts" title="GitHub &rarr; https://github.com/Brickexperts" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
  </div>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#张量"><span class="nav-text">张量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tensor类型"><span class="nav-text">tensor类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tensor阶"><span class="nav-text">tensor阶</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tensor形状"><span class="nav-text">tensor形状</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关操作"><span class="nav-text">相关操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#类型转换"><span class="nav-text">类型转换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数值操作"><span class="nav-text">数值操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#形状变换"><span class="nav-text">形状变换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据操作"><span class="nav-text">数据操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#算术运算函数"><span class="nav-text">算术运算函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵相关函数"><span class="nav-text">矩阵相关函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#规约计算"><span class="nav-text">规约计算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tf-reduce-mean"><span class="nav-text">tf.reduce_mean()</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分割"><span class="nav-text">分割</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图"><span class="nav-text">图</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#建立图"><span class="nav-text">建立图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取张量"><span class="nav-text">获取张量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取节点操作"><span class="nav-text">获取节点操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取元素列表"><span class="nav-text">获取元素列表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取对象"><span class="nav-text">获取对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#动态图（Eager）"><span class="nav-text">动态图（Eager）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#会话"><span class="nav-text">会话</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图的可视化（tensorboard）"><span class="nav-text">图的可视化（tensorboard）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习中的线性回归："><span class="nav-text">深度学习中的线性回归：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#保存和载入模型"><span class="nav-text">保存和载入模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#保存模型"><span class="nav-text">保存模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#载入模型"><span class="nav-text">载入模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#保存模型的其它方法"><span class="nav-text">保存模型的其它方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型内容"><span class="nav-text">模型内容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#添加保存检查点"><span class="nav-text">添加保存检查点</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">湛蓝星空</span>
</div>

        








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>

    

  </div>

  
    
    
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  <script src="/js/utils.js?v=7.3.0"></script>
  <script src="/js/motion.js?v=7.3.0"></script>

  
  <script src="/js/affix.js?v=7.3.0"></script>
  <script src="/js/schemes/pisces.js?v=7.3.0"></script>



  
  <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>



  <script src="/js/next-boot.js?v=7.3.0"></script>

  

  

  


  





  



















  <script src="/js/local-search.js?v=7.3.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->














</body>
</html>
